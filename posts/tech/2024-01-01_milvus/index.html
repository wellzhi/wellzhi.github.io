<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Milvus使用指南 | wellzhi</title>
<meta name=keywords content="Milvus,向量数据库,向量检索,分布式,搜索引擎"><meta name=description content='1. Milvus简介
什么是Milvus
Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。
主要特性

高性能：支持十亿级向量的毫秒级检索
多样化索引：支持多种向量索引算法（IVF、HNSW、ANNOY等）
云原生：基于Kubernetes的分布式架构
多语言SDK：支持Python、Java、Go、Node.js等
ACID事务：保证数据一致性
混合搜索：支持向量和标量数据的混合查询

应用场景

推荐系统：基于用户行为向量进行个性化推荐
图像检索：以图搜图、相似图片查找
文本搜索：语义搜索、文档相似性匹配
视频分析：视频内容检索和分析
药物发现：分子结构相似性搜索
异常检测：基于向量距离的异常识别

2. 核心概念
基本术语
Collection（集合）
类似于关系数据库中的表，用于存储向量数据和相关的标量字段。
Field（字段）
集合中的列，包括向量字段和标量字段。
Entity（实体）
集合中的一行数据，包含多个字段的值。
Partition（分区）
集合的子集，用于数据分片和查询优化。
Index（索引）
为加速向量检索而构建的数据结构。
Segment（段）
Milvus内部的数据存储单元，用于数据管理和查询优化。
数据类型
向量类型

FloatVector：浮点数向量
BinaryVector：二进制向量

标量类型

Bool：布尔值
Int8/Int16/Int32/Int64：整数
Float/Double：浮点数
String/VarChar：字符串
JSON：JSON对象

3. 安装部署
系统要求
硬件要求

CPU：x86_64架构，支持SSE4.2指令集
内存：8GB以上（推荐16GB+）
存储：SSD硬盘（推荐NVMe）
网络：千兆网卡

软件要求

操作系统：Ubuntu 18.04+、CentOS 7+、macOS 10.14+
Docker：20.10+
Docker Compose：1.28+

Docker安装（推荐）
1. 下载配置文件
# 下载docker-compose.yml
wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml
2. 启动Milvus
# 启动服务
docker-compose up -d

# 检查服务状态
docker-compose ps
3. 验证安装
# 检查Milvus是否正常运行
curl -X GET "http://localhost:9091/health"
Kubernetes部署
1. 安装Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
2. 添加Milvus Helm仓库
helm repo add milvus https://milvus-io.github.io/milvus-helm/
helm repo update
3. 部署Milvus
# 创建命名空间
kubectl create namespace milvus

# 部署Milvus集群
helm install milvus milvus/milvus --namespace milvus
源码编译安装
1. 安装依赖
# Ubuntu/Debian
sudo apt update
sudo apt install -y build-essential cmake libopenblas-dev

# CentOS/RHEL
sudo yum groupinstall -y "Development Tools"
sudo yum install -y cmake openblas-devel
2. 编译安装
# 克隆源码
git clone https://github.com/milvus-io/milvus.git
cd milvus

# 编译
make build

# 启动
./bin/milvus run standalone
4. 快速开始
安装Python SDK
pip install pymilvus
基本操作示例
1. 连接Milvus
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

# 连接到Milvus
connections.connect(
    alias="default",
    host=&#39;localhost&#39;,
    port=&#39;19530&#39;
)

print("Connected to Milvus")
2. 创建集合
# 定义字段
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200),
    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50)
]

# 创建集合schema
schema = CollectionSchema(
    fields=fields,
    description="Document embedding collection"
)

# 创建集合
collection = Collection(
    name="documents",
    schema=schema
)

print("Collection created")
3. 插入数据
import random

# 准备数据
num_entities = 1000
entities = [
    [i for i in range(num_entities)],  # id字段
    [[random.random() for _ in range(128)] for _ in range(num_entities)],  # embedding字段
    [f"Document {i}" for i in range(num_entities)],  # title字段
    [f"Category {i % 10}" for i in range(num_entities)]  # category字段
]

# 插入数据
insert_result = collection.insert(entities)
print(f"Inserted {len(insert_result.primary_keys)} entities")

# 刷新数据到磁盘
collection.flush()
4. 创建索引
# 定义索引参数
index_params = {
    "metric_type": "L2",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}
}

# 创建索引
collection.create_index(
    field_name="embedding",
    index_params=index_params
)

print("Index created")
5. 加载集合
# 加载集合到内存
collection.load()
print("Collection loaded")
6. 向量检索
# 准备查询向量
query_vectors = [[random.random() for _ in range(128)]]

# 执行搜索
search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["title", "category"]
)

# 输出结果
for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Title: {hit.entity.get(&#39;title&#39;)}")
5. 数据管理
集合管理
创建集合
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义复杂schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=256),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="score", dtype=DataType.FLOAT),
    FieldSchema(name="timestamp", dtype=DataType.INT64),
    FieldSchema(name="metadata", dtype=DataType.JSON)
]

schema = CollectionSchema(
    fields=fields,
    description="Advanced collection with multiple field types",
    enable_dynamic_field=True  # 启用动态字段
)

collection = Collection(name="advanced_collection", schema=schema)
查看集合信息
# 获取集合统计信息
stats = collection.get_stats()
print(f"Collection stats: {stats}")

# 获取集合schema
schema = collection.schema
for field in schema.fields:
    print(f"Field: {field.name}, Type: {field.dtype}, Params: {field.params}")

# 检查集合是否存在
from pymilvus import utility
has_collection = utility.has_collection("advanced_collection")
print(f"Collection exists: {has_collection}")
删除集合
# 删除集合
collection.drop()

# 或者使用utility函数
utility.drop_collection("collection_name")
分区管理
创建分区
# 创建分区
collection.create_partition("partition_2023")
collection.create_partition("partition_2024")

# 查看所有分区
partitions = collection.partitions
for partition in partitions:
    print(f"Partition: {partition.name}")
分区数据操作
# 向特定分区插入数据
entities = [
    [1, 2, 3],  # ids
    [[0.1] * 256, [0.2] * 256, [0.3] * 256],  # vectors
    ["text1", "text2", "text3"],  # text
    [0.8, 0.9, 0.7],  # scores
    [1640995200, 1640995300, 1640995400],  # timestamps
    [{"key": "value1"}, {"key": "value2"}, {"key": "value3"}]  # metadata
]

collection.insert(entities, partition_name="partition_2023")

# 在特定分区中搜索
results = collection.search(
    data=[[0.1] * 256],
    anns_field="vector",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    partition_names=["partition_2023"]
)
数据插入和更新
批量插入
import numpy as np

# 大批量数据插入
batch_size = 10000
for i in range(0, 100000, batch_size):
    ids = list(range(i, min(i + batch_size, 100000)))
    vectors = np.random.random((len(ids), 256)).tolist()
    texts = [f"Document {j}" for j in ids]
    scores = np.random.random(len(ids)).tolist()
    timestamps = [1640995200 + j for j in ids]
    metadata = [{"batch": i // batch_size} for _ in ids]
    
    entities = [ids, vectors, texts, scores, timestamps, metadata]
    collection.insert(entities)
    
    if i % 50000 == 0:
        collection.flush()  # 定期刷新
        print(f"Inserted {i + len(ids)} entities")
数据更新（Upsert）
# Milvus 2.3+支持upsert操作
update_entities = [
    [1, 2, 3],  # 更新已存在的ID
    [[0.5] * 256, [0.6] * 256, [0.7] * 256],  # 新的向量
    ["Updated text1", "Updated text2", "Updated text3"],  # 新的文本
    [0.95, 0.96, 0.97],  # 新的分数
    [1640995500, 1640995600, 1640995700],  # 新的时间戳
    [{"updated": True}, {"updated": True}, {"updated": True}]  # 新的元数据
]

collection.upsert(update_entities)
数据删除
按ID删除
# 删除指定ID的实体
delete_ids = [1, 2, 3, 4, 5]
expr = f"id in {delete_ids}"
collection.delete(expr)

# 删除满足条件的实体
expr = "score < 0.5"
collection.delete(expr)
按条件删除
# 复杂删除条件
expr = "score < 0.3 and timestamp < 1640995300"
collection.delete(expr)

# 使用JSON字段删除
expr = "JSON_CONTAINS(metadata, &#39;\"updated\": true&#39;)"
collection.delete(expr)
6. 向量检索
基本检索
相似性搜索
# 基本向量搜索
query_vectors = [[0.1] * 256, [0.2] * 256]
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 16}
}

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=10,
    output_fields=["text", "score", "timestamp"]
)

for i, hits in enumerate(results):
    print(f"Query {i} results:")
    for hit in hits:
        print(f"  ID: {hit.id}, Distance: {hit.distance:.4f}")
        print(f"  Text: {hit.entity.get(&#39;text&#39;)}")
        print(f"  Score: {hit.entity.get(&#39;score&#39;)}")
混合搜索
# 向量搜索 + 标量过滤
query_vectors = [[0.1] * 256]
search_params = {"metric_type": "L2", "params": {"nprobe": 16}}

# 添加标量过滤条件
filter_expr = "score > 0.8 and timestamp > 1640995200"

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=10,
    expr=filter_expr,
    output_fields=["text", "score", "timestamp", "metadata"]
)
高级检索
范围搜索
# 搜索距离在指定范围内的向量
from pymilvus import SearchResult

query_vectors = [[0.1] * 256]
search_params = {
    "metric_type": "L2",
    "params": {
        "nprobe": 16,
        "radius": 0.1,  # 最大距离
        "range_filter": 0.05  # 最小距离
    }
}

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=100,
    output_fields=["text", "score"]
)
多向量搜索
# 同时搜索多个向量字段（如果集合有多个向量字段）
# 假设有text_vector和image_vector两个字段

# 创建包含多个向量字段的集合
multi_vector_fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=128),
    FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=256),
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200)
]

multi_schema = CollectionSchema(fields=multi_vector_fields)
multi_collection = Collection(name="multi_vector_collection", schema=multi_schema)

# 分别在不同向量字段上搜索
text_results = multi_collection.search(
    data=[[0.1] * 128],
    anns_field="text_vector",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)

image_results = multi_collection.search(
    data=[[0.1] * 256],
    anns_field="image_vector",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
查询操作
标量查询
# 基于标量字段的查询
query_expr = "score > 0.8"
results = collection.query(
    expr=query_expr,
    output_fields=["id", "text", "score", "timestamp"]
)

for result in results:
    print(f"ID: {result[&#39;id&#39;]}, Text: {result[&#39;text&#39;]}, Score: {result[&#39;score&#39;]}")
复杂查询
# 复杂查询表达式
complex_expr = """
    (score > 0.8 and timestamp > 1640995200) or 
    (score > 0.9 and JSON_CONTAINS(metadata, &#39;"important": true&#39;))
"""

results = collection.query(
    expr=complex_expr,
    output_fields=["*"],  # 输出所有字段
    limit=100
)
分页查询
# 分页查询大量数据
page_size = 1000
offset = 0

while True:
    results = collection.query(
        expr="score > 0.5",
        output_fields=["id", "text", "score"],
        limit=page_size,
        offset=offset
    )
    
    if not results:
        break
        
    print(f"Page {offset // page_size + 1}: {len(results)} results")
    
    # 处理结果
    for result in results:
        # 处理每个结果
        pass
    
    offset += page_size
7. 索引管理
索引类型
FLAT索引
# FLAT索引 - 精确搜索，适合小数据集
flat_index = {
    "index_type": "FLAT",
    "metric_type": "L2",
    "params": {}
}

collection.create_index(
    field_name="vector",
    index_params=flat_index
)
IVF索引
# IVF_FLAT索引 - 平衡性能和精度
ivf_flat_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {
        "nlist": 128  # 聚类中心数量
    }
}

# IVF_PQ索引 - 压缩存储，适合大数据集
ivf_pq_index = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 128,
        "m": 16,  # PQ分段数
        "nbits": 8  # 每段的位数
    }
}

collection.create_index(field_name="vector", index_params=ivf_pq_index)
HNSW索引
# HNSW索引 - 高性能近似搜索
hnsw_index = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {
        "M": 16,  # 每层的最大连接数
        "efConstruction": 200  # 构建时的搜索深度
    }
}

collection.create_index(field_name="vector", index_params=hnsw_index)
ANNOY索引
# ANNOY索引 - 内存友好
annoy_index = {
    "index_type": "ANNOY",
    "metric_type": "L2",
    "params": {
        "n_trees": 8  # 树的数量
    }
}

collection.create_index(field_name="vector", index_params=annoy_index)
距离度量
欧几里得距离（L2）
l2_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",  # 欧几里得距离
    "params": {"nlist": 128}
}
内积（IP）
ip_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "IP",  # 内积
    "params": {"nlist": 128}
}
余弦相似度
# 余弦相似度需要先归一化向量，然后使用IP
import numpy as np

def normalize_vectors(vectors):
    """归一化向量以使用余弦相似度"""
    vectors = np.array(vectors)
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return (vectors / norms).tolist()

# 插入归一化后的向量
normalized_vectors = normalize_vectors(original_vectors)
entities = [ids, normalized_vectors, texts, scores, timestamps, metadata]
collection.insert(entities)

# 使用IP度量进行余弦相似度搜索
cosine_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "IP",
    "params": {"nlist": 128}
}
索引管理操作
查看索引信息
# 获取索引信息
index_info = collection.index()
print(f"Index type: {index_info.params[&#39;index_type&#39;]}")
print(f"Metric type: {index_info.params[&#39;metric_type&#39;]}")
print(f"Index params: {index_info.params[&#39;params&#39;]}")

# 检查索引构建进度
from pymilvus import utility
index_progress = utility.index_building_progress("collection_name")
print(f"Index building progress: {index_progress}")
重建索引
# 删除现有索引
collection.drop_index()

# 创建新索引
new_index = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {"M": 32, "efConstruction": 400}
}

collection.create_index(field_name="vector", index_params=new_index)

# 等待索引构建完成
import time
while True:
    progress = utility.index_building_progress(collection.name)
    if progress[&#39;pending_index_rows&#39;] == 0:
        break
    print(f"Index building progress: {progress}")
    time.sleep(5)

print("Index building completed")
8. 性能优化
搜索参数优化
IVF索引优化
# 根据数据量调整nlist
data_size = collection.num_entities
optimal_nlist = int(np.sqrt(data_size))
optimal_nlist = max(128, min(optimal_nlist, 4096))  # 限制在合理范围内

# 搜索时调整nprobe
search_params = {
    "metric_type": "L2",
    "params": {
        "nprobe": min(optimal_nlist // 4, 64)  # 通常设置为nlist的1/4
    }
}
HNSW索引优化
# 构建时参数
hnsw_build_params = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {
        "M": 16,  # 连接数，影响精度和内存
        "efConstruction": 200  # 构建时搜索深度
    }
}

# 搜索时参数
hnsw_search_params = {
    "metric_type": "L2",
    "params": {
        "ef": 100  # 搜索时的候选数量，越大精度越高但速度越慢
    }
}
内存管理
集合加载策略
# 部分加载 - 只加载需要的字段
collection.load(replica_number=1, _resource_groups=["default"])

# 释放不需要的集合
collection.release()

# 检查内存使用
from pymilvus import utility
memory_info = utility.get_query_segment_info(collection.name)
for info in memory_info:
    print(f"Segment {info.segmentID}: {info.mem_size} bytes")
分区加载
# 只加载特定分区
collection.load(partition_names=["partition_2024"])

# 动态加载/释放分区
def load_partition_by_date(date_str):
    partition_name = f"partition_{date_str}"
    if partition_name in [p.name for p in collection.partitions]:
        collection.load(partition_names=[partition_name])
        return True
    return False

def release_old_partitions(keep_days=7):
    from datetime import datetime, timedelta
    cutoff_date = datetime.now() - timedelta(days=keep_days)
    
    for partition in collection.partitions:
        if partition.name.startswith("partition_"):
            date_str = partition.name.replace("partition_", "")
            try:
                partition_date = datetime.strptime(date_str, "%Y%m%d")
                if partition_date < cutoff_date:
                    collection.release(partition_names=[partition.name])
                    print(f"Released partition: {partition.name}")
            except ValueError:
                continue
批处理优化
批量插入优化
def optimized_batch_insert(collection, data, batch_size=10000):
    """优化的批量插入函数"""
    total_entities = len(data[0])
    
    for i in range(0, total_entities, batch_size):
        end_idx = min(i + batch_size, total_entities)
        batch_data = [field_data[i:end_idx] for field_data in data]
        
        # 插入批次
        collection.insert(batch_data)
        
        # 定期刷新
        if (i + batch_size) % 50000 == 0:
            collection.flush()
            print(f"Inserted and flushed {i + batch_size} entities")
    
    # 最终刷新
    collection.flush()
    print(f"Completed insertion of {total_entities} entities")
并行搜索
import concurrent.futures
import threading

def parallel_search(collection, query_vectors, search_params, max_workers=4):
    """并行执行多个搜索请求"""
    def search_batch(vectors_batch):
        return collection.search(
            data=vectors_batch,
            anns_field="vector",
            param=search_params,
            limit=10
        )
    
    # 将查询向量分批
    batch_size = len(query_vectors) // max_workers
    batches = [query_vectors[i:i+batch_size] 
               for i in range(0, len(query_vectors), batch_size)]
    
    # 并行执行搜索
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_batch = {executor.submit(search_batch, batch): batch 
                          for batch in batches}
        
        all_results = []
        for future in concurrent.futures.as_completed(future_to_batch):
            batch_results = future.result()
            all_results.extend(batch_results)
    
    return all_results
连接池管理
from pymilvus import connections
import threading

class MilvusConnectionPool:
    def __init__(self, host=&#39;localhost&#39;, port=&#39;19530&#39;, pool_size=10):
        self.host = host
        self.port = port
        self.pool_size = pool_size
        self.connections = []
        self.lock = threading.Lock()
        self._initialize_pool()
    
    def _initialize_pool(self):
        for i in range(self.pool_size):
            alias = f"connection_{i}"
            connections.connect(
                alias=alias,
                host=self.host,
                port=self.port
            )
            self.connections.append(alias)
    
    def get_connection(self):
        with self.lock:
            if self.connections:
                return self.connections.pop()
            else:
                # 如果池为空，创建新连接
                alias = f"temp_connection_{threading.current_thread().ident}"
                connections.connect(
                    alias=alias,
                    host=self.host,
                    port=self.port
                )
                return alias
    
    def return_connection(self, alias):
        with self.lock:
            if len(self.connections) < self.pool_size:
                self.connections.append(alias)
            else:
                connections.disconnect(alias)

# 使用连接池
pool = MilvusConnectionPool()

def search_with_pool(query_vector):
    alias = pool.get_connection()
    try:
        # 使用指定连接执行搜索
        connections.connect(alias=alias)
        collection = Collection("documents", using=alias)
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"nprobe": 16}},
            limit=10
        )
        return results
    finally:
        pool.return_connection(alias)
9. 集群部署
Kubernetes集群部署
1. 准备配置文件
# milvus-cluster-values.yaml
cluster:
  enabled: true

image:
  all:
    repository: milvusdb/milvus
    tag: v2.3.0
    pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 19530
  portName: milvus
  nodePort: 30530

rootCoordinator:
  replicas: 1
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

queryCoordinator:
  replicas: 1
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

queryNode:
  replicas: 2
  resources:
    limits:
      cpu: 2
      memory: 8Gi
    requests:
      cpu: 1
      memory: 4Gi

indexNode:
  replicas: 1
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 1
      memory: 2Gi

dataNode:
  replicas: 2
  resources:
    limits:
      cpu: 1
      memory: 4Gi
    requests:
      cpu: 0.5
      memory: 2Gi

proxy:
  replicas: 2
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

# 存储配置
minio:
  enabled: true
  mode: distributed
  replicas: 4
  persistence:
    enabled: true
    size: 100Gi
    storageClass: "fast-ssd"

etcd:
  enabled: true
  replicaCount: 3
  persistence:
    enabled: true
    size: 10Gi
    storageClass: "fast-ssd"

pulsar:
  enabled: true
  components:
    broker: true
    bookkeeper: true
    zookeeper: true
  zookeeper:
    replicaCount: 3
  bookkeeper:
    replicaCount: 3
  broker:
    replicaCount: 2
2. 部署集群
# 创建命名空间
kubectl create namespace milvus-cluster

# 部署Milvus集群
helm install milvus-cluster milvus/milvus \
  --namespace milvus-cluster \
  --values milvus-cluster-values.yaml

# 检查部署状态
kubectl get pods -n milvus-cluster
kubectl get services -n milvus-cluster
3. 配置负载均衡
# milvus-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: milvus-ingress
  namespace: milvus-cluster
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/grpc-backend: "true"
spec:
  ingressClassName: nginx
  rules:
  - host: milvus.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: milvus-cluster
            port:
              number: 19530
高可用配置
多副本配置
# 连接到集群
connections.connect(
    alias="cluster",
    host=&#39;milvus.example.com&#39;,
    port=&#39;19530&#39;
)

# 创建集合时指定副本数
collection = Collection("ha_collection", schema=schema)
collection.create_index(field_name="vector", index_params=index_params)

# 加载时指定副本数
collection.load(replica_number=2)

# 检查副本状态
from pymilvus import utility
replica_info = utility.get_replicas(collection.name)
for replica in replica_info:
    print(f"Replica {replica.id}: {replica.node_ids}")
故障转移测试
def test_failover(collection):
    """测试故障转移能力"""
    import time
    import random
    
    query_vector = [random.random() for _ in range(256)]
    
    # 持续查询测试
    success_count = 0
    total_count = 0
    
    for i in range(100):
        try:
            results = collection.search(
                data=[query_vector],
                anns_field="vector",
                param={"metric_type": "L2", "params": {"nprobe": 16}},
                limit=10
            )
            success_count += 1
            print(f"Query {i}: Success")
        except Exception as e:
            print(f"Query {i}: Failed - {e}")
        
        total_count += 1
        time.sleep(1)
    
    print(f"Success rate: {success_count/total_count*100:.2f}%")
数据分片策略
基于时间的分片
from datetime import datetime, timedelta

def create_time_based_partitions(collection, start_date, end_date):
    """创建基于时间的分区"""
    current_date = start_date
    
    while current_date <= end_date:
        partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
        
        current_date += timedelta(days=1)

def insert_with_time_partition(collection, entities, timestamp_field_idx=4):
    """根据时间戳插入到对应分区"""
    # 按时间戳分组数据
    partition_data = {}
    
    for i, timestamp in enumerate(entities[timestamp_field_idx]):
        date_str = datetime.fromtimestamp(timestamp).strftime(&#39;%Y%m%d&#39;)
        partition_name = f"partition_{date_str}"
        
        if partition_name not in partition_data:
            partition_data[partition_name] = [[] for _ in entities]
        
        for j, field_data in enumerate(entities):
            partition_data[partition_name][j].append(field_data[i])
    
    # 分别插入到各个分区
    for partition_name, partition_entities in partition_data.items():
        try:
            collection.insert(partition_entities, partition_name=partition_name)
            print(f"Inserted {len(partition_entities[0])} entities to {partition_name}")
        except Exception as e:
            print(f"Failed to insert to {partition_name}: {e}")
基于哈希的分片
import hashlib

def create_hash_based_partitions(collection, num_partitions=8):
    """创建基于哈希的分区"""
    for i in range(num_partitions):
        partition_name = f"partition_hash_{i}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")

def insert_with_hash_partition(collection, entities, key_field_idx=0, num_partitions=8):
    """根据键值哈希插入到对应分区"""
    partition_data = {f"partition_hash_{i}": [[] for _ in entities] 
                     for i in range(num_partitions)}
    
    for i, key in enumerate(entities[key_field_idx]):
        # 计算哈希值确定分区
        hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16)
        partition_idx = hash_value % num_partitions
        partition_name = f"partition_hash_{partition_idx}"
        
        for j, field_data in enumerate(entities):
            partition_data[partition_name][j].append(field_data[i])
    
    # 插入到各个分区
    for partition_name, partition_entities in partition_data.items():
        if partition_entities[0]:  # 如果分区有数据
            collection.insert(partition_entities, partition_name=partition_name)
            print(f"Inserted {len(partition_entities[0])} entities to {partition_name}")
10. 监控运维
系统监控
Prometheus监控配置
# prometheus-config.yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: &#39;milvus&#39;
    static_configs:
      - targets: [&#39;milvus:9091&#39;]
    metrics_path: /metrics
    scrape_interval: 15s

  - job_name: &#39;milvus-cluster&#39;
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - milvus-cluster
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
        action: keep
        regex: milvus
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+)
        replacement: ${1}:9091
Grafana仪表板
{
  "dashboard": {
    "title": "Milvus Monitoring",
    "panels": [
      {
        "title": "QPS (Queries Per Second)",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(milvus_proxy_search_vectors_count[5m])",
            "legendFormat": "Search QPS"
          },
          {
            "expr": "rate(milvus_proxy_insert_vectors_count[5m])",
            "legendFormat": "Insert QPS"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))",
            "legendFormat": "Search P95 Latency"
          },
          {
            "expr": "histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))",
            "legendFormat": "Search P99 Latency"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "milvus_querynode_memory_usage_bytes",
            "legendFormat": "QueryNode Memory"
          },
          {
            "expr": "milvus_indexnode_memory_usage_bytes",
            "legendFormat": "IndexNode Memory"
          }
        ]
      },
      {
        "title": "Collection Statistics",
        "type": "table",
        "targets": [
          {
            "expr": "milvus_collection_num_entities",
            "format": "table"
          }
        ]
      }
    ]
  }
}
性能监控
自定义监控脚本
import time
import psutil
import threading
from pymilvus import connections, Collection, utility
from datetime import datetime

class MilvusMonitor:
    def __init__(self, collection_name, interval=60):
        self.collection_name = collection_name
        self.interval = interval
        self.running = False
        self.metrics = []
        
    def start_monitoring(self):
        self.running = True
        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        
    def stop_monitoring(self):
        self.running = False
        
    def _monitor_loop(self):
        while self.running:
            try:
                metrics = self._collect_metrics()
                self.metrics.append(metrics)
                print(f"[{metrics[&#39;timestamp&#39;]}] {metrics}")
                
                # 保留最近1000条记录
                if len(self.metrics) > 1000:
                    self.metrics = self.metrics[-1000:]
                    
            except Exception as e:
                print(f"Monitoring error: {e}")
                
            time.sleep(self.interval)
            
    def _collect_metrics(self):
        collection = Collection(self.collection_name)
        
        # 集合统计信息
        stats = collection.get_stats()
        num_entities = int(stats[&#39;row_count&#39;])
        
        # 系统资源
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage(&#39;/&#39;)
        
        # 查询性能测试
        start_time = time.time()
        try:
            test_vector = [0.1] * 256
            collection.search(
                data=[test_vector],
                anns_field="vector",
                param={"metric_type": "L2", "params": {"nprobe": 16}},
                limit=10
            )
            query_latency = (time.time() - start_time) * 1000  # ms
        except Exception as e:
            query_latency = -1
            
        return {
            &#39;timestamp&#39;: datetime.now().isoformat(),
            &#39;collection_entities&#39;: num_entities,
            &#39;cpu_percent&#39;: cpu_percent,
            &#39;memory_percent&#39;: memory.percent,
            &#39;memory_used_gb&#39;: memory.used / (1024**3),
            &#39;disk_percent&#39;: disk.percent,
            &#39;disk_used_gb&#39;: disk.used / (1024**3),
            &#39;query_latency_ms&#39;: query_latency
        }
        
    def get_metrics_summary(self, last_n=100):
        """获取最近N条记录的统计摘要"""
        if not self.metrics:
            return None
            
        recent_metrics = self.metrics[-last_n:]
        
        latencies = [m[&#39;query_latency_ms&#39;] for m in recent_metrics if m[&#39;query_latency_ms&#39;] > 0]
        cpu_usage = [m[&#39;cpu_percent&#39;] for m in recent_metrics]
        memory_usage = [m[&#39;memory_percent&#39;] for m in recent_metrics]
        
        return {
            &#39;avg_query_latency_ms&#39;: sum(latencies) / len(latencies) if latencies else 0,
            &#39;max_query_latency_ms&#39;: max(latencies) if latencies else 0,
            &#39;avg_cpu_percent&#39;: sum(cpu_usage) / len(cpu_usage),
            &#39;max_cpu_percent&#39;: max(cpu_usage),
            &#39;avg_memory_percent&#39;: sum(memory_usage) / len(memory_usage),
            &#39;max_memory_percent&#39;: max(memory_usage),
            &#39;total_entities&#39;: recent_metrics[-1][&#39;collection_entities&#39;] if recent_metrics else 0
        }

# 使用监控器
monitor = MilvusMonitor("documents", interval=30)
monitor.start_monitoring()

# 运行一段时间后查看摘要
time.sleep(300)  # 5分钟
summary = monitor.get_metrics_summary()
print(f"Performance Summary: {summary}")

monitor.stop_monitoring()
日志管理
日志配置
# milvus-log-config.yaml
log:
  level: info
  file:
    rootPath: "/var/log/milvus"
    maxSize: 100  # MB
    maxAge: 7     # days
    maxBackups: 10
  format: json
  
# 在Kubernetes中配置日志收集
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: milvus-cluster
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf

    [INPUT]
        Name              tail
        Path              /var/log/milvus/*.log
        Parser            json
        Tag               milvus.*
        Refresh_Interval  5

    [OUTPUT]
        Name  es
        Match milvus.*
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Index milvus-logs
        Type  _doc
日志分析脚本
import json
import re
from datetime import datetime, timedelta
from collections import defaultdict

def analyze_milvus_logs(log_file_path, hours=24):
    """分析Milvus日志文件"""
    cutoff_time = datetime.now() - timedelta(hours=hours)
    
    error_counts = defaultdict(int)
    warning_counts = defaultdict(int)
    performance_metrics = []
    
    with open(log_file_path, &#39;r&#39;) as f:
        for line in f:
            try:
                log_entry = json.loads(line.strip())
                log_time = datetime.fromisoformat(log_entry.get(&#39;time&#39;, &#39;&#39;).replace(&#39;Z&#39;, &#39;+00:00&#39;))
                
                if log_time < cutoff_time:
                    continue
                    
                level = log_entry.get(&#39;level&#39;, &#39;&#39;).upper()
                message = log_entry.get(&#39;msg&#39;, &#39;&#39;)
                
                # 统计错误和警告
                if level == &#39;ERROR&#39;:
                    error_counts[message] += 1
                elif level == &#39;WARN&#39;:
                    warning_counts[message] += 1
                    
                # 提取性能指标
                if &#39;latency&#39; in message.lower():
                    latency_match = re.search(r&#39;latency[:\s]+(\d+(?:\.\d+)?)\s*(ms|μs)&#39;, message)
                    if latency_match:
                        latency_value = float(latency_match.group(1))
                        latency_unit = latency_match.group(2)
                        
                        if latency_unit == &#39;μs&#39;:
                            latency_value /= 1000  # 转换为ms
                            
                        performance_metrics.append({
                            &#39;timestamp&#39;: log_time,
                            &#39;latency_ms&#39;: latency_value,
                            &#39;operation&#39;: extract_operation(message)
                        })
                        
            except (json.JSONDecodeError, ValueError) as e:
                continue
                
    return {
        &#39;error_summary&#39;: dict(error_counts),
        &#39;warning_summary&#39;: dict(warning_counts),
        &#39;performance_metrics&#39;: performance_metrics
    }

def extract_operation(message):
    """从日志消息中提取操作类型"""
    if &#39;search&#39; in message.lower():
        return &#39;search&#39;
    elif &#39;insert&#39; in message.lower():
        return &#39;insert&#39;
    elif &#39;index&#39; in message.lower():
        return &#39;index&#39;
    else:
        return &#39;unknown&#39;

def generate_log_report(analysis_result):
    """生成日志分析报告"""
    print("=== Milvus Log Analysis Report ===")
    print(f"Analysis time: {datetime.now()}")
    print()
    
    # 错误摘要
    print("Top Errors:")
    sorted_errors = sorted(analysis_result[&#39;error_summary&#39;].items(), 
                          key=lambda x: x[1], reverse=True)
    for error, count in sorted_errors[:10]:
        print(f"  {count:4d} - {error[:100]}...")
    print()
    
    # 警告摘要
    print("Top Warnings:")
    sorted_warnings = sorted(analysis_result[&#39;warning_summary&#39;].items(), 
                           key=lambda x: x[1], reverse=True)
    for warning, count in sorted_warnings[:10]:
        print(f"  {count:4d} - {warning[:100]}...")
    print()
    
    # 性能摘要
    metrics = analysis_result[&#39;performance_metrics&#39;]
    if metrics:
        latencies = [m[&#39;latency_ms&#39;] for m in metrics]
        print("Performance Summary:")
        print(f"  Total operations: {len(metrics)}")
        print(f"  Average latency: {sum(latencies)/len(latencies):.2f} ms")
        print(f"  Max latency: {max(latencies):.2f} ms")
        print(f"  Min latency: {min(latencies):.2f} ms")
        
        # 按操作类型分组
        by_operation = defaultdict(list)
        for metric in metrics:
            by_operation[metric[&#39;operation&#39;]].append(metric[&#39;latency_ms&#39;])
            
        print("\nPerformance by Operation:")
        for operation, latencies in by_operation.items():
            if latencies:
                avg_latency = sum(latencies) / len(latencies)
                print(f"  {operation.capitalize()}:")
                print(f"    Count: {len(latencies)}")
                print(f"    Avg latency: {avg_latency:.2f} ms")
                print(f"    Max latency: {max(latencies):.2f} ms")
    else:
        print("No performance metrics found.")

# 使用示例
if __name__ == "__main__":
    log_file = "/path/to/milvus.log"
    result = analyze_milvus_logs(log_file, hours=24)
    generate_log_report(result)
11. 最佳实践
1. 数据建模最佳实践
Collection设计原则
# 良好的Collection设计示例
def create_production_collection(name, vector_dim, expected_size):
    """生产环境Collection设计"""
    # 根据数据规模选择分片数
    shard_num = min(max(expected_size // 1000000, 2), 16)
    
    fields = [
        # 主键字段 - 使用有意义的ID
        FieldSchema(
            name="id", 
            dtype=DataType.INT64, 
            is_primary=True, 
            auto_id=False,
            description="Document unique identifier"
        ),
        # 时间戳字段 - 便于数据管理
        FieldSchema(
            name="created_at", 
            dtype=DataType.INT64,
            description="Creation timestamp"
        ),
        # 分类字段 - 用于过滤
        FieldSchema(
            name="category", 
            dtype=DataType.VARCHAR, 
            max_length=50,
            description="Document category"
        ),
        # 向量字段 - 核心搜索字段
        FieldSchema(
            name="embedding", 
            dtype=DataType.FLOAT_VECTOR, 
            dim=vector_dim,
            description="Document embedding vector"
        ),
        # 元数据字段 - 存储额外信息
        FieldSchema(
            name="metadata", 
            dtype=DataType.JSON,
            description="Additional metadata"
        )
    ]
    
    schema = CollectionSchema(
        fields=fields,
        description=f"Production collection for {expected_size} documents",
        enable_dynamic_field=True  # 允许动态字段
    )
    
    collection = Collection(
        name=name,
        schema=schema,
        shards_num=shard_num,
        consistency_level="Strong"  # 生产环境建议强一致性
    )
    
    return collection
分区策略
# 基于时间的分区策略
def create_time_based_partitions(collection, start_date, end_date):
    """创建基于时间的分区"""
    from datetime import datetime, timedelta
    
    current_date = start_date
    while current_date <= end_date:
        partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
        current_date += timedelta(days=1)

# 基于类别的分区策略
def create_category_partitions(collection, categories):
    """创建基于类别的分区"""
    for category in categories:
        partition_name = f"category_{category.lower()}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
2. 性能优化最佳实践
索引选择策略
def choose_optimal_index(data_size, memory_budget, latency_requirement, accuracy_requirement):
    """根据需求选择最优索引"""
    
    if data_size < 100000:
        # 小数据集使用FLAT
        return {
            "index_type": "FLAT",
            "metric_type": "L2",
            "params": {}
        }
    
    elif latency_requirement == "ultra_low" and memory_budget == "high":
        # 超低延迟需求使用HNSW
        return {
            "index_type": "HNSW",
            "metric_type": "L2",
            "params": {
                "M": 32,
                "efConstruction": 400
            }
        }
    
    elif memory_budget == "low":
        # 内存受限使用PQ压缩
        return {
            "index_type": "IVF_PQ",
            "metric_type": "L2",
            "params": {
                "nlist": min(4 * int(np.sqrt(data_size)), 4096),
                "m": 16,
                "nbits": 8
            }
        }
    
    else:
        # 平衡选择IVF_FLAT
        return {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {
                "nlist": min(4 * int(np.sqrt(data_size)), 4096)
            }
        }

# 动态调整搜索参数
def get_adaptive_search_params(index_type, accuracy_level="medium", data_size=None):
    """根据索引类型和精度要求动态调整搜索参数"""
    
    if index_type == "IVF_FLAT" or index_type == "IVF_PQ":
        nprobe_map = {
            "low": max(8, int(np.sqrt(data_size)) // 100) if data_size else 8,
            "medium": max(16, int(np.sqrt(data_size)) // 50) if data_size else 16,
            "high": max(32, int(np.sqrt(data_size)) // 25) if data_size else 32
        }
        return {"nprobe": nprobe_map[accuracy_level]}
    
    elif index_type == "HNSW":
        ef_map = {"low": 64, "medium": 128, "high": 256}
        return {"ef": ef_map[accuracy_level]}
    
    elif index_type == "ANNOY":
        search_k_map = {"low": 100, "medium": 200, "high": 400}
        return {"search_k": search_k_map[accuracy_level]}
    
    return {}
批处理优化
class OptimizedBatchProcessor:
    """优化的批处理器"""
    
    def __init__(self, collection, batch_size=10000, flush_interval=50000):
        self.collection = collection
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.total_inserted = 0
    
    def insert_batch(self, data):
        """批量插入数据"""
        total_entities = len(data[0])
        
        for i in range(0, total_entities, self.batch_size):
            end_idx = min(i + self.batch_size, total_entities)
            batch_data = [field_data[i:end_idx] for field_data in data]
            
            try:
                result = self.collection.insert(batch_data)
                self.total_inserted += len(result.primary_keys)
                
                # 定期刷新
                if self.total_inserted % self.flush_interval == 0:
                    self.collection.flush()
                    print(f"Flushed after inserting {self.total_inserted} entities")
                    
            except Exception as e:
                print(f"Error inserting batch {i//self.batch_size}: {e}")
                continue
        
        # 最终刷新
        self.collection.flush()
        return self.total_inserted
    
    def parallel_search(self, query_vectors, search_params, max_workers=4):
        """并行搜索"""
        import concurrent.futures
        
        def search_single(query_vector):
            return self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param=search_params,
                limit=10
            )
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(search_single, qv) for qv in query_vectors]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        return results
3. 数据质量最佳实践
向量预处理
import numpy as np
from sklearn.preprocessing import normalize

def preprocess_vectors(vectors, normalization="l2", dimension_check=True):
    """向量预处理管道"""
    vectors = np.array(vectors, dtype=np.float32)
    
    # 维度检查
    if dimension_check and len(vectors.shape) != 2:
        raise ValueError(f"Expected 2D array, got {len(vectors.shape)}D")
    
    # 检查NaN和无穷值
    if np.any(np.isnan(vectors)) or np.any(np.isinf(vectors)):
        print("Warning: Found NaN or infinite values, replacing with zeros")
        vectors = np.nan_to_num(vectors, nan=0.0, posinf=0.0, neginf=0.0)
    
    # 归一化
    if normalization == "l2":
        vectors = normalize(vectors, norm=&#39;l2&#39;, axis=1)
    elif normalization == "minmax":
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        vectors = scaler.fit_transform(vectors)
    
    return vectors.tolist()

# 数据验证
def validate_data_quality(data, schema):
    """验证数据质量"""
    issues = []
    
    # 检查数据长度一致性
    field_lengths = [len(field_data) for field_data in data]
    if len(set(field_lengths)) > 1:
        issues.append(f"Inconsistent field lengths: {field_lengths}")
    
    # 检查向量维度
    for i, field in enumerate(schema.fields):
        if field.dtype == DataType.FLOAT_VECTOR:
            vectors = data[i]
            expected_dim = field.params.get(&#39;dim&#39;)
            for j, vector in enumerate(vectors[:100]):  # 检查前100个
                if len(vector) != expected_dim:
                    issues.append(f"Vector {j} has dimension {len(vector)}, expected {expected_dim}")
                    break
    
    return issues
4. 监控和运维最佳实践
健康检查系统
import time
import logging
from datetime import datetime

class MilvusHealthMonitor:
    """Milvus健康监控系统"""
    
    def __init__(self, collection_names, alert_thresholds=None):
        self.collection_names = collection_names
        self.alert_thresholds = alert_thresholds or {
            &#39;query_latency&#39;: 1.0,  # 秒
            &#39;memory_usage&#39;: 0.8,   # 80%
            &#39;error_rate&#39;: 0.05     # 5%
        }
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        logger = logging.getLogger(&#39;milvus_monitor&#39;)
        logger.setLevel(logging.INFO)
        handler = logging.FileHandler(&#39;milvus_health.log&#39;)
        formatter = logging.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        return logger
    
    def check_connection_health(self):
        """检查连接健康状态"""
        try:
            from pymilvus import utility
            version = utility.get_server_version()
            self.logger.info(f"Milvus server version: {version}")
            return True
        except Exception as e:
            self.logger.error(f"Connection health check failed: {e}")
            return False
    
    def check_collection_health(self, collection_name):
        """检查集合健康状态"""
        try:
            collection = Collection(collection_name)
            
            # 检查集合状态
            stats = collection.get_stats()
            num_entities = collection.num_entities
            
            # 执行测试查询
            start_time = time.time()
            test_vector = [[0.1] * 128]  # 假设128维向量
            results = collection.search(
                data=test_vector,
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=1
            )
            query_latency = time.time() - start_time
            
            # 记录指标
            metrics = {
                &#39;collection&#39;: collection_name,
                &#39;num_entities&#39;: num_entities,
                &#39;query_latency&#39;: query_latency,
                &#39;timestamp&#39;: datetime.now().isoformat()
            }
            
            self.logger.info(f"Collection health: {metrics}")
            
            # 检查告警阈值
            if query_latency > self.alert_thresholds[&#39;query_latency&#39;]:
                self.logger.warning(f"High query latency: {query_latency:.3f}s")
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Collection health check failed for {collection_name}: {e}")
            return None
    
    def run_continuous_monitoring(self, interval=60):
        """持续监控"""
        while True:
            try:
                # 检查连接
                if not self.check_connection_health():
                    self.logger.critical("Milvus connection lost!")
                
                # 检查所有集合
                for collection_name in self.collection_names:
                    self.check_collection_health(collection_name)
                
                time.sleep(interval)
                
            except KeyboardInterrupt:
                self.logger.info("Monitoring stopped by user")
                break
            except Exception as e:
                self.logger.error(f"Monitoring error: {e}")
                time.sleep(interval)
备份和恢复策略
import json
import os
from datetime import datetime

class MilvusBackupManager:
    """Milvus备份管理器"""
    
    def __init__(self, backup_dir="./milvus_backups"):
        self.backup_dir = backup_dir
        os.makedirs(backup_dir, exist_ok=True)
    
    def backup_collection_metadata(self, collection_name):
        """备份集合元数据"""
        try:
            collection = Collection(collection_name)
            
            # 收集元数据
            metadata = {
                &#39;name&#39;: collection.name,
                &#39;description&#39;: collection.description,
                &#39;schema&#39;: {
                    &#39;fields&#39;: [
                        {
                            &#39;name&#39;: field.name,
                            &#39;dtype&#39;: str(field.dtype),
                            &#39;params&#39;: field.params,
                            &#39;is_primary&#39;: field.is_primary,
                            &#39;auto_id&#39;: field.auto_id
                        }
                        for field in collection.schema.fields
                    ],
                    &#39;enable_dynamic_field&#39;: collection.schema.enable_dynamic_field
                },
                &#39;num_entities&#39;: collection.num_entities,
                &#39;partitions&#39;: [p.name for p in collection.partitions],
                &#39;indexes&#39;: []
            }
            
            # 获取索引信息
            try:
                index_info = collection.index()
                if index_info:
                    metadata[&#39;indexes&#39;].append({
                        &#39;field_name&#39;: &#39;embedding&#39;,  # 假设向量字段名
                        &#39;index_params&#39;: index_info.params
                    })
            except:
                pass
            
            # 保存元数据
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.backup_dir}/{collection_name}_metadata_{timestamp}.json"
            
            with open(backup_file, &#39;w&#39;) as f:
                json.dump(metadata, f, indent=2)
            
            print(f"Metadata backup saved: {backup_file}")
            return backup_file
            
        except Exception as e:
            print(f"Backup failed: {e}")
            return None
    
    def restore_collection_from_metadata(self, backup_file):
        """从元数据恢复集合结构"""
        try:
            with open(backup_file, &#39;r&#39;) as f:
                metadata = json.load(f)
            
            # 重建字段
            fields = []
            for field_info in metadata[&#39;schema&#39;][&#39;fields&#39;]:
                field = FieldSchema(
                    name=field_info[&#39;name&#39;],
                    dtype=getattr(DataType, field_info[&#39;dtype&#39;].split(&#39;.&#39;)[-1]),
                    is_primary=field_info.get(&#39;is_primary&#39;, False),
                    auto_id=field_info.get(&#39;auto_id&#39;, False),
                    **field_info.get(&#39;params&#39;, {})
                )
                fields.append(field)
            
            # 重建schema
            schema = CollectionSchema(
                fields=fields,
                description=metadata[&#39;description&#39;],
                enable_dynamic_field=metadata[&#39;schema&#39;][&#39;enable_dynamic_field&#39;]
            )
            
            # 创建集合
            collection = Collection(
                name=metadata[&#39;name&#39;],
                schema=schema
            )
            
            # 重建分区
            for partition_name in metadata[&#39;partitions&#39;]:
                if partition_name != &#39;_default&#39;:
                    collection.create_partition(partition_name)
            
            print(f"Collection {metadata[&#39;name&#39;]} restored from backup")
            return collection
            
        except Exception as e:
            print(f"Restore failed: {e}")
            return None
5. 安全最佳实践
访问控制
from pymilvus import connections

# 安全连接配置
def secure_connect(host, port, username, password, secure=True):
    """安全连接到Milvus"""
    try:
        connections.connect(
            alias="secure_connection",
            host=host,
            port=port,
            user=username,
            password=password,
            secure=secure,
            server_pem_path="/path/to/server.pem",  # TLS证书路径
            server_name="milvus-server",
            timeout=30
        )
        print("Secure connection established")
        return True
    except Exception as e:
        print(f"Secure connection failed: {e}")
        return False

# 输入验证
def validate_search_input(query_vectors, limit, expr=None):
    """验证搜索输入"""
    # 验证向量
    if not isinstance(query_vectors, list) or not query_vectors:
        raise ValueError("Query vectors must be a non-empty list")
    
    # 验证limit
    if not isinstance(limit, int) or limit <= 0 or limit > 10000:
        raise ValueError("Limit must be a positive integer <= 10000")
    
    # 验证表达式（防止注入）
    if expr:
        dangerous_keywords = [&#39;DROP&#39;, &#39;DELETE&#39;, &#39;UPDATE&#39;, &#39;INSERT&#39;, &#39;CREATE&#39;]
        expr_upper = expr.upper()
        for keyword in dangerous_keywords:
            if keyword in expr_upper:
                raise ValueError(f"Dangerous keyword &#39;{keyword}&#39; found in expression")
    
    return True
12. 常见问题
Q1: 如何选择合适的索引类型？
A: 索引选择主要考虑以下因素：'><meta name=author content="wellzhi"><link rel=canonical href=https://wellzhi.github.io/posts/tech/2024-01-01_milvus/><link crossorigin=anonymous href=/assets/css/stylesheet.b54291e20a5b433add2181af00208e3e72d99f37b405cd9f3ff373c992518ba6.css integrity="sha256-tUKR4gpbQzrdIYGvACCOPnLZnze0Bc2fP/NzyZJRi6Y=" rel="preload stylesheet" as=style><script crossorigin=anonymous src=/assets/js/mermaid.min.af2e2ae7d64e037e8a582c3ba35b128209a6f8350c3825cda07833979e0d827c.js></script><link rel=icon href=https://wellzhi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wellzhi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wellzhi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wellzhi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wellzhi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wellzhi.github.io/posts/tech/2024-01-01_milvus/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wellzhi.github.io/posts/tech/2024-01-01_milvus/"><meta property="og:site_name" content="wellzhi"><meta property="og:title" content="Milvus使用指南"><meta property="og:description" content='1. Milvus简介 什么是Milvus Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。
主要特性 高性能：支持十亿级向量的毫秒级检索 多样化索引：支持多种向量索引算法（IVF、HNSW、ANNOY等） 云原生：基于Kubernetes的分布式架构 多语言SDK：支持Python、Java、Go、Node.js等 ACID事务：保证数据一致性 混合搜索：支持向量和标量数据的混合查询 应用场景 推荐系统：基于用户行为向量进行个性化推荐 图像检索：以图搜图、相似图片查找 文本搜索：语义搜索、文档相似性匹配 视频分析：视频内容检索和分析 药物发现：分子结构相似性搜索 异常检测：基于向量距离的异常识别 2. 核心概念 基本术语 Collection（集合） 类似于关系数据库中的表，用于存储向量数据和相关的标量字段。
Field（字段） 集合中的列，包括向量字段和标量字段。
Entity（实体） 集合中的一行数据，包含多个字段的值。
Partition（分区） 集合的子集，用于数据分片和查询优化。
Index（索引） 为加速向量检索而构建的数据结构。
Segment（段） Milvus内部的数据存储单元，用于数据管理和查询优化。
数据类型 向量类型 FloatVector：浮点数向量 BinaryVector：二进制向量 标量类型 Bool：布尔值 Int8/Int16/Int32/Int64：整数 Float/Double：浮点数 String/VarChar：字符串 JSON：JSON对象 3. 安装部署 系统要求 硬件要求 CPU：x86_64架构，支持SSE4.2指令集 内存：8GB以上（推荐16GB+） 存储：SSD硬盘（推荐NVMe） 网络：千兆网卡 软件要求 操作系统：Ubuntu 18.04+、CentOS 7+、macOS 10.14+ Docker：20.10+ Docker Compose：1.28+ Docker安装（推荐） 1. 下载配置文件 # 下载docker-compose.yml wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml 2. 启动Milvus # 启动服务 docker-compose up -d # 检查服务状态 docker-compose ps 3. 验证安装 # 检查Milvus是否正常运行 curl -X GET "http://localhost:9091/health" Kubernetes部署 1. 安装Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash 2. 添加Milvus Helm仓库 helm repo add milvus https://milvus-io.github.io/milvus-helm/ helm repo update 3. 部署Milvus # 创建命名空间 kubectl create namespace milvus # 部署Milvus集群 helm install milvus milvus/milvus --namespace milvus 源码编译安装 1. 安装依赖 # Ubuntu/Debian sudo apt update sudo apt install -y build-essential cmake libopenblas-dev # CentOS/RHEL sudo yum groupinstall -y "Development Tools" sudo yum install -y cmake openblas-devel 2. 编译安装 # 克隆源码 git clone https://github.com/milvus-io/milvus.git cd milvus # 编译 make build # 启动 ./bin/milvus run standalone 4. 快速开始 安装Python SDK pip install pymilvus 基本操作示例 1. 连接Milvus from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType # 连接到Milvus connections.connect( alias="default", host=&#39;localhost&#39;, port=&#39;19530&#39; ) print("Connected to Milvus") 2. 创建集合 # 定义字段 fields = [ FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False), FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200), FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50) ] # 创建集合schema schema = CollectionSchema( fields=fields, description="Document embedding collection" ) # 创建集合 collection = Collection( name="documents", schema=schema ) print("Collection created") 3. 插入数据 import random # 准备数据 num_entities = 1000 entities = [ [i for i in range(num_entities)], # id字段 [[random.random() for _ in range(128)] for _ in range(num_entities)], # embedding字段 [f"Document {i}" for i in range(num_entities)], # title字段 [f"Category {i % 10}" for i in range(num_entities)] # category字段 ] # 插入数据 insert_result = collection.insert(entities) print(f"Inserted {len(insert_result.primary_keys)} entities") # 刷新数据到磁盘 collection.flush() 4. 创建索引 # 定义索引参数 index_params = { "metric_type": "L2", "index_type": "IVF_FLAT", "params": {"nlist": 128} } # 创建索引 collection.create_index( field_name="embedding", index_params=index_params ) print("Index created") 5. 加载集合 # 加载集合到内存 collection.load() print("Collection loaded") 6. 向量检索 # 准备查询向量 query_vectors = [[random.random() for _ in range(128)]] # 执行搜索 search_params = {"metric_type": "L2", "params": {"nprobe": 10}} results = collection.search( data=query_vectors, anns_field="embedding", param=search_params, limit=10, output_fields=["title", "category"] ) # 输出结果 for hits in results: for hit in hits: print(f"ID: {hit.id}, Distance: {hit.distance}, Title: {hit.entity.get(&#39;title&#39;)}") 5. 数据管理 集合管理 创建集合 from pymilvus import Collection, FieldSchema, CollectionSchema, DataType # 定义复杂schema fields = [ FieldSchema(name="id", dtype=DataType.INT64, is_primary=True), FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000), FieldSchema(name="score", dtype=DataType.FLOAT), FieldSchema(name="timestamp", dtype=DataType.INT64), FieldSchema(name="metadata", dtype=DataType.JSON) ] schema = CollectionSchema( fields=fields, description="Advanced collection with multiple field types", enable_dynamic_field=True # 启用动态字段 ) collection = Collection(name="advanced_collection", schema=schema) 查看集合信息 # 获取集合统计信息 stats = collection.get_stats() print(f"Collection stats: {stats}") # 获取集合schema schema = collection.schema for field in schema.fields: print(f"Field: {field.name}, Type: {field.dtype}, Params: {field.params}") # 检查集合是否存在 from pymilvus import utility has_collection = utility.has_collection("advanced_collection") print(f"Collection exists: {has_collection}") 删除集合 # 删除集合 collection.drop() # 或者使用utility函数 utility.drop_collection("collection_name") 分区管理 创建分区 # 创建分区 collection.create_partition("partition_2023") collection.create_partition("partition_2024") # 查看所有分区 partitions = collection.partitions for partition in partitions: print(f"Partition: {partition.name}") 分区数据操作 # 向特定分区插入数据 entities = [ [1, 2, 3], # ids [[0.1] * 256, [0.2] * 256, [0.3] * 256], # vectors ["text1", "text2", "text3"], # text [0.8, 0.9, 0.7], # scores [1640995200, 1640995300, 1640995400], # timestamps [{"key": "value1"}, {"key": "value2"}, {"key": "value3"}] # metadata ] collection.insert(entities, partition_name="partition_2023") # 在特定分区中搜索 results = collection.search( data=[[0.1] * 256], anns_field="vector", param={"metric_type": "L2", "params": {"nprobe": 10}}, limit=10, partition_names=["partition_2023"] ) 数据插入和更新 批量插入 import numpy as np # 大批量数据插入 batch_size = 10000 for i in range(0, 100000, batch_size): ids = list(range(i, min(i + batch_size, 100000))) vectors = np.random.random((len(ids), 256)).tolist() texts = [f"Document {j}" for j in ids] scores = np.random.random(len(ids)).tolist() timestamps = [1640995200 + j for j in ids] metadata = [{"batch": i // batch_size} for _ in ids] entities = [ids, vectors, texts, scores, timestamps, metadata] collection.insert(entities) if i % 50000 == 0: collection.flush() # 定期刷新 print(f"Inserted {i + len(ids)} entities") 数据更新（Upsert） # Milvus 2.3+支持upsert操作 update_entities = [ [1, 2, 3], # 更新已存在的ID [[0.5] * 256, [0.6] * 256, [0.7] * 256], # 新的向量 ["Updated text1", "Updated text2", "Updated text3"], # 新的文本 [0.95, 0.96, 0.97], # 新的分数 [1640995500, 1640995600, 1640995700], # 新的时间戳 [{"updated": True}, {"updated": True}, {"updated": True}] # 新的元数据 ] collection.upsert(update_entities) 数据删除 按ID删除 # 删除指定ID的实体 delete_ids = [1, 2, 3, 4, 5] expr = f"id in {delete_ids}" collection.delete(expr) # 删除满足条件的实体 expr = "score < 0.5" collection.delete(expr) 按条件删除 # 复杂删除条件 expr = "score < 0.3 and timestamp < 1640995300" collection.delete(expr) # 使用JSON字段删除 expr = "JSON_CONTAINS(metadata, &#39;\"updated\": true&#39;)" collection.delete(expr) 6. 向量检索 基本检索 相似性搜索 # 基本向量搜索 query_vectors = [[0.1] * 256, [0.2] * 256] search_params = { "metric_type": "L2", "params": {"nprobe": 16} } results = collection.search( data=query_vectors, anns_field="vector", param=search_params, limit=10, output_fields=["text", "score", "timestamp"] ) for i, hits in enumerate(results): print(f"Query {i} results:") for hit in hits: print(f" ID: {hit.id}, Distance: {hit.distance:.4f}") print(f" Text: {hit.entity.get(&#39;text&#39;)}") print(f" Score: {hit.entity.get(&#39;score&#39;)}") 混合搜索 # 向量搜索 + 标量过滤 query_vectors = [[0.1] * 256] search_params = {"metric_type": "L2", "params": {"nprobe": 16}} # 添加标量过滤条件 filter_expr = "score > 0.8 and timestamp > 1640995200" results = collection.search( data=query_vectors, anns_field="vector", param=search_params, limit=10, expr=filter_expr, output_fields=["text", "score", "timestamp", "metadata"] ) 高级检索 范围搜索 # 搜索距离在指定范围内的向量 from pymilvus import SearchResult query_vectors = [[0.1] * 256] search_params = { "metric_type": "L2", "params": { "nprobe": 16, "radius": 0.1, # 最大距离 "range_filter": 0.05 # 最小距离 } } results = collection.search( data=query_vectors, anns_field="vector", param=search_params, limit=100, output_fields=["text", "score"] ) 多向量搜索 # 同时搜索多个向量字段（如果集合有多个向量字段） # 假设有text_vector和image_vector两个字段 # 创建包含多个向量字段的集合 multi_vector_fields = [ FieldSchema(name="id", dtype=DataType.INT64, is_primary=True), FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200) ] multi_schema = CollectionSchema(fields=multi_vector_fields) multi_collection = Collection(name="multi_vector_collection", schema=multi_schema) # 分别在不同向量字段上搜索 text_results = multi_collection.search( data=[[0.1] * 128], anns_field="text_vector", param={"metric_type": "L2", "params": {"nprobe": 16}}, limit=10 ) image_results = multi_collection.search( data=[[0.1] * 256], anns_field="image_vector", param={"metric_type": "L2", "params": {"nprobe": 16}}, limit=10 ) 查询操作 标量查询 # 基于标量字段的查询 query_expr = "score > 0.8" results = collection.query( expr=query_expr, output_fields=["id", "text", "score", "timestamp"] ) for result in results: print(f"ID: {result[&#39;id&#39;]}, Text: {result[&#39;text&#39;]}, Score: {result[&#39;score&#39;]}") 复杂查询 # 复杂查询表达式 complex_expr = """ (score > 0.8 and timestamp > 1640995200) or (score > 0.9 and JSON_CONTAINS(metadata, &#39;"important": true&#39;)) """ results = collection.query( expr=complex_expr, output_fields=["*"], # 输出所有字段 limit=100 ) 分页查询 # 分页查询大量数据 page_size = 1000 offset = 0 while True: results = collection.query( expr="score > 0.5", output_fields=["id", "text", "score"], limit=page_size, offset=offset ) if not results: break print(f"Page {offset // page_size + 1}: {len(results)} results") # 处理结果 for result in results: # 处理每个结果 pass offset += page_size 7. 索引管理 索引类型 FLAT索引 # FLAT索引 - 精确搜索，适合小数据集 flat_index = { "index_type": "FLAT", "metric_type": "L2", "params": {} } collection.create_index( field_name="vector", index_params=flat_index ) IVF索引 # IVF_FLAT索引 - 平衡性能和精度 ivf_flat_index = { "index_type": "IVF_FLAT", "metric_type": "L2", "params": { "nlist": 128 # 聚类中心数量 } } # IVF_PQ索引 - 压缩存储，适合大数据集 ivf_pq_index = { "index_type": "IVF_PQ", "metric_type": "L2", "params": { "nlist": 128, "m": 16, # PQ分段数 "nbits": 8 # 每段的位数 } } collection.create_index(field_name="vector", index_params=ivf_pq_index) HNSW索引 # HNSW索引 - 高性能近似搜索 hnsw_index = { "index_type": "HNSW", "metric_type": "L2", "params": { "M": 16, # 每层的最大连接数 "efConstruction": 200 # 构建时的搜索深度 } } collection.create_index(field_name="vector", index_params=hnsw_index) ANNOY索引 # ANNOY索引 - 内存友好 annoy_index = { "index_type": "ANNOY", "metric_type": "L2", "params": { "n_trees": 8 # 树的数量 } } collection.create_index(field_name="vector", index_params=annoy_index) 距离度量 欧几里得距离（L2） l2_index = { "index_type": "IVF_FLAT", "metric_type": "L2", # 欧几里得距离 "params": {"nlist": 128} } 内积（IP） ip_index = { "index_type": "IVF_FLAT", "metric_type": "IP", # 内积 "params": {"nlist": 128} } 余弦相似度 # 余弦相似度需要先归一化向量，然后使用IP import numpy as np def normalize_vectors(vectors): """归一化向量以使用余弦相似度""" vectors = np.array(vectors) norms = np.linalg.norm(vectors, axis=1, keepdims=True) return (vectors / norms).tolist() # 插入归一化后的向量 normalized_vectors = normalize_vectors(original_vectors) entities = [ids, normalized_vectors, texts, scores, timestamps, metadata] collection.insert(entities) # 使用IP度量进行余弦相似度搜索 cosine_index = { "index_type": "IVF_FLAT", "metric_type": "IP", "params": {"nlist": 128} } 索引管理操作 查看索引信息 # 获取索引信息 index_info = collection.index() print(f"Index type: {index_info.params[&#39;index_type&#39;]}") print(f"Metric type: {index_info.params[&#39;metric_type&#39;]}") print(f"Index params: {index_info.params[&#39;params&#39;]}") # 检查索引构建进度 from pymilvus import utility index_progress = utility.index_building_progress("collection_name") print(f"Index building progress: {index_progress}") 重建索引 # 删除现有索引 collection.drop_index() # 创建新索引 new_index = { "index_type": "HNSW", "metric_type": "L2", "params": {"M": 32, "efConstruction": 400} } collection.create_index(field_name="vector", index_params=new_index) # 等待索引构建完成 import time while True: progress = utility.index_building_progress(collection.name) if progress[&#39;pending_index_rows&#39;] == 0: break print(f"Index building progress: {progress}") time.sleep(5) print("Index building completed") 8. 性能优化 搜索参数优化 IVF索引优化 # 根据数据量调整nlist data_size = collection.num_entities optimal_nlist = int(np.sqrt(data_size)) optimal_nlist = max(128, min(optimal_nlist, 4096)) # 限制在合理范围内 # 搜索时调整nprobe search_params = { "metric_type": "L2", "params": { "nprobe": min(optimal_nlist // 4, 64) # 通常设置为nlist的1/4 } } HNSW索引优化 # 构建时参数 hnsw_build_params = { "index_type": "HNSW", "metric_type": "L2", "params": { "M": 16, # 连接数，影响精度和内存 "efConstruction": 200 # 构建时搜索深度 } } # 搜索时参数 hnsw_search_params = { "metric_type": "L2", "params": { "ef": 100 # 搜索时的候选数量，越大精度越高但速度越慢 } } 内存管理 集合加载策略 # 部分加载 - 只加载需要的字段 collection.load(replica_number=1, _resource_groups=["default"]) # 释放不需要的集合 collection.release() # 检查内存使用 from pymilvus import utility memory_info = utility.get_query_segment_info(collection.name) for info in memory_info: print(f"Segment {info.segmentID}: {info.mem_size} bytes") 分区加载 # 只加载特定分区 collection.load(partition_names=["partition_2024"]) # 动态加载/释放分区 def load_partition_by_date(date_str): partition_name = f"partition_{date_str}" if partition_name in [p.name for p in collection.partitions]: collection.load(partition_names=[partition_name]) return True return False def release_old_partitions(keep_days=7): from datetime import datetime, timedelta cutoff_date = datetime.now() - timedelta(days=keep_days) for partition in collection.partitions: if partition.name.startswith("partition_"): date_str = partition.name.replace("partition_", "") try: partition_date = datetime.strptime(date_str, "%Y%m%d") if partition_date < cutoff_date: collection.release(partition_names=[partition.name]) print(f"Released partition: {partition.name}") except ValueError: continue 批处理优化 批量插入优化 def optimized_batch_insert(collection, data, batch_size=10000): """优化的批量插入函数""" total_entities = len(data[0]) for i in range(0, total_entities, batch_size): end_idx = min(i + batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] # 插入批次 collection.insert(batch_data) # 定期刷新 if (i + batch_size) % 50000 == 0: collection.flush() print(f"Inserted and flushed {i + batch_size} entities") # 最终刷新 collection.flush() print(f"Completed insertion of {total_entities} entities") 并行搜索 import concurrent.futures import threading def parallel_search(collection, query_vectors, search_params, max_workers=4): """并行执行多个搜索请求""" def search_batch(vectors_batch): return collection.search( data=vectors_batch, anns_field="vector", param=search_params, limit=10 ) # 将查询向量分批 batch_size = len(query_vectors) // max_workers batches = [query_vectors[i:i+batch_size] for i in range(0, len(query_vectors), batch_size)] # 并行执行搜索 with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: future_to_batch = {executor.submit(search_batch, batch): batch for batch in batches} all_results = [] for future in concurrent.futures.as_completed(future_to_batch): batch_results = future.result() all_results.extend(batch_results) return all_results 连接池管理 from pymilvus import connections import threading class MilvusConnectionPool: def __init__(self, host=&#39;localhost&#39;, port=&#39;19530&#39;, pool_size=10): self.host = host self.port = port self.pool_size = pool_size self.connections = [] self.lock = threading.Lock() self._initialize_pool() def _initialize_pool(self): for i in range(self.pool_size): alias = f"connection_{i}" connections.connect( alias=alias, host=self.host, port=self.port ) self.connections.append(alias) def get_connection(self): with self.lock: if self.connections: return self.connections.pop() else: # 如果池为空，创建新连接 alias = f"temp_connection_{threading.current_thread().ident}" connections.connect( alias=alias, host=self.host, port=self.port ) return alias def return_connection(self, alias): with self.lock: if len(self.connections) < self.pool_size: self.connections.append(alias) else: connections.disconnect(alias) # 使用连接池 pool = MilvusConnectionPool() def search_with_pool(query_vector): alias = pool.get_connection() try: # 使用指定连接执行搜索 connections.connect(alias=alias) collection = Collection("documents", using=alias) results = collection.search( data=[query_vector], anns_field="vector", param={"metric_type": "L2", "params": {"nprobe": 16}}, limit=10 ) return results finally: pool.return_connection(alias) 9. 集群部署 Kubernetes集群部署 1. 准备配置文件 # milvus-cluster-values.yaml cluster: enabled: true image: all: repository: milvusdb/milvus tag: v2.3.0 pullPolicy: IfNotPresent service: type: LoadBalancer port: 19530 portName: milvus nodePort: 30530 rootCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryNode: replicas: 2 resources: limits: cpu: 2 memory: 8Gi requests: cpu: 1 memory: 4Gi indexNode: replicas: 1 resources: limits: cpu: 2 memory: 4Gi requests: cpu: 1 memory: 2Gi dataNode: replicas: 2 resources: limits: cpu: 1 memory: 4Gi requests: cpu: 0.5 memory: 2Gi proxy: replicas: 2 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi # 存储配置 minio: enabled: true mode: distributed replicas: 4 persistence: enabled: true size: 100Gi storageClass: "fast-ssd" etcd: enabled: true replicaCount: 3 persistence: enabled: true size: 10Gi storageClass: "fast-ssd" pulsar: enabled: true components: broker: true bookkeeper: true zookeeper: true zookeeper: replicaCount: 3 bookkeeper: replicaCount: 3 broker: replicaCount: 2 2. 部署集群 # 创建命名空间 kubectl create namespace milvus-cluster # 部署Milvus集群 helm install milvus-cluster milvus/milvus \ --namespace milvus-cluster \ --values milvus-cluster-values.yaml # 检查部署状态 kubectl get pods -n milvus-cluster kubectl get services -n milvus-cluster 3. 配置负载均衡 # milvus-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: milvus-ingress namespace: milvus-cluster annotations: nginx.ingress.kubernetes.io/backend-protocol: "GRPC" nginx.ingress.kubernetes.io/grpc-backend: "true" spec: ingressClassName: nginx rules: - host: milvus.example.com http: paths: - path: / pathType: Prefix backend: service: name: milvus-cluster port: number: 19530 高可用配置 多副本配置 # 连接到集群 connections.connect( alias="cluster", host=&#39;milvus.example.com&#39;, port=&#39;19530&#39; ) # 创建集合时指定副本数 collection = Collection("ha_collection", schema=schema) collection.create_index(field_name="vector", index_params=index_params) # 加载时指定副本数 collection.load(replica_number=2) # 检查副本状态 from pymilvus import utility replica_info = utility.get_replicas(collection.name) for replica in replica_info: print(f"Replica {replica.id}: {replica.node_ids}") 故障转移测试 def test_failover(collection): """测试故障转移能力""" import time import random query_vector = [random.random() for _ in range(256)] # 持续查询测试 success_count = 0 total_count = 0 for i in range(100): try: results = collection.search( data=[query_vector], anns_field="vector", param={"metric_type": "L2", "params": {"nprobe": 16}}, limit=10 ) success_count += 1 print(f"Query {i}: Success") except Exception as e: print(f"Query {i}: Failed - {e}") total_count += 1 time.sleep(1) print(f"Success rate: {success_count/total_count*100:.2f}%") 数据分片策略 基于时间的分片 from datetime import datetime, timedelta def create_time_based_partitions(collection, start_date, end_date): """创建基于时间的分区""" current_date = start_date while current_date <= end_date: partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}" try: collection.create_partition(partition_name) print(f"Created partition: {partition_name}") except Exception as e: print(f"Partition {partition_name} already exists or error: {e}") current_date += timedelta(days=1) def insert_with_time_partition(collection, entities, timestamp_field_idx=4): """根据时间戳插入到对应分区""" # 按时间戳分组数据 partition_data = {} for i, timestamp in enumerate(entities[timestamp_field_idx]): date_str = datetime.fromtimestamp(timestamp).strftime(&#39;%Y%m%d&#39;) partition_name = f"partition_{date_str}" if partition_name not in partition_data: partition_data[partition_name] = [[] for _ in entities] for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 分别插入到各个分区 for partition_name, partition_entities in partition_data.items(): try: collection.insert(partition_entities, partition_name=partition_name) print(f"Inserted {len(partition_entities[0])} entities to {partition_name}") except Exception as e: print(f"Failed to insert to {partition_name}: {e}") 基于哈希的分片 import hashlib def create_hash_based_partitions(collection, num_partitions=8): """创建基于哈希的分区""" for i in range(num_partitions): partition_name = f"partition_hash_{i}" try: collection.create_partition(partition_name) print(f"Created partition: {partition_name}") except Exception as e: print(f"Partition {partition_name} already exists or error: {e}") def insert_with_hash_partition(collection, entities, key_field_idx=0, num_partitions=8): """根据键值哈希插入到对应分区""" partition_data = {f"partition_hash_{i}": [[] for _ in entities] for i in range(num_partitions)} for i, key in enumerate(entities[key_field_idx]): # 计算哈希值确定分区 hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16) partition_idx = hash_value % num_partitions partition_name = f"partition_hash_{partition_idx}" for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 插入到各个分区 for partition_name, partition_entities in partition_data.items(): if partition_entities[0]: # 如果分区有数据 collection.insert(partition_entities, partition_name=partition_name) print(f"Inserted {len(partition_entities[0])} entities to {partition_name}") 10. 监控运维 系统监控 Prometheus监控配置 # prometheus-config.yaml global: scrape_interval: 15s scrape_configs: - job_name: &#39;milvus&#39; static_configs: - targets: [&#39;milvus:9091&#39;] metrics_path: /metrics scrape_interval: 15s - job_name: &#39;milvus-cluster&#39; kubernetes_sd_configs: - role: pod namespaces: names: - milvus-cluster relabel_configs: - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name] action: keep regex: milvus - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port] action: replace target_label: __address__ regex: (.+) replacement: ${1}:9091 Grafana仪表板 { "dashboard": { "title": "Milvus Monitoring", "panels": [ { "title": "QPS (Queries Per Second)", "type": "graph", "targets": [ { "expr": "rate(milvus_proxy_search_vectors_count[5m])", "legendFormat": "Search QPS" }, { "expr": "rate(milvus_proxy_insert_vectors_count[5m])", "legendFormat": "Insert QPS" } ] }, { "title": "Response Time", "type": "graph", "targets": [ { "expr": "histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))", "legendFormat": "Search P95 Latency" }, { "expr": "histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))", "legendFormat": "Search P99 Latency" } ] }, { "title": "Memory Usage", "type": "graph", "targets": [ { "expr": "milvus_querynode_memory_usage_bytes", "legendFormat": "QueryNode Memory" }, { "expr": "milvus_indexnode_memory_usage_bytes", "legendFormat": "IndexNode Memory" } ] }, { "title": "Collection Statistics", "type": "table", "targets": [ { "expr": "milvus_collection_num_entities", "format": "table" } ] } ] } } 性能监控 自定义监控脚本 import time import psutil import threading from pymilvus import connections, Collection, utility from datetime import datetime class MilvusMonitor: def __init__(self, collection_name, interval=60): self.collection_name = collection_name self.interval = interval self.running = False self.metrics = [] def start_monitoring(self): self.running = True monitor_thread = threading.Thread(target=self._monitor_loop) monitor_thread.daemon = True monitor_thread.start() def stop_monitoring(self): self.running = False def _monitor_loop(self): while self.running: try: metrics = self._collect_metrics() self.metrics.append(metrics) print(f"[{metrics[&#39;timestamp&#39;]}] {metrics}") # 保留最近1000条记录 if len(self.metrics) > 1000: self.metrics = self.metrics[-1000:] except Exception as e: print(f"Monitoring error: {e}") time.sleep(self.interval) def _collect_metrics(self): collection = Collection(self.collection_name) # 集合统计信息 stats = collection.get_stats() num_entities = int(stats[&#39;row_count&#39;]) # 系统资源 cpu_percent = psutil.cpu_percent() memory = psutil.virtual_memory() disk = psutil.disk_usage(&#39;/&#39;) # 查询性能测试 start_time = time.time() try: test_vector = [0.1] * 256 collection.search( data=[test_vector], anns_field="vector", param={"metric_type": "L2", "params": {"nprobe": 16}}, limit=10 ) query_latency = (time.time() - start_time) * 1000 # ms except Exception as e: query_latency = -1 return { &#39;timestamp&#39;: datetime.now().isoformat(), &#39;collection_entities&#39;: num_entities, &#39;cpu_percent&#39;: cpu_percent, &#39;memory_percent&#39;: memory.percent, &#39;memory_used_gb&#39;: memory.used / (1024**3), &#39;disk_percent&#39;: disk.percent, &#39;disk_used_gb&#39;: disk.used / (1024**3), &#39;query_latency_ms&#39;: query_latency } def get_metrics_summary(self, last_n=100): """获取最近N条记录的统计摘要""" if not self.metrics: return None recent_metrics = self.metrics[-last_n:] latencies = [m[&#39;query_latency_ms&#39;] for m in recent_metrics if m[&#39;query_latency_ms&#39;] > 0] cpu_usage = [m[&#39;cpu_percent&#39;] for m in recent_metrics] memory_usage = [m[&#39;memory_percent&#39;] for m in recent_metrics] return { &#39;avg_query_latency_ms&#39;: sum(latencies) / len(latencies) if latencies else 0, &#39;max_query_latency_ms&#39;: max(latencies) if latencies else 0, &#39;avg_cpu_percent&#39;: sum(cpu_usage) / len(cpu_usage), &#39;max_cpu_percent&#39;: max(cpu_usage), &#39;avg_memory_percent&#39;: sum(memory_usage) / len(memory_usage), &#39;max_memory_percent&#39;: max(memory_usage), &#39;total_entities&#39;: recent_metrics[-1][&#39;collection_entities&#39;] if recent_metrics else 0 } # 使用监控器 monitor = MilvusMonitor("documents", interval=30) monitor.start_monitoring() # 运行一段时间后查看摘要 time.sleep(300) # 5分钟 summary = monitor.get_metrics_summary() print(f"Performance Summary: {summary}") monitor.stop_monitoring() 日志管理 日志配置 # milvus-log-config.yaml log: level: info file: rootPath: "/var/log/milvus" maxSize: 100 # MB maxAge: 7 # days maxBackups: 10 format: json # 在Kubernetes中配置日志收集 apiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: milvus-cluster data: fluent-bit.conf: | [SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf [INPUT] Name tail Path /var/log/milvus/*.log Parser json Tag milvus.* Refresh_Interval 5 [OUTPUT] Name es Match milvus.* Host elasticsearch.logging.svc.cluster.local Port 9200 Index milvus-logs Type _doc 日志分析脚本 import json import re from datetime import datetime, timedelta from collections import defaultdict def analyze_milvus_logs(log_file_path, hours=24): """分析Milvus日志文件""" cutoff_time = datetime.now() - timedelta(hours=hours) error_counts = defaultdict(int) warning_counts = defaultdict(int) performance_metrics = [] with open(log_file_path, &#39;r&#39;) as f: for line in f: try: log_entry = json.loads(line.strip()) log_time = datetime.fromisoformat(log_entry.get(&#39;time&#39;, &#39;&#39;).replace(&#39;Z&#39;, &#39;+00:00&#39;)) if log_time < cutoff_time: continue level = log_entry.get(&#39;level&#39;, &#39;&#39;).upper() message = log_entry.get(&#39;msg&#39;, &#39;&#39;) # 统计错误和警告 if level == &#39;ERROR&#39;: error_counts[message] += 1 elif level == &#39;WARN&#39;: warning_counts[message] += 1 # 提取性能指标 if &#39;latency&#39; in message.lower(): latency_match = re.search(r&#39;latency[:\s]+(\d+(?:\.\d+)?)\s*(ms|μs)&#39;, message) if latency_match: latency_value = float(latency_match.group(1)) latency_unit = latency_match.group(2) if latency_unit == &#39;μs&#39;: latency_value /= 1000 # 转换为ms performance_metrics.append({ &#39;timestamp&#39;: log_time, &#39;latency_ms&#39;: latency_value, &#39;operation&#39;: extract_operation(message) }) except (json.JSONDecodeError, ValueError) as e: continue return { &#39;error_summary&#39;: dict(error_counts), &#39;warning_summary&#39;: dict(warning_counts), &#39;performance_metrics&#39;: performance_metrics } def extract_operation(message): """从日志消息中提取操作类型""" if &#39;search&#39; in message.lower(): return &#39;search&#39; elif &#39;insert&#39; in message.lower(): return &#39;insert&#39; elif &#39;index&#39; in message.lower(): return &#39;index&#39; else: return &#39;unknown&#39; def generate_log_report(analysis_result): """生成日志分析报告""" print("=== Milvus Log Analysis Report ===") print(f"Analysis time: {datetime.now()}") print() # 错误摘要 print("Top Errors:") sorted_errors = sorted(analysis_result[&#39;error_summary&#39;].items(), key=lambda x: x[1], reverse=True) for error, count in sorted_errors[:10]: print(f" {count:4d} - {error[:100]}...") print() # 警告摘要 print("Top Warnings:") sorted_warnings = sorted(analysis_result[&#39;warning_summary&#39;].items(), key=lambda x: x[1], reverse=True) for warning, count in sorted_warnings[:10]: print(f" {count:4d} - {warning[:100]}...") print() # 性能摘要 metrics = analysis_result[&#39;performance_metrics&#39;] if metrics: latencies = [m[&#39;latency_ms&#39;] for m in metrics] print("Performance Summary:") print(f" Total operations: {len(metrics)}") print(f" Average latency: {sum(latencies)/len(latencies):.2f} ms") print(f" Max latency: {max(latencies):.2f} ms") print(f" Min latency: {min(latencies):.2f} ms") # 按操作类型分组 by_operation = defaultdict(list) for metric in metrics: by_operation[metric[&#39;operation&#39;]].append(metric[&#39;latency_ms&#39;]) print("\nPerformance by Operation:") for operation, latencies in by_operation.items(): if latencies: avg_latency = sum(latencies) / len(latencies) print(f" {operation.capitalize()}:") print(f" Count: {len(latencies)}") print(f" Avg latency: {avg_latency:.2f} ms") print(f" Max latency: {max(latencies):.2f} ms") else: print("No performance metrics found.") # 使用示例 if __name__ == "__main__": log_file = "/path/to/milvus.log" result = analyze_milvus_logs(log_file, hours=24) generate_log_report(result) 11. 最佳实践 1. 数据建模最佳实践 Collection设计原则 # 良好的Collection设计示例 def create_production_collection(name, vector_dim, expected_size): """生产环境Collection设计""" # 根据数据规模选择分片数 shard_num = min(max(expected_size // 1000000, 2), 16) fields = [ # 主键字段 - 使用有意义的ID FieldSchema( name="id", dtype=DataType.INT64, is_primary=True, auto_id=False, description="Document unique identifier" ), # 时间戳字段 - 便于数据管理 FieldSchema( name="created_at", dtype=DataType.INT64, description="Creation timestamp" ), # 分类字段 - 用于过滤 FieldSchema( name="category", dtype=DataType.VARCHAR, max_length=50, description="Document category" ), # 向量字段 - 核心搜索字段 FieldSchema( name="embedding", dtype=DataType.FLOAT_VECTOR, dim=vector_dim, description="Document embedding vector" ), # 元数据字段 - 存储额外信息 FieldSchema( name="metadata", dtype=DataType.JSON, description="Additional metadata" ) ] schema = CollectionSchema( fields=fields, description=f"Production collection for {expected_size} documents", enable_dynamic_field=True # 允许动态字段 ) collection = Collection( name=name, schema=schema, shards_num=shard_num, consistency_level="Strong" # 生产环境建议强一致性 ) return collection 分区策略 # 基于时间的分区策略 def create_time_based_partitions(collection, start_date, end_date): """创建基于时间的分区""" from datetime import datetime, timedelta current_date = start_date while current_date <= end_date: partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}" try: collection.create_partition(partition_name) print(f"Created partition: {partition_name}") except Exception as e: print(f"Partition {partition_name} already exists or error: {e}") current_date += timedelta(days=1) # 基于类别的分区策略 def create_category_partitions(collection, categories): """创建基于类别的分区""" for category in categories: partition_name = f"category_{category.lower()}" try: collection.create_partition(partition_name) print(f"Created partition: {partition_name}") except Exception as e: print(f"Partition {partition_name} already exists or error: {e}") 2. 性能优化最佳实践 索引选择策略 def choose_optimal_index(data_size, memory_budget, latency_requirement, accuracy_requirement): """根据需求选择最优索引""" if data_size < 100000: # 小数据集使用FLAT return { "index_type": "FLAT", "metric_type": "L2", "params": {} } elif latency_requirement == "ultra_low" and memory_budget == "high": # 超低延迟需求使用HNSW return { "index_type": "HNSW", "metric_type": "L2", "params": { "M": 32, "efConstruction": 400 } } elif memory_budget == "low": # 内存受限使用PQ压缩 return { "index_type": "IVF_PQ", "metric_type": "L2", "params": { "nlist": min(4 * int(np.sqrt(data_size)), 4096), "m": 16, "nbits": 8 } } else: # 平衡选择IVF_FLAT return { "index_type": "IVF_FLAT", "metric_type": "L2", "params": { "nlist": min(4 * int(np.sqrt(data_size)), 4096) } } # 动态调整搜索参数 def get_adaptive_search_params(index_type, accuracy_level="medium", data_size=None): """根据索引类型和精度要求动态调整搜索参数""" if index_type == "IVF_FLAT" or index_type == "IVF_PQ": nprobe_map = { "low": max(8, int(np.sqrt(data_size)) // 100) if data_size else 8, "medium": max(16, int(np.sqrt(data_size)) // 50) if data_size else 16, "high": max(32, int(np.sqrt(data_size)) // 25) if data_size else 32 } return {"nprobe": nprobe_map[accuracy_level]} elif index_type == "HNSW": ef_map = {"low": 64, "medium": 128, "high": 256} return {"ef": ef_map[accuracy_level]} elif index_type == "ANNOY": search_k_map = {"low": 100, "medium": 200, "high": 400} return {"search_k": search_k_map[accuracy_level]} return {} 批处理优化 class OptimizedBatchProcessor: """优化的批处理器""" def __init__(self, collection, batch_size=10000, flush_interval=50000): self.collection = collection self.batch_size = batch_size self.flush_interval = flush_interval self.total_inserted = 0 def insert_batch(self, data): """批量插入数据""" total_entities = len(data[0]) for i in range(0, total_entities, self.batch_size): end_idx = min(i + self.batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] try: result = self.collection.insert(batch_data) self.total_inserted += len(result.primary_keys) # 定期刷新 if self.total_inserted % self.flush_interval == 0: self.collection.flush() print(f"Flushed after inserting {self.total_inserted} entities") except Exception as e: print(f"Error inserting batch {i//self.batch_size}: {e}") continue # 最终刷新 self.collection.flush() return self.total_inserted def parallel_search(self, query_vectors, search_params, max_workers=4): """并行搜索""" import concurrent.futures def search_single(query_vector): return self.collection.search( data=[query_vector], anns_field="embedding", param=search_params, limit=10 ) with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: futures = [executor.submit(search_single, qv) for qv in query_vectors] results = [future.result() for future in concurrent.futures.as_completed(futures)] return results 3. 数据质量最佳实践 向量预处理 import numpy as np from sklearn.preprocessing import normalize def preprocess_vectors(vectors, normalization="l2", dimension_check=True): """向量预处理管道""" vectors = np.array(vectors, dtype=np.float32) # 维度检查 if dimension_check and len(vectors.shape) != 2: raise ValueError(f"Expected 2D array, got {len(vectors.shape)}D") # 检查NaN和无穷值 if np.any(np.isnan(vectors)) or np.any(np.isinf(vectors)): print("Warning: Found NaN or infinite values, replacing with zeros") vectors = np.nan_to_num(vectors, nan=0.0, posinf=0.0, neginf=0.0) # 归一化 if normalization == "l2": vectors = normalize(vectors, norm=&#39;l2&#39;, axis=1) elif normalization == "minmax": from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() vectors = scaler.fit_transform(vectors) return vectors.tolist() # 数据验证 def validate_data_quality(data, schema): """验证数据质量""" issues = [] # 检查数据长度一致性 field_lengths = [len(field_data) for field_data in data] if len(set(field_lengths)) > 1: issues.append(f"Inconsistent field lengths: {field_lengths}") # 检查向量维度 for i, field in enumerate(schema.fields): if field.dtype == DataType.FLOAT_VECTOR: vectors = data[i] expected_dim = field.params.get(&#39;dim&#39;) for j, vector in enumerate(vectors[:100]): # 检查前100个 if len(vector) != expected_dim: issues.append(f"Vector {j} has dimension {len(vector)}, expected {expected_dim}") break return issues 4. 监控和运维最佳实践 健康检查系统 import time import logging from datetime import datetime class MilvusHealthMonitor: """Milvus健康监控系统""" def __init__(self, collection_names, alert_thresholds=None): self.collection_names = collection_names self.alert_thresholds = alert_thresholds or { &#39;query_latency&#39;: 1.0, # 秒 &#39;memory_usage&#39;: 0.8, # 80% &#39;error_rate&#39;: 0.05 # 5% } self.logger = self._setup_logger() def _setup_logger(self): logger = logging.getLogger(&#39;milvus_monitor&#39;) logger.setLevel(logging.INFO) handler = logging.FileHandler(&#39;milvus_health.log&#39;) formatter = logging.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;) handler.setFormatter(formatter) logger.addHandler(handler) return logger def check_connection_health(self): """检查连接健康状态""" try: from pymilvus import utility version = utility.get_server_version() self.logger.info(f"Milvus server version: {version}") return True except Exception as e: self.logger.error(f"Connection health check failed: {e}") return False def check_collection_health(self, collection_name): """检查集合健康状态""" try: collection = Collection(collection_name) # 检查集合状态 stats = collection.get_stats() num_entities = collection.num_entities # 执行测试查询 start_time = time.time() test_vector = [[0.1] * 128] # 假设128维向量 results = collection.search( data=test_vector, anns_field="embedding", param={"metric_type": "L2", "params": {"nprobe": 10}}, limit=1 ) query_latency = time.time() - start_time # 记录指标 metrics = { &#39;collection&#39;: collection_name, &#39;num_entities&#39;: num_entities, &#39;query_latency&#39;: query_latency, &#39;timestamp&#39;: datetime.now().isoformat() } self.logger.info(f"Collection health: {metrics}") # 检查告警阈值 if query_latency > self.alert_thresholds[&#39;query_latency&#39;]: self.logger.warning(f"High query latency: {query_latency:.3f}s") return metrics except Exception as e: self.logger.error(f"Collection health check failed for {collection_name}: {e}") return None def run_continuous_monitoring(self, interval=60): """持续监控""" while True: try: # 检查连接 if not self.check_connection_health(): self.logger.critical("Milvus connection lost!") # 检查所有集合 for collection_name in self.collection_names: self.check_collection_health(collection_name) time.sleep(interval) except KeyboardInterrupt: self.logger.info("Monitoring stopped by user") break except Exception as e: self.logger.error(f"Monitoring error: {e}") time.sleep(interval) 备份和恢复策略 import json import os from datetime import datetime class MilvusBackupManager: """Milvus备份管理器""" def __init__(self, backup_dir="./milvus_backups"): self.backup_dir = backup_dir os.makedirs(backup_dir, exist_ok=True) def backup_collection_metadata(self, collection_name): """备份集合元数据""" try: collection = Collection(collection_name) # 收集元数据 metadata = { &#39;name&#39;: collection.name, &#39;description&#39;: collection.description, &#39;schema&#39;: { &#39;fields&#39;: [ { &#39;name&#39;: field.name, &#39;dtype&#39;: str(field.dtype), &#39;params&#39;: field.params, &#39;is_primary&#39;: field.is_primary, &#39;auto_id&#39;: field.auto_id } for field in collection.schema.fields ], &#39;enable_dynamic_field&#39;: collection.schema.enable_dynamic_field }, &#39;num_entities&#39;: collection.num_entities, &#39;partitions&#39;: [p.name for p in collection.partitions], &#39;indexes&#39;: [] } # 获取索引信息 try: index_info = collection.index() if index_info: metadata[&#39;indexes&#39;].append({ &#39;field_name&#39;: &#39;embedding&#39;, # 假设向量字段名 &#39;index_params&#39;: index_info.params }) except: pass # 保存元数据 timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") backup_file = f"{self.backup_dir}/{collection_name}_metadata_{timestamp}.json" with open(backup_file, &#39;w&#39;) as f: json.dump(metadata, f, indent=2) print(f"Metadata backup saved: {backup_file}") return backup_file except Exception as e: print(f"Backup failed: {e}") return None def restore_collection_from_metadata(self, backup_file): """从元数据恢复集合结构""" try: with open(backup_file, &#39;r&#39;) as f: metadata = json.load(f) # 重建字段 fields = [] for field_info in metadata[&#39;schema&#39;][&#39;fields&#39;]: field = FieldSchema( name=field_info[&#39;name&#39;], dtype=getattr(DataType, field_info[&#39;dtype&#39;].split(&#39;.&#39;)[-1]), is_primary=field_info.get(&#39;is_primary&#39;, False), auto_id=field_info.get(&#39;auto_id&#39;, False), **field_info.get(&#39;params&#39;, {}) ) fields.append(field) # 重建schema schema = CollectionSchema( fields=fields, description=metadata[&#39;description&#39;], enable_dynamic_field=metadata[&#39;schema&#39;][&#39;enable_dynamic_field&#39;] ) # 创建集合 collection = Collection( name=metadata[&#39;name&#39;], schema=schema ) # 重建分区 for partition_name in metadata[&#39;partitions&#39;]: if partition_name != &#39;_default&#39;: collection.create_partition(partition_name) print(f"Collection {metadata[&#39;name&#39;]} restored from backup") return collection except Exception as e: print(f"Restore failed: {e}") return None 5. 安全最佳实践 访问控制 from pymilvus import connections # 安全连接配置 def secure_connect(host, port, username, password, secure=True): """安全连接到Milvus""" try: connections.connect( alias="secure_connection", host=host, port=port, user=username, password=password, secure=secure, server_pem_path="/path/to/server.pem", # TLS证书路径 server_name="milvus-server", timeout=30 ) print("Secure connection established") return True except Exception as e: print(f"Secure connection failed: {e}") return False # 输入验证 def validate_search_input(query_vectors, limit, expr=None): """验证搜索输入""" # 验证向量 if not isinstance(query_vectors, list) or not query_vectors: raise ValueError("Query vectors must be a non-empty list") # 验证limit if not isinstance(limit, int) or limit <= 0 or limit > 10000: raise ValueError("Limit must be a positive integer <= 10000") # 验证表达式（防止注入） if expr: dangerous_keywords = [&#39;DROP&#39;, &#39;DELETE&#39;, &#39;UPDATE&#39;, &#39;INSERT&#39;, &#39;CREATE&#39;] expr_upper = expr.upper() for keyword in dangerous_keywords: if keyword in expr_upper: raise ValueError(f"Dangerous keyword &#39;{keyword}&#39; found in expression") return True 12. 常见问题 Q1: 如何选择合适的索引类型？ A: 索引选择主要考虑以下因素：'><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-01T04:14:54-08:00"><meta property="article:modified_time" content="2024-01-01T04:14:54-08:00"><meta property="article:tag" content="Milvus"><meta property="article:tag" content="向量数据库"><meta property="article:tag" content="向量检索"><meta property="article:tag" content="分布式"><meta property="article:tag" content="搜索引擎"><meta name=twitter:card content="summary"><meta name=twitter:title content="Milvus使用指南"><meta name=twitter:description content='1. Milvus简介
什么是Milvus
Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。
主要特性

高性能：支持十亿级向量的毫秒级检索
多样化索引：支持多种向量索引算法（IVF、HNSW、ANNOY等）
云原生：基于Kubernetes的分布式架构
多语言SDK：支持Python、Java、Go、Node.js等
ACID事务：保证数据一致性
混合搜索：支持向量和标量数据的混合查询

应用场景

推荐系统：基于用户行为向量进行个性化推荐
图像检索：以图搜图、相似图片查找
文本搜索：语义搜索、文档相似性匹配
视频分析：视频内容检索和分析
药物发现：分子结构相似性搜索
异常检测：基于向量距离的异常识别

2. 核心概念
基本术语
Collection（集合）
类似于关系数据库中的表，用于存储向量数据和相关的标量字段。
Field（字段）
集合中的列，包括向量字段和标量字段。
Entity（实体）
集合中的一行数据，包含多个字段的值。
Partition（分区）
集合的子集，用于数据分片和查询优化。
Index（索引）
为加速向量检索而构建的数据结构。
Segment（段）
Milvus内部的数据存储单元，用于数据管理和查询优化。
数据类型
向量类型

FloatVector：浮点数向量
BinaryVector：二进制向量

标量类型

Bool：布尔值
Int8/Int16/Int32/Int64：整数
Float/Double：浮点数
String/VarChar：字符串
JSON：JSON对象

3. 安装部署
系统要求
硬件要求

CPU：x86_64架构，支持SSE4.2指令集
内存：8GB以上（推荐16GB+）
存储：SSD硬盘（推荐NVMe）
网络：千兆网卡

软件要求

操作系统：Ubuntu 18.04+、CentOS 7+、macOS 10.14+
Docker：20.10+
Docker Compose：1.28+

Docker安装（推荐）
1. 下载配置文件
# 下载docker-compose.yml
wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml
2. 启动Milvus
# 启动服务
docker-compose up -d

# 检查服务状态
docker-compose ps
3. 验证安装
# 检查Milvus是否正常运行
curl -X GET "http://localhost:9091/health"
Kubernetes部署
1. 安装Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
2. 添加Milvus Helm仓库
helm repo add milvus https://milvus-io.github.io/milvus-helm/
helm repo update
3. 部署Milvus
# 创建命名空间
kubectl create namespace milvus

# 部署Milvus集群
helm install milvus milvus/milvus --namespace milvus
源码编译安装
1. 安装依赖
# Ubuntu/Debian
sudo apt update
sudo apt install -y build-essential cmake libopenblas-dev

# CentOS/RHEL
sudo yum groupinstall -y "Development Tools"
sudo yum install -y cmake openblas-devel
2. 编译安装
# 克隆源码
git clone https://github.com/milvus-io/milvus.git
cd milvus

# 编译
make build

# 启动
./bin/milvus run standalone
4. 快速开始
安装Python SDK
pip install pymilvus
基本操作示例
1. 连接Milvus
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

# 连接到Milvus
connections.connect(
    alias="default",
    host=&#39;localhost&#39;,
    port=&#39;19530&#39;
)

print("Connected to Milvus")
2. 创建集合
# 定义字段
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128),
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200),
    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50)
]

# 创建集合schema
schema = CollectionSchema(
    fields=fields,
    description="Document embedding collection"
)

# 创建集合
collection = Collection(
    name="documents",
    schema=schema
)

print("Collection created")
3. 插入数据
import random

# 准备数据
num_entities = 1000
entities = [
    [i for i in range(num_entities)],  # id字段
    [[random.random() for _ in range(128)] for _ in range(num_entities)],  # embedding字段
    [f"Document {i}" for i in range(num_entities)],  # title字段
    [f"Category {i % 10}" for i in range(num_entities)]  # category字段
]

# 插入数据
insert_result = collection.insert(entities)
print(f"Inserted {len(insert_result.primary_keys)} entities")

# 刷新数据到磁盘
collection.flush()
4. 创建索引
# 定义索引参数
index_params = {
    "metric_type": "L2",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}
}

# 创建索引
collection.create_index(
    field_name="embedding",
    index_params=index_params
)

print("Index created")
5. 加载集合
# 加载集合到内存
collection.load()
print("Collection loaded")
6. 向量检索
# 准备查询向量
query_vectors = [[random.random() for _ in range(128)]]

# 执行搜索
search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
results = collection.search(
    data=query_vectors,
    anns_field="embedding",
    param=search_params,
    limit=10,
    output_fields=["title", "category"]
)

# 输出结果
for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Title: {hit.entity.get(&#39;title&#39;)}")
5. 数据管理
集合管理
创建集合
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义复杂schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=256),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="score", dtype=DataType.FLOAT),
    FieldSchema(name="timestamp", dtype=DataType.INT64),
    FieldSchema(name="metadata", dtype=DataType.JSON)
]

schema = CollectionSchema(
    fields=fields,
    description="Advanced collection with multiple field types",
    enable_dynamic_field=True  # 启用动态字段
)

collection = Collection(name="advanced_collection", schema=schema)
查看集合信息
# 获取集合统计信息
stats = collection.get_stats()
print(f"Collection stats: {stats}")

# 获取集合schema
schema = collection.schema
for field in schema.fields:
    print(f"Field: {field.name}, Type: {field.dtype}, Params: {field.params}")

# 检查集合是否存在
from pymilvus import utility
has_collection = utility.has_collection("advanced_collection")
print(f"Collection exists: {has_collection}")
删除集合
# 删除集合
collection.drop()

# 或者使用utility函数
utility.drop_collection("collection_name")
分区管理
创建分区
# 创建分区
collection.create_partition("partition_2023")
collection.create_partition("partition_2024")

# 查看所有分区
partitions = collection.partitions
for partition in partitions:
    print(f"Partition: {partition.name}")
分区数据操作
# 向特定分区插入数据
entities = [
    [1, 2, 3],  # ids
    [[0.1] * 256, [0.2] * 256, [0.3] * 256],  # vectors
    ["text1", "text2", "text3"],  # text
    [0.8, 0.9, 0.7],  # scores
    [1640995200, 1640995300, 1640995400],  # timestamps
    [{"key": "value1"}, {"key": "value2"}, {"key": "value3"}]  # metadata
]

collection.insert(entities, partition_name="partition_2023")

# 在特定分区中搜索
results = collection.search(
    data=[[0.1] * 256],
    anns_field="vector",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=10,
    partition_names=["partition_2023"]
)
数据插入和更新
批量插入
import numpy as np

# 大批量数据插入
batch_size = 10000
for i in range(0, 100000, batch_size):
    ids = list(range(i, min(i + batch_size, 100000)))
    vectors = np.random.random((len(ids), 256)).tolist()
    texts = [f"Document {j}" for j in ids]
    scores = np.random.random(len(ids)).tolist()
    timestamps = [1640995200 + j for j in ids]
    metadata = [{"batch": i // batch_size} for _ in ids]
    
    entities = [ids, vectors, texts, scores, timestamps, metadata]
    collection.insert(entities)
    
    if i % 50000 == 0:
        collection.flush()  # 定期刷新
        print(f"Inserted {i + len(ids)} entities")
数据更新（Upsert）
# Milvus 2.3+支持upsert操作
update_entities = [
    [1, 2, 3],  # 更新已存在的ID
    [[0.5] * 256, [0.6] * 256, [0.7] * 256],  # 新的向量
    ["Updated text1", "Updated text2", "Updated text3"],  # 新的文本
    [0.95, 0.96, 0.97],  # 新的分数
    [1640995500, 1640995600, 1640995700],  # 新的时间戳
    [{"updated": True}, {"updated": True}, {"updated": True}]  # 新的元数据
]

collection.upsert(update_entities)
数据删除
按ID删除
# 删除指定ID的实体
delete_ids = [1, 2, 3, 4, 5]
expr = f"id in {delete_ids}"
collection.delete(expr)

# 删除满足条件的实体
expr = "score < 0.5"
collection.delete(expr)
按条件删除
# 复杂删除条件
expr = "score < 0.3 and timestamp < 1640995300"
collection.delete(expr)

# 使用JSON字段删除
expr = "JSON_CONTAINS(metadata, &#39;\"updated\": true&#39;)"
collection.delete(expr)
6. 向量检索
基本检索
相似性搜索
# 基本向量搜索
query_vectors = [[0.1] * 256, [0.2] * 256]
search_params = {
    "metric_type": "L2",
    "params": {"nprobe": 16}
}

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=10,
    output_fields=["text", "score", "timestamp"]
)

for i, hits in enumerate(results):
    print(f"Query {i} results:")
    for hit in hits:
        print(f"  ID: {hit.id}, Distance: {hit.distance:.4f}")
        print(f"  Text: {hit.entity.get(&#39;text&#39;)}")
        print(f"  Score: {hit.entity.get(&#39;score&#39;)}")
混合搜索
# 向量搜索 + 标量过滤
query_vectors = [[0.1] * 256]
search_params = {"metric_type": "L2", "params": {"nprobe": 16}}

# 添加标量过滤条件
filter_expr = "score > 0.8 and timestamp > 1640995200"

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=10,
    expr=filter_expr,
    output_fields=["text", "score", "timestamp", "metadata"]
)
高级检索
范围搜索
# 搜索距离在指定范围内的向量
from pymilvus import SearchResult

query_vectors = [[0.1] * 256]
search_params = {
    "metric_type": "L2",
    "params": {
        "nprobe": 16,
        "radius": 0.1,  # 最大距离
        "range_filter": 0.05  # 最小距离
    }
}

results = collection.search(
    data=query_vectors,
    anns_field="vector",
    param=search_params,
    limit=100,
    output_fields=["text", "score"]
)
多向量搜索
# 同时搜索多个向量字段（如果集合有多个向量字段）
# 假设有text_vector和image_vector两个字段

# 创建包含多个向量字段的集合
multi_vector_fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=128),
    FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=256),
    FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200)
]

multi_schema = CollectionSchema(fields=multi_vector_fields)
multi_collection = Collection(name="multi_vector_collection", schema=multi_schema)

# 分别在不同向量字段上搜索
text_results = multi_collection.search(
    data=[[0.1] * 128],
    anns_field="text_vector",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)

image_results = multi_collection.search(
    data=[[0.1] * 256],
    anns_field="image_vector",
    param={"metric_type": "L2", "params": {"nprobe": 16}},
    limit=10
)
查询操作
标量查询
# 基于标量字段的查询
query_expr = "score > 0.8"
results = collection.query(
    expr=query_expr,
    output_fields=["id", "text", "score", "timestamp"]
)

for result in results:
    print(f"ID: {result[&#39;id&#39;]}, Text: {result[&#39;text&#39;]}, Score: {result[&#39;score&#39;]}")
复杂查询
# 复杂查询表达式
complex_expr = """
    (score > 0.8 and timestamp > 1640995200) or 
    (score > 0.9 and JSON_CONTAINS(metadata, &#39;"important": true&#39;))
"""

results = collection.query(
    expr=complex_expr,
    output_fields=["*"],  # 输出所有字段
    limit=100
)
分页查询
# 分页查询大量数据
page_size = 1000
offset = 0

while True:
    results = collection.query(
        expr="score > 0.5",
        output_fields=["id", "text", "score"],
        limit=page_size,
        offset=offset
    )
    
    if not results:
        break
        
    print(f"Page {offset // page_size + 1}: {len(results)} results")
    
    # 处理结果
    for result in results:
        # 处理每个结果
        pass
    
    offset += page_size
7. 索引管理
索引类型
FLAT索引
# FLAT索引 - 精确搜索，适合小数据集
flat_index = {
    "index_type": "FLAT",
    "metric_type": "L2",
    "params": {}
}

collection.create_index(
    field_name="vector",
    index_params=flat_index
)
IVF索引
# IVF_FLAT索引 - 平衡性能和精度
ivf_flat_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {
        "nlist": 128  # 聚类中心数量
    }
}

# IVF_PQ索引 - 压缩存储，适合大数据集
ivf_pq_index = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 128,
        "m": 16,  # PQ分段数
        "nbits": 8  # 每段的位数
    }
}

collection.create_index(field_name="vector", index_params=ivf_pq_index)
HNSW索引
# HNSW索引 - 高性能近似搜索
hnsw_index = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {
        "M": 16,  # 每层的最大连接数
        "efConstruction": 200  # 构建时的搜索深度
    }
}

collection.create_index(field_name="vector", index_params=hnsw_index)
ANNOY索引
# ANNOY索引 - 内存友好
annoy_index = {
    "index_type": "ANNOY",
    "metric_type": "L2",
    "params": {
        "n_trees": 8  # 树的数量
    }
}

collection.create_index(field_name="vector", index_params=annoy_index)
距离度量
欧几里得距离（L2）
l2_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",  # 欧几里得距离
    "params": {"nlist": 128}
}
内积（IP）
ip_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "IP",  # 内积
    "params": {"nlist": 128}
}
余弦相似度
# 余弦相似度需要先归一化向量，然后使用IP
import numpy as np

def normalize_vectors(vectors):
    """归一化向量以使用余弦相似度"""
    vectors = np.array(vectors)
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return (vectors / norms).tolist()

# 插入归一化后的向量
normalized_vectors = normalize_vectors(original_vectors)
entities = [ids, normalized_vectors, texts, scores, timestamps, metadata]
collection.insert(entities)

# 使用IP度量进行余弦相似度搜索
cosine_index = {
    "index_type": "IVF_FLAT",
    "metric_type": "IP",
    "params": {"nlist": 128}
}
索引管理操作
查看索引信息
# 获取索引信息
index_info = collection.index()
print(f"Index type: {index_info.params[&#39;index_type&#39;]}")
print(f"Metric type: {index_info.params[&#39;metric_type&#39;]}")
print(f"Index params: {index_info.params[&#39;params&#39;]}")

# 检查索引构建进度
from pymilvus import utility
index_progress = utility.index_building_progress("collection_name")
print(f"Index building progress: {index_progress}")
重建索引
# 删除现有索引
collection.drop_index()

# 创建新索引
new_index = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {"M": 32, "efConstruction": 400}
}

collection.create_index(field_name="vector", index_params=new_index)

# 等待索引构建完成
import time
while True:
    progress = utility.index_building_progress(collection.name)
    if progress[&#39;pending_index_rows&#39;] == 0:
        break
    print(f"Index building progress: {progress}")
    time.sleep(5)

print("Index building completed")
8. 性能优化
搜索参数优化
IVF索引优化
# 根据数据量调整nlist
data_size = collection.num_entities
optimal_nlist = int(np.sqrt(data_size))
optimal_nlist = max(128, min(optimal_nlist, 4096))  # 限制在合理范围内

# 搜索时调整nprobe
search_params = {
    "metric_type": "L2",
    "params": {
        "nprobe": min(optimal_nlist // 4, 64)  # 通常设置为nlist的1/4
    }
}
HNSW索引优化
# 构建时参数
hnsw_build_params = {
    "index_type": "HNSW",
    "metric_type": "L2",
    "params": {
        "M": 16,  # 连接数，影响精度和内存
        "efConstruction": 200  # 构建时搜索深度
    }
}

# 搜索时参数
hnsw_search_params = {
    "metric_type": "L2",
    "params": {
        "ef": 100  # 搜索时的候选数量，越大精度越高但速度越慢
    }
}
内存管理
集合加载策略
# 部分加载 - 只加载需要的字段
collection.load(replica_number=1, _resource_groups=["default"])

# 释放不需要的集合
collection.release()

# 检查内存使用
from pymilvus import utility
memory_info = utility.get_query_segment_info(collection.name)
for info in memory_info:
    print(f"Segment {info.segmentID}: {info.mem_size} bytes")
分区加载
# 只加载特定分区
collection.load(partition_names=["partition_2024"])

# 动态加载/释放分区
def load_partition_by_date(date_str):
    partition_name = f"partition_{date_str}"
    if partition_name in [p.name for p in collection.partitions]:
        collection.load(partition_names=[partition_name])
        return True
    return False

def release_old_partitions(keep_days=7):
    from datetime import datetime, timedelta
    cutoff_date = datetime.now() - timedelta(days=keep_days)
    
    for partition in collection.partitions:
        if partition.name.startswith("partition_"):
            date_str = partition.name.replace("partition_", "")
            try:
                partition_date = datetime.strptime(date_str, "%Y%m%d")
                if partition_date < cutoff_date:
                    collection.release(partition_names=[partition.name])
                    print(f"Released partition: {partition.name}")
            except ValueError:
                continue
批处理优化
批量插入优化
def optimized_batch_insert(collection, data, batch_size=10000):
    """优化的批量插入函数"""
    total_entities = len(data[0])
    
    for i in range(0, total_entities, batch_size):
        end_idx = min(i + batch_size, total_entities)
        batch_data = [field_data[i:end_idx] for field_data in data]
        
        # 插入批次
        collection.insert(batch_data)
        
        # 定期刷新
        if (i + batch_size) % 50000 == 0:
            collection.flush()
            print(f"Inserted and flushed {i + batch_size} entities")
    
    # 最终刷新
    collection.flush()
    print(f"Completed insertion of {total_entities} entities")
并行搜索
import concurrent.futures
import threading

def parallel_search(collection, query_vectors, search_params, max_workers=4):
    """并行执行多个搜索请求"""
    def search_batch(vectors_batch):
        return collection.search(
            data=vectors_batch,
            anns_field="vector",
            param=search_params,
            limit=10
        )
    
    # 将查询向量分批
    batch_size = len(query_vectors) // max_workers
    batches = [query_vectors[i:i+batch_size] 
               for i in range(0, len(query_vectors), batch_size)]
    
    # 并行执行搜索
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_batch = {executor.submit(search_batch, batch): batch 
                          for batch in batches}
        
        all_results = []
        for future in concurrent.futures.as_completed(future_to_batch):
            batch_results = future.result()
            all_results.extend(batch_results)
    
    return all_results
连接池管理
from pymilvus import connections
import threading

class MilvusConnectionPool:
    def __init__(self, host=&#39;localhost&#39;, port=&#39;19530&#39;, pool_size=10):
        self.host = host
        self.port = port
        self.pool_size = pool_size
        self.connections = []
        self.lock = threading.Lock()
        self._initialize_pool()
    
    def _initialize_pool(self):
        for i in range(self.pool_size):
            alias = f"connection_{i}"
            connections.connect(
                alias=alias,
                host=self.host,
                port=self.port
            )
            self.connections.append(alias)
    
    def get_connection(self):
        with self.lock:
            if self.connections:
                return self.connections.pop()
            else:
                # 如果池为空，创建新连接
                alias = f"temp_connection_{threading.current_thread().ident}"
                connections.connect(
                    alias=alias,
                    host=self.host,
                    port=self.port
                )
                return alias
    
    def return_connection(self, alias):
        with self.lock:
            if len(self.connections) < self.pool_size:
                self.connections.append(alias)
            else:
                connections.disconnect(alias)

# 使用连接池
pool = MilvusConnectionPool()

def search_with_pool(query_vector):
    alias = pool.get_connection()
    try:
        # 使用指定连接执行搜索
        connections.connect(alias=alias)
        collection = Collection("documents", using=alias)
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"nprobe": 16}},
            limit=10
        )
        return results
    finally:
        pool.return_connection(alias)
9. 集群部署
Kubernetes集群部署
1. 准备配置文件
# milvus-cluster-values.yaml
cluster:
  enabled: true

image:
  all:
    repository: milvusdb/milvus
    tag: v2.3.0
    pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 19530
  portName: milvus
  nodePort: 30530

rootCoordinator:
  replicas: 1
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

queryCoordinator:
  replicas: 1
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

queryNode:
  replicas: 2
  resources:
    limits:
      cpu: 2
      memory: 8Gi
    requests:
      cpu: 1
      memory: 4Gi

indexNode:
  replicas: 1
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 1
      memory: 2Gi

dataNode:
  replicas: 2
  resources:
    limits:
      cpu: 1
      memory: 4Gi
    requests:
      cpu: 0.5
      memory: 2Gi

proxy:
  replicas: 2
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

# 存储配置
minio:
  enabled: true
  mode: distributed
  replicas: 4
  persistence:
    enabled: true
    size: 100Gi
    storageClass: "fast-ssd"

etcd:
  enabled: true
  replicaCount: 3
  persistence:
    enabled: true
    size: 10Gi
    storageClass: "fast-ssd"

pulsar:
  enabled: true
  components:
    broker: true
    bookkeeper: true
    zookeeper: true
  zookeeper:
    replicaCount: 3
  bookkeeper:
    replicaCount: 3
  broker:
    replicaCount: 2
2. 部署集群
# 创建命名空间
kubectl create namespace milvus-cluster

# 部署Milvus集群
helm install milvus-cluster milvus/milvus \
  --namespace milvus-cluster \
  --values milvus-cluster-values.yaml

# 检查部署状态
kubectl get pods -n milvus-cluster
kubectl get services -n milvus-cluster
3. 配置负载均衡
# milvus-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: milvus-ingress
  namespace: milvus-cluster
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/grpc-backend: "true"
spec:
  ingressClassName: nginx
  rules:
  - host: milvus.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: milvus-cluster
            port:
              number: 19530
高可用配置
多副本配置
# 连接到集群
connections.connect(
    alias="cluster",
    host=&#39;milvus.example.com&#39;,
    port=&#39;19530&#39;
)

# 创建集合时指定副本数
collection = Collection("ha_collection", schema=schema)
collection.create_index(field_name="vector", index_params=index_params)

# 加载时指定副本数
collection.load(replica_number=2)

# 检查副本状态
from pymilvus import utility
replica_info = utility.get_replicas(collection.name)
for replica in replica_info:
    print(f"Replica {replica.id}: {replica.node_ids}")
故障转移测试
def test_failover(collection):
    """测试故障转移能力"""
    import time
    import random
    
    query_vector = [random.random() for _ in range(256)]
    
    # 持续查询测试
    success_count = 0
    total_count = 0
    
    for i in range(100):
        try:
            results = collection.search(
                data=[query_vector],
                anns_field="vector",
                param={"metric_type": "L2", "params": {"nprobe": 16}},
                limit=10
            )
            success_count += 1
            print(f"Query {i}: Success")
        except Exception as e:
            print(f"Query {i}: Failed - {e}")
        
        total_count += 1
        time.sleep(1)
    
    print(f"Success rate: {success_count/total_count*100:.2f}%")
数据分片策略
基于时间的分片
from datetime import datetime, timedelta

def create_time_based_partitions(collection, start_date, end_date):
    """创建基于时间的分区"""
    current_date = start_date
    
    while current_date <= end_date:
        partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
        
        current_date += timedelta(days=1)

def insert_with_time_partition(collection, entities, timestamp_field_idx=4):
    """根据时间戳插入到对应分区"""
    # 按时间戳分组数据
    partition_data = {}
    
    for i, timestamp in enumerate(entities[timestamp_field_idx]):
        date_str = datetime.fromtimestamp(timestamp).strftime(&#39;%Y%m%d&#39;)
        partition_name = f"partition_{date_str}"
        
        if partition_name not in partition_data:
            partition_data[partition_name] = [[] for _ in entities]
        
        for j, field_data in enumerate(entities):
            partition_data[partition_name][j].append(field_data[i])
    
    # 分别插入到各个分区
    for partition_name, partition_entities in partition_data.items():
        try:
            collection.insert(partition_entities, partition_name=partition_name)
            print(f"Inserted {len(partition_entities[0])} entities to {partition_name}")
        except Exception as e:
            print(f"Failed to insert to {partition_name}: {e}")
基于哈希的分片
import hashlib

def create_hash_based_partitions(collection, num_partitions=8):
    """创建基于哈希的分区"""
    for i in range(num_partitions):
        partition_name = f"partition_hash_{i}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")

def insert_with_hash_partition(collection, entities, key_field_idx=0, num_partitions=8):
    """根据键值哈希插入到对应分区"""
    partition_data = {f"partition_hash_{i}": [[] for _ in entities] 
                     for i in range(num_partitions)}
    
    for i, key in enumerate(entities[key_field_idx]):
        # 计算哈希值确定分区
        hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16)
        partition_idx = hash_value % num_partitions
        partition_name = f"partition_hash_{partition_idx}"
        
        for j, field_data in enumerate(entities):
            partition_data[partition_name][j].append(field_data[i])
    
    # 插入到各个分区
    for partition_name, partition_entities in partition_data.items():
        if partition_entities[0]:  # 如果分区有数据
            collection.insert(partition_entities, partition_name=partition_name)
            print(f"Inserted {len(partition_entities[0])} entities to {partition_name}")
10. 监控运维
系统监控
Prometheus监控配置
# prometheus-config.yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: &#39;milvus&#39;
    static_configs:
      - targets: [&#39;milvus:9091&#39;]
    metrics_path: /metrics
    scrape_interval: 15s

  - job_name: &#39;milvus-cluster&#39;
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - milvus-cluster
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
        action: keep
        regex: milvus
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+)
        replacement: ${1}:9091
Grafana仪表板
{
  "dashboard": {
    "title": "Milvus Monitoring",
    "panels": [
      {
        "title": "QPS (Queries Per Second)",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(milvus_proxy_search_vectors_count[5m])",
            "legendFormat": "Search QPS"
          },
          {
            "expr": "rate(milvus_proxy_insert_vectors_count[5m])",
            "legendFormat": "Insert QPS"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))",
            "legendFormat": "Search P95 Latency"
          },
          {
            "expr": "histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))",
            "legendFormat": "Search P99 Latency"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "milvus_querynode_memory_usage_bytes",
            "legendFormat": "QueryNode Memory"
          },
          {
            "expr": "milvus_indexnode_memory_usage_bytes",
            "legendFormat": "IndexNode Memory"
          }
        ]
      },
      {
        "title": "Collection Statistics",
        "type": "table",
        "targets": [
          {
            "expr": "milvus_collection_num_entities",
            "format": "table"
          }
        ]
      }
    ]
  }
}
性能监控
自定义监控脚本
import time
import psutil
import threading
from pymilvus import connections, Collection, utility
from datetime import datetime

class MilvusMonitor:
    def __init__(self, collection_name, interval=60):
        self.collection_name = collection_name
        self.interval = interval
        self.running = False
        self.metrics = []
        
    def start_monitoring(self):
        self.running = True
        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        
    def stop_monitoring(self):
        self.running = False
        
    def _monitor_loop(self):
        while self.running:
            try:
                metrics = self._collect_metrics()
                self.metrics.append(metrics)
                print(f"[{metrics[&#39;timestamp&#39;]}] {metrics}")
                
                # 保留最近1000条记录
                if len(self.metrics) > 1000:
                    self.metrics = self.metrics[-1000:]
                    
            except Exception as e:
                print(f"Monitoring error: {e}")
                
            time.sleep(self.interval)
            
    def _collect_metrics(self):
        collection = Collection(self.collection_name)
        
        # 集合统计信息
        stats = collection.get_stats()
        num_entities = int(stats[&#39;row_count&#39;])
        
        # 系统资源
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage(&#39;/&#39;)
        
        # 查询性能测试
        start_time = time.time()
        try:
            test_vector = [0.1] * 256
            collection.search(
                data=[test_vector],
                anns_field="vector",
                param={"metric_type": "L2", "params": {"nprobe": 16}},
                limit=10
            )
            query_latency = (time.time() - start_time) * 1000  # ms
        except Exception as e:
            query_latency = -1
            
        return {
            &#39;timestamp&#39;: datetime.now().isoformat(),
            &#39;collection_entities&#39;: num_entities,
            &#39;cpu_percent&#39;: cpu_percent,
            &#39;memory_percent&#39;: memory.percent,
            &#39;memory_used_gb&#39;: memory.used / (1024**3),
            &#39;disk_percent&#39;: disk.percent,
            &#39;disk_used_gb&#39;: disk.used / (1024**3),
            &#39;query_latency_ms&#39;: query_latency
        }
        
    def get_metrics_summary(self, last_n=100):
        """获取最近N条记录的统计摘要"""
        if not self.metrics:
            return None
            
        recent_metrics = self.metrics[-last_n:]
        
        latencies = [m[&#39;query_latency_ms&#39;] for m in recent_metrics if m[&#39;query_latency_ms&#39;] > 0]
        cpu_usage = [m[&#39;cpu_percent&#39;] for m in recent_metrics]
        memory_usage = [m[&#39;memory_percent&#39;] for m in recent_metrics]
        
        return {
            &#39;avg_query_latency_ms&#39;: sum(latencies) / len(latencies) if latencies else 0,
            &#39;max_query_latency_ms&#39;: max(latencies) if latencies else 0,
            &#39;avg_cpu_percent&#39;: sum(cpu_usage) / len(cpu_usage),
            &#39;max_cpu_percent&#39;: max(cpu_usage),
            &#39;avg_memory_percent&#39;: sum(memory_usage) / len(memory_usage),
            &#39;max_memory_percent&#39;: max(memory_usage),
            &#39;total_entities&#39;: recent_metrics[-1][&#39;collection_entities&#39;] if recent_metrics else 0
        }

# 使用监控器
monitor = MilvusMonitor("documents", interval=30)
monitor.start_monitoring()

# 运行一段时间后查看摘要
time.sleep(300)  # 5分钟
summary = monitor.get_metrics_summary()
print(f"Performance Summary: {summary}")

monitor.stop_monitoring()
日志管理
日志配置
# milvus-log-config.yaml
log:
  level: info
  file:
    rootPath: "/var/log/milvus"
    maxSize: 100  # MB
    maxAge: 7     # days
    maxBackups: 10
  format: json
  
# 在Kubernetes中配置日志收集
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: milvus-cluster
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf

    [INPUT]
        Name              tail
        Path              /var/log/milvus/*.log
        Parser            json
        Tag               milvus.*
        Refresh_Interval  5

    [OUTPUT]
        Name  es
        Match milvus.*
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Index milvus-logs
        Type  _doc
日志分析脚本
import json
import re
from datetime import datetime, timedelta
from collections import defaultdict

def analyze_milvus_logs(log_file_path, hours=24):
    """分析Milvus日志文件"""
    cutoff_time = datetime.now() - timedelta(hours=hours)
    
    error_counts = defaultdict(int)
    warning_counts = defaultdict(int)
    performance_metrics = []
    
    with open(log_file_path, &#39;r&#39;) as f:
        for line in f:
            try:
                log_entry = json.loads(line.strip())
                log_time = datetime.fromisoformat(log_entry.get(&#39;time&#39;, &#39;&#39;).replace(&#39;Z&#39;, &#39;+00:00&#39;))
                
                if log_time < cutoff_time:
                    continue
                    
                level = log_entry.get(&#39;level&#39;, &#39;&#39;).upper()
                message = log_entry.get(&#39;msg&#39;, &#39;&#39;)
                
                # 统计错误和警告
                if level == &#39;ERROR&#39;:
                    error_counts[message] += 1
                elif level == &#39;WARN&#39;:
                    warning_counts[message] += 1
                    
                # 提取性能指标
                if &#39;latency&#39; in message.lower():
                    latency_match = re.search(r&#39;latency[:\s]+(\d+(?:\.\d+)?)\s*(ms|μs)&#39;, message)
                    if latency_match:
                        latency_value = float(latency_match.group(1))
                        latency_unit = latency_match.group(2)
                        
                        if latency_unit == &#39;μs&#39;:
                            latency_value /= 1000  # 转换为ms
                            
                        performance_metrics.append({
                            &#39;timestamp&#39;: log_time,
                            &#39;latency_ms&#39;: latency_value,
                            &#39;operation&#39;: extract_operation(message)
                        })
                        
            except (json.JSONDecodeError, ValueError) as e:
                continue
                
    return {
        &#39;error_summary&#39;: dict(error_counts),
        &#39;warning_summary&#39;: dict(warning_counts),
        &#39;performance_metrics&#39;: performance_metrics
    }

def extract_operation(message):
    """从日志消息中提取操作类型"""
    if &#39;search&#39; in message.lower():
        return &#39;search&#39;
    elif &#39;insert&#39; in message.lower():
        return &#39;insert&#39;
    elif &#39;index&#39; in message.lower():
        return &#39;index&#39;
    else:
        return &#39;unknown&#39;

def generate_log_report(analysis_result):
    """生成日志分析报告"""
    print("=== Milvus Log Analysis Report ===")
    print(f"Analysis time: {datetime.now()}")
    print()
    
    # 错误摘要
    print("Top Errors:")
    sorted_errors = sorted(analysis_result[&#39;error_summary&#39;].items(), 
                          key=lambda x: x[1], reverse=True)
    for error, count in sorted_errors[:10]:
        print(f"  {count:4d} - {error[:100]}...")
    print()
    
    # 警告摘要
    print("Top Warnings:")
    sorted_warnings = sorted(analysis_result[&#39;warning_summary&#39;].items(), 
                           key=lambda x: x[1], reverse=True)
    for warning, count in sorted_warnings[:10]:
        print(f"  {count:4d} - {warning[:100]}...")
    print()
    
    # 性能摘要
    metrics = analysis_result[&#39;performance_metrics&#39;]
    if metrics:
        latencies = [m[&#39;latency_ms&#39;] for m in metrics]
        print("Performance Summary:")
        print(f"  Total operations: {len(metrics)}")
        print(f"  Average latency: {sum(latencies)/len(latencies):.2f} ms")
        print(f"  Max latency: {max(latencies):.2f} ms")
        print(f"  Min latency: {min(latencies):.2f} ms")
        
        # 按操作类型分组
        by_operation = defaultdict(list)
        for metric in metrics:
            by_operation[metric[&#39;operation&#39;]].append(metric[&#39;latency_ms&#39;])
            
        print("\nPerformance by Operation:")
        for operation, latencies in by_operation.items():
            if latencies:
                avg_latency = sum(latencies) / len(latencies)
                print(f"  {operation.capitalize()}:")
                print(f"    Count: {len(latencies)}")
                print(f"    Avg latency: {avg_latency:.2f} ms")
                print(f"    Max latency: {max(latencies):.2f} ms")
    else:
        print("No performance metrics found.")

# 使用示例
if __name__ == "__main__":
    log_file = "/path/to/milvus.log"
    result = analyze_milvus_logs(log_file, hours=24)
    generate_log_report(result)
11. 最佳实践
1. 数据建模最佳实践
Collection设计原则
# 良好的Collection设计示例
def create_production_collection(name, vector_dim, expected_size):
    """生产环境Collection设计"""
    # 根据数据规模选择分片数
    shard_num = min(max(expected_size // 1000000, 2), 16)
    
    fields = [
        # 主键字段 - 使用有意义的ID
        FieldSchema(
            name="id", 
            dtype=DataType.INT64, 
            is_primary=True, 
            auto_id=False,
            description="Document unique identifier"
        ),
        # 时间戳字段 - 便于数据管理
        FieldSchema(
            name="created_at", 
            dtype=DataType.INT64,
            description="Creation timestamp"
        ),
        # 分类字段 - 用于过滤
        FieldSchema(
            name="category", 
            dtype=DataType.VARCHAR, 
            max_length=50,
            description="Document category"
        ),
        # 向量字段 - 核心搜索字段
        FieldSchema(
            name="embedding", 
            dtype=DataType.FLOAT_VECTOR, 
            dim=vector_dim,
            description="Document embedding vector"
        ),
        # 元数据字段 - 存储额外信息
        FieldSchema(
            name="metadata", 
            dtype=DataType.JSON,
            description="Additional metadata"
        )
    ]
    
    schema = CollectionSchema(
        fields=fields,
        description=f"Production collection for {expected_size} documents",
        enable_dynamic_field=True  # 允许动态字段
    )
    
    collection = Collection(
        name=name,
        schema=schema,
        shards_num=shard_num,
        consistency_level="Strong"  # 生产环境建议强一致性
    )
    
    return collection
分区策略
# 基于时间的分区策略
def create_time_based_partitions(collection, start_date, end_date):
    """创建基于时间的分区"""
    from datetime import datetime, timedelta
    
    current_date = start_date
    while current_date <= end_date:
        partition_name = f"partition_{current_date.strftime(&#39;%Y%m%d&#39;)}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
        current_date += timedelta(days=1)

# 基于类别的分区策略
def create_category_partitions(collection, categories):
    """创建基于类别的分区"""
    for category in categories:
        partition_name = f"category_{category.lower()}"
        try:
            collection.create_partition(partition_name)
            print(f"Created partition: {partition_name}")
        except Exception as e:
            print(f"Partition {partition_name} already exists or error: {e}")
2. 性能优化最佳实践
索引选择策略
def choose_optimal_index(data_size, memory_budget, latency_requirement, accuracy_requirement):
    """根据需求选择最优索引"""
    
    if data_size < 100000:
        # 小数据集使用FLAT
        return {
            "index_type": "FLAT",
            "metric_type": "L2",
            "params": {}
        }
    
    elif latency_requirement == "ultra_low" and memory_budget == "high":
        # 超低延迟需求使用HNSW
        return {
            "index_type": "HNSW",
            "metric_type": "L2",
            "params": {
                "M": 32,
                "efConstruction": 400
            }
        }
    
    elif memory_budget == "low":
        # 内存受限使用PQ压缩
        return {
            "index_type": "IVF_PQ",
            "metric_type": "L2",
            "params": {
                "nlist": min(4 * int(np.sqrt(data_size)), 4096),
                "m": 16,
                "nbits": 8
            }
        }
    
    else:
        # 平衡选择IVF_FLAT
        return {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {
                "nlist": min(4 * int(np.sqrt(data_size)), 4096)
            }
        }

# 动态调整搜索参数
def get_adaptive_search_params(index_type, accuracy_level="medium", data_size=None):
    """根据索引类型和精度要求动态调整搜索参数"""
    
    if index_type == "IVF_FLAT" or index_type == "IVF_PQ":
        nprobe_map = {
            "low": max(8, int(np.sqrt(data_size)) // 100) if data_size else 8,
            "medium": max(16, int(np.sqrt(data_size)) // 50) if data_size else 16,
            "high": max(32, int(np.sqrt(data_size)) // 25) if data_size else 32
        }
        return {"nprobe": nprobe_map[accuracy_level]}
    
    elif index_type == "HNSW":
        ef_map = {"low": 64, "medium": 128, "high": 256}
        return {"ef": ef_map[accuracy_level]}
    
    elif index_type == "ANNOY":
        search_k_map = {"low": 100, "medium": 200, "high": 400}
        return {"search_k": search_k_map[accuracy_level]}
    
    return {}
批处理优化
class OptimizedBatchProcessor:
    """优化的批处理器"""
    
    def __init__(self, collection, batch_size=10000, flush_interval=50000):
        self.collection = collection
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.total_inserted = 0
    
    def insert_batch(self, data):
        """批量插入数据"""
        total_entities = len(data[0])
        
        for i in range(0, total_entities, self.batch_size):
            end_idx = min(i + self.batch_size, total_entities)
            batch_data = [field_data[i:end_idx] for field_data in data]
            
            try:
                result = self.collection.insert(batch_data)
                self.total_inserted += len(result.primary_keys)
                
                # 定期刷新
                if self.total_inserted % self.flush_interval == 0:
                    self.collection.flush()
                    print(f"Flushed after inserting {self.total_inserted} entities")
                    
            except Exception as e:
                print(f"Error inserting batch {i//self.batch_size}: {e}")
                continue
        
        # 最终刷新
        self.collection.flush()
        return self.total_inserted
    
    def parallel_search(self, query_vectors, search_params, max_workers=4):
        """并行搜索"""
        import concurrent.futures
        
        def search_single(query_vector):
            return self.collection.search(
                data=[query_vector],
                anns_field="embedding",
                param=search_params,
                limit=10
            )
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(search_single, qv) for qv in query_vectors]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        return results
3. 数据质量最佳实践
向量预处理
import numpy as np
from sklearn.preprocessing import normalize

def preprocess_vectors(vectors, normalization="l2", dimension_check=True):
    """向量预处理管道"""
    vectors = np.array(vectors, dtype=np.float32)
    
    # 维度检查
    if dimension_check and len(vectors.shape) != 2:
        raise ValueError(f"Expected 2D array, got {len(vectors.shape)}D")
    
    # 检查NaN和无穷值
    if np.any(np.isnan(vectors)) or np.any(np.isinf(vectors)):
        print("Warning: Found NaN or infinite values, replacing with zeros")
        vectors = np.nan_to_num(vectors, nan=0.0, posinf=0.0, neginf=0.0)
    
    # 归一化
    if normalization == "l2":
        vectors = normalize(vectors, norm=&#39;l2&#39;, axis=1)
    elif normalization == "minmax":
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        vectors = scaler.fit_transform(vectors)
    
    return vectors.tolist()

# 数据验证
def validate_data_quality(data, schema):
    """验证数据质量"""
    issues = []
    
    # 检查数据长度一致性
    field_lengths = [len(field_data) for field_data in data]
    if len(set(field_lengths)) > 1:
        issues.append(f"Inconsistent field lengths: {field_lengths}")
    
    # 检查向量维度
    for i, field in enumerate(schema.fields):
        if field.dtype == DataType.FLOAT_VECTOR:
            vectors = data[i]
            expected_dim = field.params.get(&#39;dim&#39;)
            for j, vector in enumerate(vectors[:100]):  # 检查前100个
                if len(vector) != expected_dim:
                    issues.append(f"Vector {j} has dimension {len(vector)}, expected {expected_dim}")
                    break
    
    return issues
4. 监控和运维最佳实践
健康检查系统
import time
import logging
from datetime import datetime

class MilvusHealthMonitor:
    """Milvus健康监控系统"""
    
    def __init__(self, collection_names, alert_thresholds=None):
        self.collection_names = collection_names
        self.alert_thresholds = alert_thresholds or {
            &#39;query_latency&#39;: 1.0,  # 秒
            &#39;memory_usage&#39;: 0.8,   # 80%
            &#39;error_rate&#39;: 0.05     # 5%
        }
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        logger = logging.getLogger(&#39;milvus_monitor&#39;)
        logger.setLevel(logging.INFO)
        handler = logging.FileHandler(&#39;milvus_health.log&#39;)
        formatter = logging.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        return logger
    
    def check_connection_health(self):
        """检查连接健康状态"""
        try:
            from pymilvus import utility
            version = utility.get_server_version()
            self.logger.info(f"Milvus server version: {version}")
            return True
        except Exception as e:
            self.logger.error(f"Connection health check failed: {e}")
            return False
    
    def check_collection_health(self, collection_name):
        """检查集合健康状态"""
        try:
            collection = Collection(collection_name)
            
            # 检查集合状态
            stats = collection.get_stats()
            num_entities = collection.num_entities
            
            # 执行测试查询
            start_time = time.time()
            test_vector = [[0.1] * 128]  # 假设128维向量
            results = collection.search(
                data=test_vector,
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=1
            )
            query_latency = time.time() - start_time
            
            # 记录指标
            metrics = {
                &#39;collection&#39;: collection_name,
                &#39;num_entities&#39;: num_entities,
                &#39;query_latency&#39;: query_latency,
                &#39;timestamp&#39;: datetime.now().isoformat()
            }
            
            self.logger.info(f"Collection health: {metrics}")
            
            # 检查告警阈值
            if query_latency > self.alert_thresholds[&#39;query_latency&#39;]:
                self.logger.warning(f"High query latency: {query_latency:.3f}s")
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Collection health check failed for {collection_name}: {e}")
            return None
    
    def run_continuous_monitoring(self, interval=60):
        """持续监控"""
        while True:
            try:
                # 检查连接
                if not self.check_connection_health():
                    self.logger.critical("Milvus connection lost!")
                
                # 检查所有集合
                for collection_name in self.collection_names:
                    self.check_collection_health(collection_name)
                
                time.sleep(interval)
                
            except KeyboardInterrupt:
                self.logger.info("Monitoring stopped by user")
                break
            except Exception as e:
                self.logger.error(f"Monitoring error: {e}")
                time.sleep(interval)
备份和恢复策略
import json
import os
from datetime import datetime

class MilvusBackupManager:
    """Milvus备份管理器"""
    
    def __init__(self, backup_dir="./milvus_backups"):
        self.backup_dir = backup_dir
        os.makedirs(backup_dir, exist_ok=True)
    
    def backup_collection_metadata(self, collection_name):
        """备份集合元数据"""
        try:
            collection = Collection(collection_name)
            
            # 收集元数据
            metadata = {
                &#39;name&#39;: collection.name,
                &#39;description&#39;: collection.description,
                &#39;schema&#39;: {
                    &#39;fields&#39;: [
                        {
                            &#39;name&#39;: field.name,
                            &#39;dtype&#39;: str(field.dtype),
                            &#39;params&#39;: field.params,
                            &#39;is_primary&#39;: field.is_primary,
                            &#39;auto_id&#39;: field.auto_id
                        }
                        for field in collection.schema.fields
                    ],
                    &#39;enable_dynamic_field&#39;: collection.schema.enable_dynamic_field
                },
                &#39;num_entities&#39;: collection.num_entities,
                &#39;partitions&#39;: [p.name for p in collection.partitions],
                &#39;indexes&#39;: []
            }
            
            # 获取索引信息
            try:
                index_info = collection.index()
                if index_info:
                    metadata[&#39;indexes&#39;].append({
                        &#39;field_name&#39;: &#39;embedding&#39;,  # 假设向量字段名
                        &#39;index_params&#39;: index_info.params
                    })
            except:
                pass
            
            # 保存元数据
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.backup_dir}/{collection_name}_metadata_{timestamp}.json"
            
            with open(backup_file, &#39;w&#39;) as f:
                json.dump(metadata, f, indent=2)
            
            print(f"Metadata backup saved: {backup_file}")
            return backup_file
            
        except Exception as e:
            print(f"Backup failed: {e}")
            return None
    
    def restore_collection_from_metadata(self, backup_file):
        """从元数据恢复集合结构"""
        try:
            with open(backup_file, &#39;r&#39;) as f:
                metadata = json.load(f)
            
            # 重建字段
            fields = []
            for field_info in metadata[&#39;schema&#39;][&#39;fields&#39;]:
                field = FieldSchema(
                    name=field_info[&#39;name&#39;],
                    dtype=getattr(DataType, field_info[&#39;dtype&#39;].split(&#39;.&#39;)[-1]),
                    is_primary=field_info.get(&#39;is_primary&#39;, False),
                    auto_id=field_info.get(&#39;auto_id&#39;, False),
                    **field_info.get(&#39;params&#39;, {})
                )
                fields.append(field)
            
            # 重建schema
            schema = CollectionSchema(
                fields=fields,
                description=metadata[&#39;description&#39;],
                enable_dynamic_field=metadata[&#39;schema&#39;][&#39;enable_dynamic_field&#39;]
            )
            
            # 创建集合
            collection = Collection(
                name=metadata[&#39;name&#39;],
                schema=schema
            )
            
            # 重建分区
            for partition_name in metadata[&#39;partitions&#39;]:
                if partition_name != &#39;_default&#39;:
                    collection.create_partition(partition_name)
            
            print(f"Collection {metadata[&#39;name&#39;]} restored from backup")
            return collection
            
        except Exception as e:
            print(f"Restore failed: {e}")
            return None
5. 安全最佳实践
访问控制
from pymilvus import connections

# 安全连接配置
def secure_connect(host, port, username, password, secure=True):
    """安全连接到Milvus"""
    try:
        connections.connect(
            alias="secure_connection",
            host=host,
            port=port,
            user=username,
            password=password,
            secure=secure,
            server_pem_path="/path/to/server.pem",  # TLS证书路径
            server_name="milvus-server",
            timeout=30
        )
        print("Secure connection established")
        return True
    except Exception as e:
        print(f"Secure connection failed: {e}")
        return False

# 输入验证
def validate_search_input(query_vectors, limit, expr=None):
    """验证搜索输入"""
    # 验证向量
    if not isinstance(query_vectors, list) or not query_vectors:
        raise ValueError("Query vectors must be a non-empty list")
    
    # 验证limit
    if not isinstance(limit, int) or limit <= 0 or limit > 10000:
        raise ValueError("Limit must be a positive integer <= 10000")
    
    # 验证表达式（防止注入）
    if expr:
        dangerous_keywords = [&#39;DROP&#39;, &#39;DELETE&#39;, &#39;UPDATE&#39;, &#39;INSERT&#39;, &#39;CREATE&#39;]
        expr_upper = expr.upper()
        for keyword in dangerous_keywords:
            if keyword in expr_upper:
                raise ValueError(f"Dangerous keyword &#39;{keyword}&#39; found in expression")
    
    return True
12. 常见问题
Q1: 如何选择合适的索引类型？
A: 索引选择主要考虑以下因素：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wellzhi.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Tech","item":"https://wellzhi.github.io/posts/tech/"},{"@type":"ListItem","position":3,"name":"Milvus使用指南","item":"https://wellzhi.github.io/posts/tech/2024-01-01_milvus/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Milvus使用指南","name":"Milvus使用指南","description":"1. Milvus简介 什么是Milvus Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。\n主要特性 高性能：支持十亿级向量的毫秒级检索 多样化索引：支持多种向量索引算法（IVF、HNSW、ANNOY等） 云原生：基于Kubernetes的分布式架构 多语言SDK：支持Python、Java、Go、Node.js等 ACID事务：保证数据一致性 混合搜索：支持向量和标量数据的混合查询 应用场景 推荐系统：基于用户行为向量进行个性化推荐 图像检索：以图搜图、相似图片查找 文本搜索：语义搜索、文档相似性匹配 视频分析：视频内容检索和分析 药物发现：分子结构相似性搜索 异常检测：基于向量距离的异常识别 2. 核心概念 基本术语 Collection（集合） 类似于关系数据库中的表，用于存储向量数据和相关的标量字段。\nField（字段） 集合中的列，包括向量字段和标量字段。\nEntity（实体） 集合中的一行数据，包含多个字段的值。\nPartition（分区） 集合的子集，用于数据分片和查询优化。\nIndex（索引） 为加速向量检索而构建的数据结构。\nSegment（段） Milvus内部的数据存储单元，用于数据管理和查询优化。\n数据类型 向量类型 FloatVector：浮点数向量 BinaryVector：二进制向量 标量类型 Bool：布尔值 Int8/Int16/Int32/Int64：整数 Float/Double：浮点数 String/VarChar：字符串 JSON：JSON对象 3. 安装部署 系统要求 硬件要求 CPU：x86_64架构，支持SSE4.2指令集 内存：8GB以上（推荐16GB+） 存储：SSD硬盘（推荐NVMe） 网络：千兆网卡 软件要求 操作系统：Ubuntu 18.04+、CentOS 7+、macOS 10.14+ Docker：20.10+ Docker Compose：1.28+ Docker安装（推荐） 1. 下载配置文件 # 下载docker-compose.yml wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml 2. 启动Milvus # 启动服务 docker-compose up -d # 检查服务状态 docker-compose ps 3. 验证安装 # 检查Milvus是否正常运行 curl -X GET \u0026#34;http://localhost:9091/health\u0026#34; Kubernetes部署 1. 安装Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash 2. 添加Milvus Helm仓库 helm repo add milvus https://milvus-io.github.io/milvus-helm/ helm repo update 3. 部署Milvus # 创建命名空间 kubectl create namespace milvus # 部署Milvus集群 helm install milvus milvus/milvus --namespace milvus 源码编译安装 1. 安装依赖 # Ubuntu/Debian sudo apt update sudo apt install -y build-essential cmake libopenblas-dev # CentOS/RHEL sudo yum groupinstall -y \u0026#34;Development Tools\u0026#34; sudo yum install -y cmake openblas-devel 2. 编译安装 # 克隆源码 git clone https://github.com/milvus-io/milvus.git cd milvus # 编译 make build # 启动 ./bin/milvus run standalone 4. 快速开始 安装Python SDK pip install pymilvus 基本操作示例 1. 连接Milvus from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType # 连接到Milvus connections.connect( alias=\u0026#34;default\u0026#34;, host=\u0026#39;localhost\u0026#39;, port=\u0026#39;19530\u0026#39; ) print(\u0026#34;Connected to Milvus\u0026#34;) 2. 创建集合 # 定义字段 fields = [ FieldSchema(name=\u0026#34;id\u0026#34;, dtype=DataType.INT64, is_primary=True, auto_id=False), FieldSchema(name=\u0026#34;embedding\u0026#34;, dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name=\u0026#34;title\u0026#34;, dtype=DataType.VARCHAR, max_length=200), FieldSchema(name=\u0026#34;category\u0026#34;, dtype=DataType.VARCHAR, max_length=50) ] # 创建集合schema schema = CollectionSchema( fields=fields, description=\u0026#34;Document embedding collection\u0026#34; ) # 创建集合 collection = Collection( name=\u0026#34;documents\u0026#34;, schema=schema ) print(\u0026#34;Collection created\u0026#34;) 3. 插入数据 import random # 准备数据 num_entities = 1000 entities = [ [i for i in range(num_entities)], # id字段 [[random.random() for _ in range(128)] for _ in range(num_entities)], # embedding字段 [f\u0026#34;Document {i}\u0026#34; for i in range(num_entities)], # title字段 [f\u0026#34;Category {i % 10}\u0026#34; for i in range(num_entities)] # category字段 ] # 插入数据 insert_result = collection.insert(entities) print(f\u0026#34;Inserted {len(insert_result.primary_keys)} entities\u0026#34;) # 刷新数据到磁盘 collection.flush() 4. 创建索引 # 定义索引参数 index_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nlist\u0026#34;: 128} } # 创建索引 collection.create_index( field_name=\u0026#34;embedding\u0026#34;, index_params=index_params ) print(\u0026#34;Index created\u0026#34;) 5. 加载集合 # 加载集合到内存 collection.load() print(\u0026#34;Collection loaded\u0026#34;) 6. 向量检索 # 准备查询向量 query_vectors = [[random.random() for _ in range(128)]] # 执行搜索 search_params = {\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 10}} results = collection.search( data=query_vectors, anns_field=\u0026#34;embedding\u0026#34;, param=search_params, limit=10, output_fields=[\u0026#34;title\u0026#34;, \u0026#34;category\u0026#34;] ) # 输出结果 for hits in results: for hit in hits: print(f\u0026#34;ID: {hit.id}, Distance: {hit.distance}, Title: {hit.entity.get(\u0026#39;title\u0026#39;)}\u0026#34;) 5. 数据管理 集合管理 创建集合 from pymilvus import Collection, FieldSchema, CollectionSchema, DataType # 定义复杂schema fields = [ FieldSchema(name=\u0026#34;id\u0026#34;, dtype=DataType.INT64, is_primary=True), FieldSchema(name=\u0026#34;vector\u0026#34;, dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name=\u0026#34;text\u0026#34;, dtype=DataType.VARCHAR, max_length=1000), FieldSchema(name=\u0026#34;score\u0026#34;, dtype=DataType.FLOAT), FieldSchema(name=\u0026#34;timestamp\u0026#34;, dtype=DataType.INT64), FieldSchema(name=\u0026#34;metadata\u0026#34;, dtype=DataType.JSON) ] schema = CollectionSchema( fields=fields, description=\u0026#34;Advanced collection with multiple field types\u0026#34;, enable_dynamic_field=True # 启用动态字段 ) collection = Collection(name=\u0026#34;advanced_collection\u0026#34;, schema=schema) 查看集合信息 # 获取集合统计信息 stats = collection.get_stats() print(f\u0026#34;Collection stats: {stats}\u0026#34;) # 获取集合schema schema = collection.schema for field in schema.fields: print(f\u0026#34;Field: {field.name}, Type: {field.dtype}, Params: {field.params}\u0026#34;) # 检查集合是否存在 from pymilvus import utility has_collection = utility.has_collection(\u0026#34;advanced_collection\u0026#34;) print(f\u0026#34;Collection exists: {has_collection}\u0026#34;) 删除集合 # 删除集合 collection.drop() # 或者使用utility函数 utility.drop_collection(\u0026#34;collection_name\u0026#34;) 分区管理 创建分区 # 创建分区 collection.create_partition(\u0026#34;partition_2023\u0026#34;) collection.create_partition(\u0026#34;partition_2024\u0026#34;) # 查看所有分区 partitions = collection.partitions for partition in partitions: print(f\u0026#34;Partition: {partition.name}\u0026#34;) 分区数据操作 # 向特定分区插入数据 entities = [ [1, 2, 3], # ids [[0.1] * 256, [0.2] * 256, [0.3] * 256], # vectors [\u0026#34;text1\u0026#34;, \u0026#34;text2\u0026#34;, \u0026#34;text3\u0026#34;], # text [0.8, 0.9, 0.7], # scores [1640995200, 1640995300, 1640995400], # timestamps [{\u0026#34;key\u0026#34;: \u0026#34;value1\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;value2\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;value3\u0026#34;}] # metadata ] collection.insert(entities, partition_name=\u0026#34;partition_2023\u0026#34;) # 在特定分区中搜索 results = collection.search( data=[[0.1] * 256], anns_field=\u0026#34;vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 10}}, limit=10, partition_names=[\u0026#34;partition_2023\u0026#34;] ) 数据插入和更新 批量插入 import numpy as np # 大批量数据插入 batch_size = 10000 for i in range(0, 100000, batch_size): ids = list(range(i, min(i + batch_size, 100000))) vectors = np.random.random((len(ids), 256)).tolist() texts = [f\u0026#34;Document {j}\u0026#34; for j in ids] scores = np.random.random(len(ids)).tolist() timestamps = [1640995200 + j for j in ids] metadata = [{\u0026#34;batch\u0026#34;: i // batch_size} for _ in ids] entities = [ids, vectors, texts, scores, timestamps, metadata] collection.insert(entities) if i % 50000 == 0: collection.flush() # 定期刷新 print(f\u0026#34;Inserted {i + len(ids)} entities\u0026#34;) 数据更新（Upsert） # Milvus 2.3+支持upsert操作 update_entities = [ [1, 2, 3], # 更新已存在的ID [[0.5] * 256, [0.6] * 256, [0.7] * 256], # 新的向量 [\u0026#34;Updated text1\u0026#34;, \u0026#34;Updated text2\u0026#34;, \u0026#34;Updated text3\u0026#34;], # 新的文本 [0.95, 0.96, 0.97], # 新的分数 [1640995500, 1640995600, 1640995700], # 新的时间戳 [{\u0026#34;updated\u0026#34;: True}, {\u0026#34;updated\u0026#34;: True}, {\u0026#34;updated\u0026#34;: True}] # 新的元数据 ] collection.upsert(update_entities) 数据删除 按ID删除 # 删除指定ID的实体 delete_ids = [1, 2, 3, 4, 5] expr = f\u0026#34;id in {delete_ids}\u0026#34; collection.delete(expr) # 删除满足条件的实体 expr = \u0026#34;score \u0026lt; 0.5\u0026#34; collection.delete(expr) 按条件删除 # 复杂删除条件 expr = \u0026#34;score \u0026lt; 0.3 and timestamp \u0026lt; 1640995300\u0026#34; collection.delete(expr) # 使用JSON字段删除 expr = \u0026#34;JSON_CONTAINS(metadata, \u0026#39;\\\u0026#34;updated\\\u0026#34;: true\u0026#39;)\u0026#34; collection.delete(expr) 6. 向量检索 基本检索 相似性搜索 # 基本向量搜索 query_vectors = [[0.1] * 256, [0.2] * 256] search_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16} } results = collection.search( data=query_vectors, anns_field=\u0026#34;vector\u0026#34;, param=search_params, limit=10, output_fields=[\u0026#34;text\u0026#34;, \u0026#34;score\u0026#34;, \u0026#34;timestamp\u0026#34;] ) for i, hits in enumerate(results): print(f\u0026#34;Query {i} results:\u0026#34;) for hit in hits: print(f\u0026#34; ID: {hit.id}, Distance: {hit.distance:.4f}\u0026#34;) print(f\u0026#34; Text: {hit.entity.get(\u0026#39;text\u0026#39;)}\u0026#34;) print(f\u0026#34; Score: {hit.entity.get(\u0026#39;score\u0026#39;)}\u0026#34;) 混合搜索 # 向量搜索 + 标量过滤 query_vectors = [[0.1] * 256] search_params = {\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}} # 添加标量过滤条件 filter_expr = \u0026#34;score \u0026gt; 0.8 and timestamp \u0026gt; 1640995200\u0026#34; results = collection.search( data=query_vectors, anns_field=\u0026#34;vector\u0026#34;, param=search_params, limit=10, expr=filter_expr, output_fields=[\u0026#34;text\u0026#34;, \u0026#34;score\u0026#34;, \u0026#34;timestamp\u0026#34;, \u0026#34;metadata\u0026#34;] ) 高级检索 范围搜索 # 搜索距离在指定范围内的向量 from pymilvus import SearchResult query_vectors = [[0.1] * 256] search_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nprobe\u0026#34;: 16, \u0026#34;radius\u0026#34;: 0.1, # 最大距离 \u0026#34;range_filter\u0026#34;: 0.05 # 最小距离 } } results = collection.search( data=query_vectors, anns_field=\u0026#34;vector\u0026#34;, param=search_params, limit=100, output_fields=[\u0026#34;text\u0026#34;, \u0026#34;score\u0026#34;] ) 多向量搜索 # 同时搜索多个向量字段（如果集合有多个向量字段） # 假设有text_vector和image_vector两个字段 # 创建包含多个向量字段的集合 multi_vector_fields = [ FieldSchema(name=\u0026#34;id\u0026#34;, dtype=DataType.INT64, is_primary=True), FieldSchema(name=\u0026#34;text_vector\u0026#34;, dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name=\u0026#34;image_vector\u0026#34;, dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name=\u0026#34;title\u0026#34;, dtype=DataType.VARCHAR, max_length=200) ] multi_schema = CollectionSchema(fields=multi_vector_fields) multi_collection = Collection(name=\u0026#34;multi_vector_collection\u0026#34;, schema=multi_schema) # 分别在不同向量字段上搜索 text_results = multi_collection.search( data=[[0.1] * 128], anns_field=\u0026#34;text_vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}}, limit=10 ) image_results = multi_collection.search( data=[[0.1] * 256], anns_field=\u0026#34;image_vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}}, limit=10 ) 查询操作 标量查询 # 基于标量字段的查询 query_expr = \u0026#34;score \u0026gt; 0.8\u0026#34; results = collection.query( expr=query_expr, output_fields=[\u0026#34;id\u0026#34;, \u0026#34;text\u0026#34;, \u0026#34;score\u0026#34;, \u0026#34;timestamp\u0026#34;] ) for result in results: print(f\u0026#34;ID: {result[\u0026#39;id\u0026#39;]}, Text: {result[\u0026#39;text\u0026#39;]}, Score: {result[\u0026#39;score\u0026#39;]}\u0026#34;) 复杂查询 # 复杂查询表达式 complex_expr = \u0026#34;\u0026#34;\u0026#34; (score \u0026gt; 0.8 and timestamp \u0026gt; 1640995200) or (score \u0026gt; 0.9 and JSON_CONTAINS(metadata, \u0026#39;\u0026#34;important\u0026#34;: true\u0026#39;)) \u0026#34;\u0026#34;\u0026#34; results = collection.query( expr=complex_expr, output_fields=[\u0026#34;*\u0026#34;], # 输出所有字段 limit=100 ) 分页查询 # 分页查询大量数据 page_size = 1000 offset = 0 while True: results = collection.query( expr=\u0026#34;score \u0026gt; 0.5\u0026#34;, output_fields=[\u0026#34;id\u0026#34;, \u0026#34;text\u0026#34;, \u0026#34;score\u0026#34;], limit=page_size, offset=offset ) if not results: break print(f\u0026#34;Page {offset // page_size + 1}: {len(results)} results\u0026#34;) # 处理结果 for result in results: # 处理每个结果 pass offset += page_size 7. 索引管理 索引类型 FLAT索引 # FLAT索引 - 精确搜索，适合小数据集 flat_index = { \u0026#34;index_type\u0026#34;: \u0026#34;FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {} } collection.create_index( field_name=\u0026#34;vector\u0026#34;, index_params=flat_index ) IVF索引 # IVF_FLAT索引 - 平衡性能和精度 ivf_flat_index = { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nlist\u0026#34;: 128 # 聚类中心数量 } } # IVF_PQ索引 - 压缩存储，适合大数据集 ivf_pq_index = { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_PQ\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nlist\u0026#34;: 128, \u0026#34;m\u0026#34;: 16, # PQ分段数 \u0026#34;nbits\u0026#34;: 8 # 每段的位数 } } collection.create_index(field_name=\u0026#34;vector\u0026#34;, index_params=ivf_pq_index) HNSW索引 # HNSW索引 - 高性能近似搜索 hnsw_index = { \u0026#34;index_type\u0026#34;: \u0026#34;HNSW\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;M\u0026#34;: 16, # 每层的最大连接数 \u0026#34;efConstruction\u0026#34;: 200 # 构建时的搜索深度 } } collection.create_index(field_name=\u0026#34;vector\u0026#34;, index_params=hnsw_index) ANNOY索引 # ANNOY索引 - 内存友好 annoy_index = { \u0026#34;index_type\u0026#34;: \u0026#34;ANNOY\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;n_trees\u0026#34;: 8 # 树的数量 } } collection.create_index(field_name=\u0026#34;vector\u0026#34;, index_params=annoy_index) 距离度量 欧几里得距离（L2） l2_index = { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, # 欧几里得距离 \u0026#34;params\u0026#34;: {\u0026#34;nlist\u0026#34;: 128} } 内积（IP） ip_index = { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;IP\u0026#34;, # 内积 \u0026#34;params\u0026#34;: {\u0026#34;nlist\u0026#34;: 128} } 余弦相似度 # 余弦相似度需要先归一化向量，然后使用IP import numpy as np def normalize_vectors(vectors): \u0026#34;\u0026#34;\u0026#34;归一化向量以使用余弦相似度\u0026#34;\u0026#34;\u0026#34; vectors = np.array(vectors) norms = np.linalg.norm(vectors, axis=1, keepdims=True) return (vectors / norms).tolist() # 插入归一化后的向量 normalized_vectors = normalize_vectors(original_vectors) entities = [ids, normalized_vectors, texts, scores, timestamps, metadata] collection.insert(entities) # 使用IP度量进行余弦相似度搜索 cosine_index = { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;IP\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nlist\u0026#34;: 128} } 索引管理操作 查看索引信息 # 获取索引信息 index_info = collection.index() print(f\u0026#34;Index type: {index_info.params[\u0026#39;index_type\u0026#39;]}\u0026#34;) print(f\u0026#34;Metric type: {index_info.params[\u0026#39;metric_type\u0026#39;]}\u0026#34;) print(f\u0026#34;Index params: {index_info.params[\u0026#39;params\u0026#39;]}\u0026#34;) # 检查索引构建进度 from pymilvus import utility index_progress = utility.index_building_progress(\u0026#34;collection_name\u0026#34;) print(f\u0026#34;Index building progress: {index_progress}\u0026#34;) 重建索引 # 删除现有索引 collection.drop_index() # 创建新索引 new_index = { \u0026#34;index_type\u0026#34;: \u0026#34;HNSW\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;M\u0026#34;: 32, \u0026#34;efConstruction\u0026#34;: 400} } collection.create_index(field_name=\u0026#34;vector\u0026#34;, index_params=new_index) # 等待索引构建完成 import time while True: progress = utility.index_building_progress(collection.name) if progress[\u0026#39;pending_index_rows\u0026#39;] == 0: break print(f\u0026#34;Index building progress: {progress}\u0026#34;) time.sleep(5) print(\u0026#34;Index building completed\u0026#34;) 8. 性能优化 搜索参数优化 IVF索引优化 # 根据数据量调整nlist data_size = collection.num_entities optimal_nlist = int(np.sqrt(data_size)) optimal_nlist = max(128, min(optimal_nlist, 4096)) # 限制在合理范围内 # 搜索时调整nprobe search_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nprobe\u0026#34;: min(optimal_nlist // 4, 64) # 通常设置为nlist的1/4 } } HNSW索引优化 # 构建时参数 hnsw_build_params = { \u0026#34;index_type\u0026#34;: \u0026#34;HNSW\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;M\u0026#34;: 16, # 连接数，影响精度和内存 \u0026#34;efConstruction\u0026#34;: 200 # 构建时搜索深度 } } # 搜索时参数 hnsw_search_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;ef\u0026#34;: 100 # 搜索时的候选数量，越大精度越高但速度越慢 } } 内存管理 集合加载策略 # 部分加载 - 只加载需要的字段 collection.load(replica_number=1, _resource_groups=[\u0026#34;default\u0026#34;]) # 释放不需要的集合 collection.release() # 检查内存使用 from pymilvus import utility memory_info = utility.get_query_segment_info(collection.name) for info in memory_info: print(f\u0026#34;Segment {info.segmentID}: {info.mem_size} bytes\u0026#34;) 分区加载 # 只加载特定分区 collection.load(partition_names=[\u0026#34;partition_2024\u0026#34;]) # 动态加载/释放分区 def load_partition_by_date(date_str): partition_name = f\u0026#34;partition_{date_str}\u0026#34; if partition_name in [p.name for p in collection.partitions]: collection.load(partition_names=[partition_name]) return True return False def release_old_partitions(keep_days=7): from datetime import datetime, timedelta cutoff_date = datetime.now() - timedelta(days=keep_days) for partition in collection.partitions: if partition.name.startswith(\u0026#34;partition_\u0026#34;): date_str = partition.name.replace(\u0026#34;partition_\u0026#34;, \u0026#34;\u0026#34;) try: partition_date = datetime.strptime(date_str, \u0026#34;%Y%m%d\u0026#34;) if partition_date \u0026lt; cutoff_date: collection.release(partition_names=[partition.name]) print(f\u0026#34;Released partition: {partition.name}\u0026#34;) except ValueError: continue 批处理优化 批量插入优化 def optimized_batch_insert(collection, data, batch_size=10000): \u0026#34;\u0026#34;\u0026#34;优化的批量插入函数\u0026#34;\u0026#34;\u0026#34; total_entities = len(data[0]) for i in range(0, total_entities, batch_size): end_idx = min(i + batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] # 插入批次 collection.insert(batch_data) # 定期刷新 if (i + batch_size) % 50000 == 0: collection.flush() print(f\u0026#34;Inserted and flushed {i + batch_size} entities\u0026#34;) # 最终刷新 collection.flush() print(f\u0026#34;Completed insertion of {total_entities} entities\u0026#34;) 并行搜索 import concurrent.futures import threading def parallel_search(collection, query_vectors, search_params, max_workers=4): \u0026#34;\u0026#34;\u0026#34;并行执行多个搜索请求\u0026#34;\u0026#34;\u0026#34; def search_batch(vectors_batch): return collection.search( data=vectors_batch, anns_field=\u0026#34;vector\u0026#34;, param=search_params, limit=10 ) # 将查询向量分批 batch_size = len(query_vectors) // max_workers batches = [query_vectors[i:i+batch_size] for i in range(0, len(query_vectors), batch_size)] # 并行执行搜索 with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: future_to_batch = {executor.submit(search_batch, batch): batch for batch in batches} all_results = [] for future in concurrent.futures.as_completed(future_to_batch): batch_results = future.result() all_results.extend(batch_results) return all_results 连接池管理 from pymilvus import connections import threading class MilvusConnectionPool: def __init__(self, host=\u0026#39;localhost\u0026#39;, port=\u0026#39;19530\u0026#39;, pool_size=10): self.host = host self.port = port self.pool_size = pool_size self.connections = [] self.lock = threading.Lock() self._initialize_pool() def _initialize_pool(self): for i in range(self.pool_size): alias = f\u0026#34;connection_{i}\u0026#34; connections.connect( alias=alias, host=self.host, port=self.port ) self.connections.append(alias) def get_connection(self): with self.lock: if self.connections: return self.connections.pop() else: # 如果池为空，创建新连接 alias = f\u0026#34;temp_connection_{threading.current_thread().ident}\u0026#34; connections.connect( alias=alias, host=self.host, port=self.port ) return alias def return_connection(self, alias): with self.lock: if len(self.connections) \u0026lt; self.pool_size: self.connections.append(alias) else: connections.disconnect(alias) # 使用连接池 pool = MilvusConnectionPool() def search_with_pool(query_vector): alias = pool.get_connection() try: # 使用指定连接执行搜索 connections.connect(alias=alias) collection = Collection(\u0026#34;documents\u0026#34;, using=alias) results = collection.search( data=[query_vector], anns_field=\u0026#34;vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}}, limit=10 ) return results finally: pool.return_connection(alias) 9. 集群部署 Kubernetes集群部署 1. 准备配置文件 # milvus-cluster-values.yaml cluster: enabled: true image: all: repository: milvusdb/milvus tag: v2.3.0 pullPolicy: IfNotPresent service: type: LoadBalancer port: 19530 portName: milvus nodePort: 30530 rootCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryNode: replicas: 2 resources: limits: cpu: 2 memory: 8Gi requests: cpu: 1 memory: 4Gi indexNode: replicas: 1 resources: limits: cpu: 2 memory: 4Gi requests: cpu: 1 memory: 2Gi dataNode: replicas: 2 resources: limits: cpu: 1 memory: 4Gi requests: cpu: 0.5 memory: 2Gi proxy: replicas: 2 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi # 存储配置 minio: enabled: true mode: distributed replicas: 4 persistence: enabled: true size: 100Gi storageClass: \u0026#34;fast-ssd\u0026#34; etcd: enabled: true replicaCount: 3 persistence: enabled: true size: 10Gi storageClass: \u0026#34;fast-ssd\u0026#34; pulsar: enabled: true components: broker: true bookkeeper: true zookeeper: true zookeeper: replicaCount: 3 bookkeeper: replicaCount: 3 broker: replicaCount: 2 2. 部署集群 # 创建命名空间 kubectl create namespace milvus-cluster # 部署Milvus集群 helm install milvus-cluster milvus/milvus \\ --namespace milvus-cluster \\ --values milvus-cluster-values.yaml # 检查部署状态 kubectl get pods -n milvus-cluster kubectl get services -n milvus-cluster 3. 配置负载均衡 # milvus-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: milvus-ingress namespace: milvus-cluster annotations: nginx.ingress.kubernetes.io/backend-protocol: \u0026#34;GRPC\u0026#34; nginx.ingress.kubernetes.io/grpc-backend: \u0026#34;true\u0026#34; spec: ingressClassName: nginx rules: - host: milvus.example.com http: paths: - path: / pathType: Prefix backend: service: name: milvus-cluster port: number: 19530 高可用配置 多副本配置 # 连接到集群 connections.connect( alias=\u0026#34;cluster\u0026#34;, host=\u0026#39;milvus.example.com\u0026#39;, port=\u0026#39;19530\u0026#39; ) # 创建集合时指定副本数 collection = Collection(\u0026#34;ha_collection\u0026#34;, schema=schema) collection.create_index(field_name=\u0026#34;vector\u0026#34;, index_params=index_params) # 加载时指定副本数 collection.load(replica_number=2) # 检查副本状态 from pymilvus import utility replica_info = utility.get_replicas(collection.name) for replica in replica_info: print(f\u0026#34;Replica {replica.id}: {replica.node_ids}\u0026#34;) 故障转移测试 def test_failover(collection): \u0026#34;\u0026#34;\u0026#34;测试故障转移能力\u0026#34;\u0026#34;\u0026#34; import time import random query_vector = [random.random() for _ in range(256)] # 持续查询测试 success_count = 0 total_count = 0 for i in range(100): try: results = collection.search( data=[query_vector], anns_field=\u0026#34;vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}}, limit=10 ) success_count += 1 print(f\u0026#34;Query {i}: Success\u0026#34;) except Exception as e: print(f\u0026#34;Query {i}: Failed - {e}\u0026#34;) total_count += 1 time.sleep(1) print(f\u0026#34;Success rate: {success_count/total_count*100:.2f}%\u0026#34;) 数据分片策略 基于时间的分片 from datetime import datetime, timedelta def create_time_based_partitions(collection, start_date, end_date): \u0026#34;\u0026#34;\u0026#34;创建基于时间的分区\u0026#34;\u0026#34;\u0026#34; current_date = start_date while current_date \u0026lt;= end_date: partition_name = f\u0026#34;partition_{current_date.strftime(\u0026#39;%Y%m%d\u0026#39;)}\u0026#34; try: collection.create_partition(partition_name) print(f\u0026#34;Created partition: {partition_name}\u0026#34;) except Exception as e: print(f\u0026#34;Partition {partition_name} already exists or error: {e}\u0026#34;) current_date += timedelta(days=1) def insert_with_time_partition(collection, entities, timestamp_field_idx=4): \u0026#34;\u0026#34;\u0026#34;根据时间戳插入到对应分区\u0026#34;\u0026#34;\u0026#34; # 按时间戳分组数据 partition_data = {} for i, timestamp in enumerate(entities[timestamp_field_idx]): date_str = datetime.fromtimestamp(timestamp).strftime(\u0026#39;%Y%m%d\u0026#39;) partition_name = f\u0026#34;partition_{date_str}\u0026#34; if partition_name not in partition_data: partition_data[partition_name] = [[] for _ in entities] for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 分别插入到各个分区 for partition_name, partition_entities in partition_data.items(): try: collection.insert(partition_entities, partition_name=partition_name) print(f\u0026#34;Inserted {len(partition_entities[0])} entities to {partition_name}\u0026#34;) except Exception as e: print(f\u0026#34;Failed to insert to {partition_name}: {e}\u0026#34;) 基于哈希的分片 import hashlib def create_hash_based_partitions(collection, num_partitions=8): \u0026#34;\u0026#34;\u0026#34;创建基于哈希的分区\u0026#34;\u0026#34;\u0026#34; for i in range(num_partitions): partition_name = f\u0026#34;partition_hash_{i}\u0026#34; try: collection.create_partition(partition_name) print(f\u0026#34;Created partition: {partition_name}\u0026#34;) except Exception as e: print(f\u0026#34;Partition {partition_name} already exists or error: {e}\u0026#34;) def insert_with_hash_partition(collection, entities, key_field_idx=0, num_partitions=8): \u0026#34;\u0026#34;\u0026#34;根据键值哈希插入到对应分区\u0026#34;\u0026#34;\u0026#34; partition_data = {f\u0026#34;partition_hash_{i}\u0026#34;: [[] for _ in entities] for i in range(num_partitions)} for i, key in enumerate(entities[key_field_idx]): # 计算哈希值确定分区 hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16) partition_idx = hash_value % num_partitions partition_name = f\u0026#34;partition_hash_{partition_idx}\u0026#34; for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 插入到各个分区 for partition_name, partition_entities in partition_data.items(): if partition_entities[0]: # 如果分区有数据 collection.insert(partition_entities, partition_name=partition_name) print(f\u0026#34;Inserted {len(partition_entities[0])} entities to {partition_name}\u0026#34;) 10. 监控运维 系统监控 Prometheus监控配置 # prometheus-config.yaml global: scrape_interval: 15s scrape_configs: - job_name: \u0026#39;milvus\u0026#39; static_configs: - targets: [\u0026#39;milvus:9091\u0026#39;] metrics_path: /metrics scrape_interval: 15s - job_name: \u0026#39;milvus-cluster\u0026#39; kubernetes_sd_configs: - role: pod namespaces: names: - milvus-cluster relabel_configs: - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name] action: keep regex: milvus - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port] action: replace target_label: __address__ regex: (.+) replacement: ${1}:9091 Grafana仪表板 { \u0026#34;dashboard\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Milvus Monitoring\u0026#34;, \u0026#34;panels\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;QPS (Queries Per Second)\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;targets\u0026#34;: [ { \u0026#34;expr\u0026#34;: \u0026#34;rate(milvus_proxy_search_vectors_count[5m])\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;Search QPS\u0026#34; }, { \u0026#34;expr\u0026#34;: \u0026#34;rate(milvus_proxy_insert_vectors_count[5m])\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;Insert QPS\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;Response Time\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;targets\u0026#34;: [ { \u0026#34;expr\u0026#34;: \u0026#34;histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;Search P95 Latency\u0026#34; }, { \u0026#34;expr\u0026#34;: \u0026#34;histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;Search P99 Latency\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;Memory Usage\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;targets\u0026#34;: [ { \u0026#34;expr\u0026#34;: \u0026#34;milvus_querynode_memory_usage_bytes\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;QueryNode Memory\u0026#34; }, { \u0026#34;expr\u0026#34;: \u0026#34;milvus_indexnode_memory_usage_bytes\u0026#34;, \u0026#34;legendFormat\u0026#34;: \u0026#34;IndexNode Memory\u0026#34; } ] }, { \u0026#34;title\u0026#34;: \u0026#34;Collection Statistics\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;table\u0026#34;, \u0026#34;targets\u0026#34;: [ { \u0026#34;expr\u0026#34;: \u0026#34;milvus_collection_num_entities\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;table\u0026#34; } ] } ] } } 性能监控 自定义监控脚本 import time import psutil import threading from pymilvus import connections, Collection, utility from datetime import datetime class MilvusMonitor: def __init__(self, collection_name, interval=60): self.collection_name = collection_name self.interval = interval self.running = False self.metrics = [] def start_monitoring(self): self.running = True monitor_thread = threading.Thread(target=self._monitor_loop) monitor_thread.daemon = True monitor_thread.start() def stop_monitoring(self): self.running = False def _monitor_loop(self): while self.running: try: metrics = self._collect_metrics() self.metrics.append(metrics) print(f\u0026#34;[{metrics[\u0026#39;timestamp\u0026#39;]}] {metrics}\u0026#34;) # 保留最近1000条记录 if len(self.metrics) \u0026gt; 1000: self.metrics = self.metrics[-1000:] except Exception as e: print(f\u0026#34;Monitoring error: {e}\u0026#34;) time.sleep(self.interval) def _collect_metrics(self): collection = Collection(self.collection_name) # 集合统计信息 stats = collection.get_stats() num_entities = int(stats[\u0026#39;row_count\u0026#39;]) # 系统资源 cpu_percent = psutil.cpu_percent() memory = psutil.virtual_memory() disk = psutil.disk_usage(\u0026#39;/\u0026#39;) # 查询性能测试 start_time = time.time() try: test_vector = [0.1] * 256 collection.search( data=[test_vector], anns_field=\u0026#34;vector\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 16}}, limit=10 ) query_latency = (time.time() - start_time) * 1000 # ms except Exception as e: query_latency = -1 return { \u0026#39;timestamp\u0026#39;: datetime.now().isoformat(), \u0026#39;collection_entities\u0026#39;: num_entities, \u0026#39;cpu_percent\u0026#39;: cpu_percent, \u0026#39;memory_percent\u0026#39;: memory.percent, \u0026#39;memory_used_gb\u0026#39;: memory.used / (1024**3), \u0026#39;disk_percent\u0026#39;: disk.percent, \u0026#39;disk_used_gb\u0026#39;: disk.used / (1024**3), \u0026#39;query_latency_ms\u0026#39;: query_latency } def get_metrics_summary(self, last_n=100): \u0026#34;\u0026#34;\u0026#34;获取最近N条记录的统计摘要\u0026#34;\u0026#34;\u0026#34; if not self.metrics: return None recent_metrics = self.metrics[-last_n:] latencies = [m[\u0026#39;query_latency_ms\u0026#39;] for m in recent_metrics if m[\u0026#39;query_latency_ms\u0026#39;] \u0026gt; 0] cpu_usage = [m[\u0026#39;cpu_percent\u0026#39;] for m in recent_metrics] memory_usage = [m[\u0026#39;memory_percent\u0026#39;] for m in recent_metrics] return { \u0026#39;avg_query_latency_ms\u0026#39;: sum(latencies) / len(latencies) if latencies else 0, \u0026#39;max_query_latency_ms\u0026#39;: max(latencies) if latencies else 0, \u0026#39;avg_cpu_percent\u0026#39;: sum(cpu_usage) / len(cpu_usage), \u0026#39;max_cpu_percent\u0026#39;: max(cpu_usage), \u0026#39;avg_memory_percent\u0026#39;: sum(memory_usage) / len(memory_usage), \u0026#39;max_memory_percent\u0026#39;: max(memory_usage), \u0026#39;total_entities\u0026#39;: recent_metrics[-1][\u0026#39;collection_entities\u0026#39;] if recent_metrics else 0 } # 使用监控器 monitor = MilvusMonitor(\u0026#34;documents\u0026#34;, interval=30) monitor.start_monitoring() # 运行一段时间后查看摘要 time.sleep(300) # 5分钟 summary = monitor.get_metrics_summary() print(f\u0026#34;Performance Summary: {summary}\u0026#34;) monitor.stop_monitoring() 日志管理 日志配置 # milvus-log-config.yaml log: level: info file: rootPath: \u0026#34;/var/log/milvus\u0026#34; maxSize: 100 # MB maxAge: 7 # days maxBackups: 10 format: json # 在Kubernetes中配置日志收集 apiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: milvus-cluster data: fluent-bit.conf: | [SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf [INPUT] Name tail Path /var/log/milvus/*.log Parser json Tag milvus.* Refresh_Interval 5 [OUTPUT] Name es Match milvus.* Host elasticsearch.logging.svc.cluster.local Port 9200 Index milvus-logs Type _doc 日志分析脚本 import json import re from datetime import datetime, timedelta from collections import defaultdict def analyze_milvus_logs(log_file_path, hours=24): \u0026#34;\u0026#34;\u0026#34;分析Milvus日志文件\u0026#34;\u0026#34;\u0026#34; cutoff_time = datetime.now() - timedelta(hours=hours) error_counts = defaultdict(int) warning_counts = defaultdict(int) performance_metrics = [] with open(log_file_path, \u0026#39;r\u0026#39;) as f: for line in f: try: log_entry = json.loads(line.strip()) log_time = datetime.fromisoformat(log_entry.get(\u0026#39;time\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;Z\u0026#39;, \u0026#39;+00:00\u0026#39;)) if log_time \u0026lt; cutoff_time: continue level = log_entry.get(\u0026#39;level\u0026#39;, \u0026#39;\u0026#39;).upper() message = log_entry.get(\u0026#39;msg\u0026#39;, \u0026#39;\u0026#39;) # 统计错误和警告 if level == \u0026#39;ERROR\u0026#39;: error_counts[message] += 1 elif level == \u0026#39;WARN\u0026#39;: warning_counts[message] += 1 # 提取性能指标 if \u0026#39;latency\u0026#39; in message.lower(): latency_match = re.search(r\u0026#39;latency[:\\s]+(\\d+(?:\\.\\d+)?)\\s*(ms|μs)\u0026#39;, message) if latency_match: latency_value = float(latency_match.group(1)) latency_unit = latency_match.group(2) if latency_unit == \u0026#39;μs\u0026#39;: latency_value /= 1000 # 转换为ms performance_metrics.append({ \u0026#39;timestamp\u0026#39;: log_time, \u0026#39;latency_ms\u0026#39;: latency_value, \u0026#39;operation\u0026#39;: extract_operation(message) }) except (json.JSONDecodeError, ValueError) as e: continue return { \u0026#39;error_summary\u0026#39;: dict(error_counts), \u0026#39;warning_summary\u0026#39;: dict(warning_counts), \u0026#39;performance_metrics\u0026#39;: performance_metrics } def extract_operation(message): \u0026#34;\u0026#34;\u0026#34;从日志消息中提取操作类型\u0026#34;\u0026#34;\u0026#34; if \u0026#39;search\u0026#39; in message.lower(): return \u0026#39;search\u0026#39; elif \u0026#39;insert\u0026#39; in message.lower(): return \u0026#39;insert\u0026#39; elif \u0026#39;index\u0026#39; in message.lower(): return \u0026#39;index\u0026#39; else: return \u0026#39;unknown\u0026#39; def generate_log_report(analysis_result): \u0026#34;\u0026#34;\u0026#34;生成日志分析报告\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;=== Milvus Log Analysis Report ===\u0026#34;) print(f\u0026#34;Analysis time: {datetime.now()}\u0026#34;) print() # 错误摘要 print(\u0026#34;Top Errors:\u0026#34;) sorted_errors = sorted(analysis_result[\u0026#39;error_summary\u0026#39;].items(), key=lambda x: x[1], reverse=True) for error, count in sorted_errors[:10]: print(f\u0026#34; {count:4d} - {error[:100]}...\u0026#34;) print() # 警告摘要 print(\u0026#34;Top Warnings:\u0026#34;) sorted_warnings = sorted(analysis_result[\u0026#39;warning_summary\u0026#39;].items(), key=lambda x: x[1], reverse=True) for warning, count in sorted_warnings[:10]: print(f\u0026#34; {count:4d} - {warning[:100]}...\u0026#34;) print() # 性能摘要 metrics = analysis_result[\u0026#39;performance_metrics\u0026#39;] if metrics: latencies = [m[\u0026#39;latency_ms\u0026#39;] for m in metrics] print(\u0026#34;Performance Summary:\u0026#34;) print(f\u0026#34; Total operations: {len(metrics)}\u0026#34;) print(f\u0026#34; Average latency: {sum(latencies)/len(latencies):.2f} ms\u0026#34;) print(f\u0026#34; Max latency: {max(latencies):.2f} ms\u0026#34;) print(f\u0026#34; Min latency: {min(latencies):.2f} ms\u0026#34;) # 按操作类型分组 by_operation = defaultdict(list) for metric in metrics: by_operation[metric[\u0026#39;operation\u0026#39;]].append(metric[\u0026#39;latency_ms\u0026#39;]) print(\u0026#34;\\nPerformance by Operation:\u0026#34;) for operation, latencies in by_operation.items(): if latencies: avg_latency = sum(latencies) / len(latencies) print(f\u0026#34; {operation.capitalize()}:\u0026#34;) print(f\u0026#34; Count: {len(latencies)}\u0026#34;) print(f\u0026#34; Avg latency: {avg_latency:.2f} ms\u0026#34;) print(f\u0026#34; Max latency: {max(latencies):.2f} ms\u0026#34;) else: print(\u0026#34;No performance metrics found.\u0026#34;) # 使用示例 if __name__ == \u0026#34;__main__\u0026#34;: log_file = \u0026#34;/path/to/milvus.log\u0026#34; result = analyze_milvus_logs(log_file, hours=24) generate_log_report(result) 11. 最佳实践 1. 数据建模最佳实践 Collection设计原则 # 良好的Collection设计示例 def create_production_collection(name, vector_dim, expected_size): \u0026#34;\u0026#34;\u0026#34;生产环境Collection设计\u0026#34;\u0026#34;\u0026#34; # 根据数据规模选择分片数 shard_num = min(max(expected_size // 1000000, 2), 16) fields = [ # 主键字段 - 使用有意义的ID FieldSchema( name=\u0026#34;id\u0026#34;, dtype=DataType.INT64, is_primary=True, auto_id=False, description=\u0026#34;Document unique identifier\u0026#34; ), # 时间戳字段 - 便于数据管理 FieldSchema( name=\u0026#34;created_at\u0026#34;, dtype=DataType.INT64, description=\u0026#34;Creation timestamp\u0026#34; ), # 分类字段 - 用于过滤 FieldSchema( name=\u0026#34;category\u0026#34;, dtype=DataType.VARCHAR, max_length=50, description=\u0026#34;Document category\u0026#34; ), # 向量字段 - 核心搜索字段 FieldSchema( name=\u0026#34;embedding\u0026#34;, dtype=DataType.FLOAT_VECTOR, dim=vector_dim, description=\u0026#34;Document embedding vector\u0026#34; ), # 元数据字段 - 存储额外信息 FieldSchema( name=\u0026#34;metadata\u0026#34;, dtype=DataType.JSON, description=\u0026#34;Additional metadata\u0026#34; ) ] schema = CollectionSchema( fields=fields, description=f\u0026#34;Production collection for {expected_size} documents\u0026#34;, enable_dynamic_field=True # 允许动态字段 ) collection = Collection( name=name, schema=schema, shards_num=shard_num, consistency_level=\u0026#34;Strong\u0026#34; # 生产环境建议强一致性 ) return collection 分区策略 # 基于时间的分区策略 def create_time_based_partitions(collection, start_date, end_date): \u0026#34;\u0026#34;\u0026#34;创建基于时间的分区\u0026#34;\u0026#34;\u0026#34; from datetime import datetime, timedelta current_date = start_date while current_date \u0026lt;= end_date: partition_name = f\u0026#34;partition_{current_date.strftime(\u0026#39;%Y%m%d\u0026#39;)}\u0026#34; try: collection.create_partition(partition_name) print(f\u0026#34;Created partition: {partition_name}\u0026#34;) except Exception as e: print(f\u0026#34;Partition {partition_name} already exists or error: {e}\u0026#34;) current_date += timedelta(days=1) # 基于类别的分区策略 def create_category_partitions(collection, categories): \u0026#34;\u0026#34;\u0026#34;创建基于类别的分区\u0026#34;\u0026#34;\u0026#34; for category in categories: partition_name = f\u0026#34;category_{category.lower()}\u0026#34; try: collection.create_partition(partition_name) print(f\u0026#34;Created partition: {partition_name}\u0026#34;) except Exception as e: print(f\u0026#34;Partition {partition_name} already exists or error: {e}\u0026#34;) 2. 性能优化最佳实践 索引选择策略 def choose_optimal_index(data_size, memory_budget, latency_requirement, accuracy_requirement): \u0026#34;\u0026#34;\u0026#34;根据需求选择最优索引\u0026#34;\u0026#34;\u0026#34; if data_size \u0026lt; 100000: # 小数据集使用FLAT return { \u0026#34;index_type\u0026#34;: \u0026#34;FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {} } elif latency_requirement == \u0026#34;ultra_low\u0026#34; and memory_budget == \u0026#34;high\u0026#34;: # 超低延迟需求使用HNSW return { \u0026#34;index_type\u0026#34;: \u0026#34;HNSW\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;M\u0026#34;: 32, \u0026#34;efConstruction\u0026#34;: 400 } } elif memory_budget == \u0026#34;low\u0026#34;: # 内存受限使用PQ压缩 return { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_PQ\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nlist\u0026#34;: min(4 * int(np.sqrt(data_size)), 4096), \u0026#34;m\u0026#34;: 16, \u0026#34;nbits\u0026#34;: 8 } } else: # 平衡选择IVF_FLAT return { \u0026#34;index_type\u0026#34;: \u0026#34;IVF_FLAT\u0026#34;, \u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;nlist\u0026#34;: min(4 * int(np.sqrt(data_size)), 4096) } } # 动态调整搜索参数 def get_adaptive_search_params(index_type, accuracy_level=\u0026#34;medium\u0026#34;, data_size=None): \u0026#34;\u0026#34;\u0026#34;根据索引类型和精度要求动态调整搜索参数\u0026#34;\u0026#34;\u0026#34; if index_type == \u0026#34;IVF_FLAT\u0026#34; or index_type == \u0026#34;IVF_PQ\u0026#34;: nprobe_map = { \u0026#34;low\u0026#34;: max(8, int(np.sqrt(data_size)) // 100) if data_size else 8, \u0026#34;medium\u0026#34;: max(16, int(np.sqrt(data_size)) // 50) if data_size else 16, \u0026#34;high\u0026#34;: max(32, int(np.sqrt(data_size)) // 25) if data_size else 32 } return {\u0026#34;nprobe\u0026#34;: nprobe_map[accuracy_level]} elif index_type == \u0026#34;HNSW\u0026#34;: ef_map = {\u0026#34;low\u0026#34;: 64, \u0026#34;medium\u0026#34;: 128, \u0026#34;high\u0026#34;: 256} return {\u0026#34;ef\u0026#34;: ef_map[accuracy_level]} elif index_type == \u0026#34;ANNOY\u0026#34;: search_k_map = {\u0026#34;low\u0026#34;: 100, \u0026#34;medium\u0026#34;: 200, \u0026#34;high\u0026#34;: 400} return {\u0026#34;search_k\u0026#34;: search_k_map[accuracy_level]} return {} 批处理优化 class OptimizedBatchProcessor: \u0026#34;\u0026#34;\u0026#34;优化的批处理器\u0026#34;\u0026#34;\u0026#34; def __init__(self, collection, batch_size=10000, flush_interval=50000): self.collection = collection self.batch_size = batch_size self.flush_interval = flush_interval self.total_inserted = 0 def insert_batch(self, data): \u0026#34;\u0026#34;\u0026#34;批量插入数据\u0026#34;\u0026#34;\u0026#34; total_entities = len(data[0]) for i in range(0, total_entities, self.batch_size): end_idx = min(i + self.batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] try: result = self.collection.insert(batch_data) self.total_inserted += len(result.primary_keys) # 定期刷新 if self.total_inserted % self.flush_interval == 0: self.collection.flush() print(f\u0026#34;Flushed after inserting {self.total_inserted} entities\u0026#34;) except Exception as e: print(f\u0026#34;Error inserting batch {i//self.batch_size}: {e}\u0026#34;) continue # 最终刷新 self.collection.flush() return self.total_inserted def parallel_search(self, query_vectors, search_params, max_workers=4): \u0026#34;\u0026#34;\u0026#34;并行搜索\u0026#34;\u0026#34;\u0026#34; import concurrent.futures def search_single(query_vector): return self.collection.search( data=[query_vector], anns_field=\u0026#34;embedding\u0026#34;, param=search_params, limit=10 ) with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: futures = [executor.submit(search_single, qv) for qv in query_vectors] results = [future.result() for future in concurrent.futures.as_completed(futures)] return results 3. 数据质量最佳实践 向量预处理 import numpy as np from sklearn.preprocessing import normalize def preprocess_vectors(vectors, normalization=\u0026#34;l2\u0026#34;, dimension_check=True): \u0026#34;\u0026#34;\u0026#34;向量预处理管道\u0026#34;\u0026#34;\u0026#34; vectors = np.array(vectors, dtype=np.float32) # 维度检查 if dimension_check and len(vectors.shape) != 2: raise ValueError(f\u0026#34;Expected 2D array, got {len(vectors.shape)}D\u0026#34;) # 检查NaN和无穷值 if np.any(np.isnan(vectors)) or np.any(np.isinf(vectors)): print(\u0026#34;Warning: Found NaN or infinite values, replacing with zeros\u0026#34;) vectors = np.nan_to_num(vectors, nan=0.0, posinf=0.0, neginf=0.0) # 归一化 if normalization == \u0026#34;l2\u0026#34;: vectors = normalize(vectors, norm=\u0026#39;l2\u0026#39;, axis=1) elif normalization == \u0026#34;minmax\u0026#34;: from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() vectors = scaler.fit_transform(vectors) return vectors.tolist() # 数据验证 def validate_data_quality(data, schema): \u0026#34;\u0026#34;\u0026#34;验证数据质量\u0026#34;\u0026#34;\u0026#34; issues = [] # 检查数据长度一致性 field_lengths = [len(field_data) for field_data in data] if len(set(field_lengths)) \u0026gt; 1: issues.append(f\u0026#34;Inconsistent field lengths: {field_lengths}\u0026#34;) # 检查向量维度 for i, field in enumerate(schema.fields): if field.dtype == DataType.FLOAT_VECTOR: vectors = data[i] expected_dim = field.params.get(\u0026#39;dim\u0026#39;) for j, vector in enumerate(vectors[:100]): # 检查前100个 if len(vector) != expected_dim: issues.append(f\u0026#34;Vector {j} has dimension {len(vector)}, expected {expected_dim}\u0026#34;) break return issues 4. 监控和运维最佳实践 健康检查系统 import time import logging from datetime import datetime class MilvusHealthMonitor: \u0026#34;\u0026#34;\u0026#34;Milvus健康监控系统\u0026#34;\u0026#34;\u0026#34; def __init__(self, collection_names, alert_thresholds=None): self.collection_names = collection_names self.alert_thresholds = alert_thresholds or { \u0026#39;query_latency\u0026#39;: 1.0, # 秒 \u0026#39;memory_usage\u0026#39;: 0.8, # 80% \u0026#39;error_rate\u0026#39;: 0.05 # 5% } self.logger = self._setup_logger() def _setup_logger(self): logger = logging.getLogger(\u0026#39;milvus_monitor\u0026#39;) logger.setLevel(logging.INFO) handler = logging.FileHandler(\u0026#39;milvus_health.log\u0026#39;) formatter = logging.Formatter(\u0026#39;%(asctime)s - %(levelname)s - %(message)s\u0026#39;) handler.setFormatter(formatter) logger.addHandler(handler) return logger def check_connection_health(self): \u0026#34;\u0026#34;\u0026#34;检查连接健康状态\u0026#34;\u0026#34;\u0026#34; try: from pymilvus import utility version = utility.get_server_version() self.logger.info(f\u0026#34;Milvus server version: {version}\u0026#34;) return True except Exception as e: self.logger.error(f\u0026#34;Connection health check failed: {e}\u0026#34;) return False def check_collection_health(self, collection_name): \u0026#34;\u0026#34;\u0026#34;检查集合健康状态\u0026#34;\u0026#34;\u0026#34; try: collection = Collection(collection_name) # 检查集合状态 stats = collection.get_stats() num_entities = collection.num_entities # 执行测试查询 start_time = time.time() test_vector = [[0.1] * 128] # 假设128维向量 results = collection.search( data=test_vector, anns_field=\u0026#34;embedding\u0026#34;, param={\u0026#34;metric_type\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 10}}, limit=1 ) query_latency = time.time() - start_time # 记录指标 metrics = { \u0026#39;collection\u0026#39;: collection_name, \u0026#39;num_entities\u0026#39;: num_entities, \u0026#39;query_latency\u0026#39;: query_latency, \u0026#39;timestamp\u0026#39;: datetime.now().isoformat() } self.logger.info(f\u0026#34;Collection health: {metrics}\u0026#34;) # 检查告警阈值 if query_latency \u0026gt; self.alert_thresholds[\u0026#39;query_latency\u0026#39;]: self.logger.warning(f\u0026#34;High query latency: {query_latency:.3f}s\u0026#34;) return metrics except Exception as e: self.logger.error(f\u0026#34;Collection health check failed for {collection_name}: {e}\u0026#34;) return None def run_continuous_monitoring(self, interval=60): \u0026#34;\u0026#34;\u0026#34;持续监控\u0026#34;\u0026#34;\u0026#34; while True: try: # 检查连接 if not self.check_connection_health(): self.logger.critical(\u0026#34;Milvus connection lost!\u0026#34;) # 检查所有集合 for collection_name in self.collection_names: self.check_collection_health(collection_name) time.sleep(interval) except KeyboardInterrupt: self.logger.info(\u0026#34;Monitoring stopped by user\u0026#34;) break except Exception as e: self.logger.error(f\u0026#34;Monitoring error: {e}\u0026#34;) time.sleep(interval) 备份和恢复策略 import json import os from datetime import datetime class MilvusBackupManager: \u0026#34;\u0026#34;\u0026#34;Milvus备份管理器\u0026#34;\u0026#34;\u0026#34; def __init__(self, backup_dir=\u0026#34;./milvus_backups\u0026#34;): self.backup_dir = backup_dir os.makedirs(backup_dir, exist_ok=True) def backup_collection_metadata(self, collection_name): \u0026#34;\u0026#34;\u0026#34;备份集合元数据\u0026#34;\u0026#34;\u0026#34; try: collection = Collection(collection_name) # 收集元数据 metadata = { \u0026#39;name\u0026#39;: collection.name, \u0026#39;description\u0026#39;: collection.description, \u0026#39;schema\u0026#39;: { \u0026#39;fields\u0026#39;: [ { \u0026#39;name\u0026#39;: field.name, \u0026#39;dtype\u0026#39;: str(field.dtype), \u0026#39;params\u0026#39;: field.params, \u0026#39;is_primary\u0026#39;: field.is_primary, \u0026#39;auto_id\u0026#39;: field.auto_id } for field in collection.schema.fields ], \u0026#39;enable_dynamic_field\u0026#39;: collection.schema.enable_dynamic_field }, \u0026#39;num_entities\u0026#39;: collection.num_entities, \u0026#39;partitions\u0026#39;: [p.name for p in collection.partitions], \u0026#39;indexes\u0026#39;: [] } # 获取索引信息 try: index_info = collection.index() if index_info: metadata[\u0026#39;indexes\u0026#39;].append({ \u0026#39;field_name\u0026#39;: \u0026#39;embedding\u0026#39;, # 假设向量字段名 \u0026#39;index_params\u0026#39;: index_info.params }) except: pass # 保存元数据 timestamp = datetime.now().strftime(\u0026#34;%Y%m%d_%H%M%S\u0026#34;) backup_file = f\u0026#34;{self.backup_dir}/{collection_name}_metadata_{timestamp}.json\u0026#34; with open(backup_file, \u0026#39;w\u0026#39;) as f: json.dump(metadata, f, indent=2) print(f\u0026#34;Metadata backup saved: {backup_file}\u0026#34;) return backup_file except Exception as e: print(f\u0026#34;Backup failed: {e}\u0026#34;) return None def restore_collection_from_metadata(self, backup_file): \u0026#34;\u0026#34;\u0026#34;从元数据恢复集合结构\u0026#34;\u0026#34;\u0026#34; try: with open(backup_file, \u0026#39;r\u0026#39;) as f: metadata = json.load(f) # 重建字段 fields = [] for field_info in metadata[\u0026#39;schema\u0026#39;][\u0026#39;fields\u0026#39;]: field = FieldSchema( name=field_info[\u0026#39;name\u0026#39;], dtype=getattr(DataType, field_info[\u0026#39;dtype\u0026#39;].split(\u0026#39;.\u0026#39;)[-1]), is_primary=field_info.get(\u0026#39;is_primary\u0026#39;, False), auto_id=field_info.get(\u0026#39;auto_id\u0026#39;, False), **field_info.get(\u0026#39;params\u0026#39;, {}) ) fields.append(field) # 重建schema schema = CollectionSchema( fields=fields, description=metadata[\u0026#39;description\u0026#39;], enable_dynamic_field=metadata[\u0026#39;schema\u0026#39;][\u0026#39;enable_dynamic_field\u0026#39;] ) # 创建集合 collection = Collection( name=metadata[\u0026#39;name\u0026#39;], schema=schema ) # 重建分区 for partition_name in metadata[\u0026#39;partitions\u0026#39;]: if partition_name != \u0026#39;_default\u0026#39;: collection.create_partition(partition_name) print(f\u0026#34;Collection {metadata[\u0026#39;name\u0026#39;]} restored from backup\u0026#34;) return collection except Exception as e: print(f\u0026#34;Restore failed: {e}\u0026#34;) return None 5. 安全最佳实践 访问控制 from pymilvus import connections # 安全连接配置 def secure_connect(host, port, username, password, secure=True): \u0026#34;\u0026#34;\u0026#34;安全连接到Milvus\u0026#34;\u0026#34;\u0026#34; try: connections.connect( alias=\u0026#34;secure_connection\u0026#34;, host=host, port=port, user=username, password=password, secure=secure, server_pem_path=\u0026#34;/path/to/server.pem\u0026#34;, # TLS证书路径 server_name=\u0026#34;milvus-server\u0026#34;, timeout=30 ) print(\u0026#34;Secure connection established\u0026#34;) return True except Exception as e: print(f\u0026#34;Secure connection failed: {e}\u0026#34;) return False # 输入验证 def validate_search_input(query_vectors, limit, expr=None): \u0026#34;\u0026#34;\u0026#34;验证搜索输入\u0026#34;\u0026#34;\u0026#34; # 验证向量 if not isinstance(query_vectors, list) or not query_vectors: raise ValueError(\u0026#34;Query vectors must be a non-empty list\u0026#34;) # 验证limit if not isinstance(limit, int) or limit \u0026lt;= 0 or limit \u0026gt; 10000: raise ValueError(\u0026#34;Limit must be a positive integer \u0026lt;= 10000\u0026#34;) # 验证表达式（防止注入） if expr: dangerous_keywords = [\u0026#39;DROP\u0026#39;, \u0026#39;DELETE\u0026#39;, \u0026#39;UPDATE\u0026#39;, \u0026#39;INSERT\u0026#39;, \u0026#39;CREATE\u0026#39;] expr_upper = expr.upper() for keyword in dangerous_keywords: if keyword in expr_upper: raise ValueError(f\u0026#34;Dangerous keyword \u0026#39;{keyword}\u0026#39; found in expression\u0026#34;) return True 12. 常见问题 Q1: 如何选择合适的索引类型？ A: 索引选择主要考虑以下因素：\n","keywords":["Milvus","向量数据库","向量检索","分布式","搜索引擎"],"articleBody":"1. Milvus简介 什么是Milvus Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。\n主要特性 高性能：支持十亿级向量的毫秒级检索 多样化索引：支持多种向量索引算法（IVF、HNSW、ANNOY等） 云原生：基于Kubernetes的分布式架构 多语言SDK：支持Python、Java、Go、Node.js等 ACID事务：保证数据一致性 混合搜索：支持向量和标量数据的混合查询 应用场景 推荐系统：基于用户行为向量进行个性化推荐 图像检索：以图搜图、相似图片查找 文本搜索：语义搜索、文档相似性匹配 视频分析：视频内容检索和分析 药物发现：分子结构相似性搜索 异常检测：基于向量距离的异常识别 2. 核心概念 基本术语 Collection（集合） 类似于关系数据库中的表，用于存储向量数据和相关的标量字段。\nField（字段） 集合中的列，包括向量字段和标量字段。\nEntity（实体） 集合中的一行数据，包含多个字段的值。\nPartition（分区） 集合的子集，用于数据分片和查询优化。\nIndex（索引） 为加速向量检索而构建的数据结构。\nSegment（段） Milvus内部的数据存储单元，用于数据管理和查询优化。\n数据类型 向量类型 FloatVector：浮点数向量 BinaryVector：二进制向量 标量类型 Bool：布尔值 Int8/Int16/Int32/Int64：整数 Float/Double：浮点数 String/VarChar：字符串 JSON：JSON对象 3. 安装部署 系统要求 硬件要求 CPU：x86_64架构，支持SSE4.2指令集 内存：8GB以上（推荐16GB+） 存储：SSD硬盘（推荐NVMe） 网络：千兆网卡 软件要求 操作系统：Ubuntu 18.04+、CentOS 7+、macOS 10.14+ Docker：20.10+ Docker Compose：1.28+ Docker安装（推荐） 1. 下载配置文件 # 下载docker-compose.yml wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml 2. 启动Milvus # 启动服务 docker-compose up -d # 检查服务状态 docker-compose ps 3. 验证安装 # 检查Milvus是否正常运行 curl -X GET \"http://localhost:9091/health\" Kubernetes部署 1. 安装Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash 2. 添加Milvus Helm仓库 helm repo add milvus https://milvus-io.github.io/milvus-helm/ helm repo update 3. 部署Milvus # 创建命名空间 kubectl create namespace milvus # 部署Milvus集群 helm install milvus milvus/milvus --namespace milvus 源码编译安装 1. 安装依赖 # Ubuntu/Debian sudo apt update sudo apt install -y build-essential cmake libopenblas-dev # CentOS/RHEL sudo yum groupinstall -y \"Development Tools\" sudo yum install -y cmake openblas-devel 2. 编译安装 # 克隆源码 git clone https://github.com/milvus-io/milvus.git cd milvus # 编译 make build # 启动 ./bin/milvus run standalone 4. 快速开始 安装Python SDK pip install pymilvus 基本操作示例 1. 连接Milvus from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType # 连接到Milvus connections.connect( alias=\"default\", host='localhost', port='19530' ) print(\"Connected to Milvus\") 2. 创建集合 # 定义字段 fields = [ FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False), FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=200), FieldSchema(name=\"category\", dtype=DataType.VARCHAR, max_length=50) ] # 创建集合schema schema = CollectionSchema( fields=fields, description=\"Document embedding collection\" ) # 创建集合 collection = Collection( name=\"documents\", schema=schema ) print(\"Collection created\") 3. 插入数据 import random # 准备数据 num_entities = 1000 entities = [ [i for i in range(num_entities)], # id字段 [[random.random() for _ in range(128)] for _ in range(num_entities)], # embedding字段 [f\"Document {i}\" for i in range(num_entities)], # title字段 [f\"Category {i % 10}\" for i in range(num_entities)] # category字段 ] # 插入数据 insert_result = collection.insert(entities) print(f\"Inserted {len(insert_result.primary_keys)} entities\") # 刷新数据到磁盘 collection.flush() 4. 创建索引 # 定义索引参数 index_params = { \"metric_type\": \"L2\", \"index_type\": \"IVF_FLAT\", \"params\": {\"nlist\": 128} } # 创建索引 collection.create_index( field_name=\"embedding\", index_params=index_params ) print(\"Index created\") 5. 加载集合 # 加载集合到内存 collection.load() print(\"Collection loaded\") 6. 向量检索 # 准备查询向量 query_vectors = [[random.random() for _ in range(128)]] # 执行搜索 search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}} results = collection.search( data=query_vectors, anns_field=\"embedding\", param=search_params, limit=10, output_fields=[\"title\", \"category\"] ) # 输出结果 for hits in results: for hit in hits: print(f\"ID: {hit.id}, Distance: {hit.distance}, Title: {hit.entity.get('title')}\") 5. 数据管理 集合管理 创建集合 from pymilvus import Collection, FieldSchema, CollectionSchema, DataType # 定义复杂schema fields = [ FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True), FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=1000), FieldSchema(name=\"score\", dtype=DataType.FLOAT), FieldSchema(name=\"timestamp\", dtype=DataType.INT64), FieldSchema(name=\"metadata\", dtype=DataType.JSON) ] schema = CollectionSchema( fields=fields, description=\"Advanced collection with multiple field types\", enable_dynamic_field=True # 启用动态字段 ) collection = Collection(name=\"advanced_collection\", schema=schema) 查看集合信息 # 获取集合统计信息 stats = collection.get_stats() print(f\"Collection stats: {stats}\") # 获取集合schema schema = collection.schema for field in schema.fields: print(f\"Field: {field.name}, Type: {field.dtype}, Params: {field.params}\") # 检查集合是否存在 from pymilvus import utility has_collection = utility.has_collection(\"advanced_collection\") print(f\"Collection exists: {has_collection}\") 删除集合 # 删除集合 collection.drop() # 或者使用utility函数 utility.drop_collection(\"collection_name\") 分区管理 创建分区 # 创建分区 collection.create_partition(\"partition_2023\") collection.create_partition(\"partition_2024\") # 查看所有分区 partitions = collection.partitions for partition in partitions: print(f\"Partition: {partition.name}\") 分区数据操作 # 向特定分区插入数据 entities = [ [1, 2, 3], # ids [[0.1] * 256, [0.2] * 256, [0.3] * 256], # vectors [\"text1\", \"text2\", \"text3\"], # text [0.8, 0.9, 0.7], # scores [1640995200, 1640995300, 1640995400], # timestamps [{\"key\": \"value1\"}, {\"key\": \"value2\"}, {\"key\": \"value3\"}] # metadata ] collection.insert(entities, partition_name=\"partition_2023\") # 在特定分区中搜索 results = collection.search( data=[[0.1] * 256], anns_field=\"vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}, limit=10, partition_names=[\"partition_2023\"] ) 数据插入和更新 批量插入 import numpy as np # 大批量数据插入 batch_size = 10000 for i in range(0, 100000, batch_size): ids = list(range(i, min(i + batch_size, 100000))) vectors = np.random.random((len(ids), 256)).tolist() texts = [f\"Document {j}\" for j in ids] scores = np.random.random(len(ids)).tolist() timestamps = [1640995200 + j for j in ids] metadata = [{\"batch\": i // batch_size} for _ in ids] entities = [ids, vectors, texts, scores, timestamps, metadata] collection.insert(entities) if i % 50000 == 0: collection.flush() # 定期刷新 print(f\"Inserted {i + len(ids)} entities\") 数据更新（Upsert） # Milvus 2.3+支持upsert操作 update_entities = [ [1, 2, 3], # 更新已存在的ID [[0.5] * 256, [0.6] * 256, [0.7] * 256], # 新的向量 [\"Updated text1\", \"Updated text2\", \"Updated text3\"], # 新的文本 [0.95, 0.96, 0.97], # 新的分数 [1640995500, 1640995600, 1640995700], # 新的时间戳 [{\"updated\": True}, {\"updated\": True}, {\"updated\": True}] # 新的元数据 ] collection.upsert(update_entities) 数据删除 按ID删除 # 删除指定ID的实体 delete_ids = [1, 2, 3, 4, 5] expr = f\"id in {delete_ids}\" collection.delete(expr) # 删除满足条件的实体 expr = \"score \u003c 0.5\" collection.delete(expr) 按条件删除 # 复杂删除条件 expr = \"score \u003c 0.3 and timestamp \u003c 1640995300\" collection.delete(expr) # 使用JSON字段删除 expr = \"JSON_CONTAINS(metadata, '\\\"updated\\\": true')\" collection.delete(expr) 6. 向量检索 基本检索 相似性搜索 # 基本向量搜索 query_vectors = [[0.1] * 256, [0.2] * 256] search_params = { \"metric_type\": \"L2\", \"params\": {\"nprobe\": 16} } results = collection.search( data=query_vectors, anns_field=\"vector\", param=search_params, limit=10, output_fields=[\"text\", \"score\", \"timestamp\"] ) for i, hits in enumerate(results): print(f\"Query {i} results:\") for hit in hits: print(f\" ID: {hit.id}, Distance: {hit.distance:.4f}\") print(f\" Text: {hit.entity.get('text')}\") print(f\" Score: {hit.entity.get('score')}\") 混合搜索 # 向量搜索 + 标量过滤 query_vectors = [[0.1] * 256] search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}} # 添加标量过滤条件 filter_expr = \"score \u003e 0.8 and timestamp \u003e 1640995200\" results = collection.search( data=query_vectors, anns_field=\"vector\", param=search_params, limit=10, expr=filter_expr, output_fields=[\"text\", \"score\", \"timestamp\", \"metadata\"] ) 高级检索 范围搜索 # 搜索距离在指定范围内的向量 from pymilvus import SearchResult query_vectors = [[0.1] * 256] search_params = { \"metric_type\": \"L2\", \"params\": { \"nprobe\": 16, \"radius\": 0.1, # 最大距离 \"range_filter\": 0.05 # 最小距离 } } results = collection.search( data=query_vectors, anns_field=\"vector\", param=search_params, limit=100, output_fields=[\"text\", \"score\"] ) 多向量搜索 # 同时搜索多个向量字段（如果集合有多个向量字段） # 假设有text_vector和image_vector两个字段 # 创建包含多个向量字段的集合 multi_vector_fields = [ FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True), FieldSchema(name=\"text_vector\", dtype=DataType.FLOAT_VECTOR, dim=128), FieldSchema(name=\"image_vector\", dtype=DataType.FLOAT_VECTOR, dim=256), FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=200) ] multi_schema = CollectionSchema(fields=multi_vector_fields) multi_collection = Collection(name=\"multi_vector_collection\", schema=multi_schema) # 分别在不同向量字段上搜索 text_results = multi_collection.search( data=[[0.1] * 128], anns_field=\"text_vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}}, limit=10 ) image_results = multi_collection.search( data=[[0.1] * 256], anns_field=\"image_vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}}, limit=10 ) 查询操作 标量查询 # 基于标量字段的查询 query_expr = \"score \u003e 0.8\" results = collection.query( expr=query_expr, output_fields=[\"id\", \"text\", \"score\", \"timestamp\"] ) for result in results: print(f\"ID: {result['id']}, Text: {result['text']}, Score: {result['score']}\") 复杂查询 # 复杂查询表达式 complex_expr = \"\"\" (score \u003e 0.8 and timestamp \u003e 1640995200) or (score \u003e 0.9 and JSON_CONTAINS(metadata, '\"important\": true')) \"\"\" results = collection.query( expr=complex_expr, output_fields=[\"*\"], # 输出所有字段 limit=100 ) 分页查询 # 分页查询大量数据 page_size = 1000 offset = 0 while True: results = collection.query( expr=\"score \u003e 0.5\", output_fields=[\"id\", \"text\", \"score\"], limit=page_size, offset=offset ) if not results: break print(f\"Page {offset // page_size + 1}: {len(results)} results\") # 处理结果 for result in results: # 处理每个结果 pass offset += page_size 7. 索引管理 索引类型 FLAT索引 # FLAT索引 - 精确搜索，适合小数据集 flat_index = { \"index_type\": \"FLAT\", \"metric_type\": \"L2\", \"params\": {} } collection.create_index( field_name=\"vector\", index_params=flat_index ) IVF索引 # IVF_FLAT索引 - 平衡性能和精度 ivf_flat_index = { \"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": { \"nlist\": 128 # 聚类中心数量 } } # IVF_PQ索引 - 压缩存储，适合大数据集 ivf_pq_index = { \"index_type\": \"IVF_PQ\", \"metric_type\": \"L2\", \"params\": { \"nlist\": 128, \"m\": 16, # PQ分段数 \"nbits\": 8 # 每段的位数 } } collection.create_index(field_name=\"vector\", index_params=ivf_pq_index) HNSW索引 # HNSW索引 - 高性能近似搜索 hnsw_index = { \"index_type\": \"HNSW\", \"metric_type\": \"L2\", \"params\": { \"M\": 16, # 每层的最大连接数 \"efConstruction\": 200 # 构建时的搜索深度 } } collection.create_index(field_name=\"vector\", index_params=hnsw_index) ANNOY索引 # ANNOY索引 - 内存友好 annoy_index = { \"index_type\": \"ANNOY\", \"metric_type\": \"L2\", \"params\": { \"n_trees\": 8 # 树的数量 } } collection.create_index(field_name=\"vector\", index_params=annoy_index) 距离度量 欧几里得距离（L2） l2_index = { \"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", # 欧几里得距离 \"params\": {\"nlist\": 128} } 内积（IP） ip_index = { \"index_type\": \"IVF_FLAT\", \"metric_type\": \"IP\", # 内积 \"params\": {\"nlist\": 128} } 余弦相似度 # 余弦相似度需要先归一化向量，然后使用IP import numpy as np def normalize_vectors(vectors): \"\"\"归一化向量以使用余弦相似度\"\"\" vectors = np.array(vectors) norms = np.linalg.norm(vectors, axis=1, keepdims=True) return (vectors / norms).tolist() # 插入归一化后的向量 normalized_vectors = normalize_vectors(original_vectors) entities = [ids, normalized_vectors, texts, scores, timestamps, metadata] collection.insert(entities) # 使用IP度量进行余弦相似度搜索 cosine_index = { \"index_type\": \"IVF_FLAT\", \"metric_type\": \"IP\", \"params\": {\"nlist\": 128} } 索引管理操作 查看索引信息 # 获取索引信息 index_info = collection.index() print(f\"Index type: {index_info.params['index_type']}\") print(f\"Metric type: {index_info.params['metric_type']}\") print(f\"Index params: {index_info.params['params']}\") # 检查索引构建进度 from pymilvus import utility index_progress = utility.index_building_progress(\"collection_name\") print(f\"Index building progress: {index_progress}\") 重建索引 # 删除现有索引 collection.drop_index() # 创建新索引 new_index = { \"index_type\": \"HNSW\", \"metric_type\": \"L2\", \"params\": {\"M\": 32, \"efConstruction\": 400} } collection.create_index(field_name=\"vector\", index_params=new_index) # 等待索引构建完成 import time while True: progress = utility.index_building_progress(collection.name) if progress['pending_index_rows'] == 0: break print(f\"Index building progress: {progress}\") time.sleep(5) print(\"Index building completed\") 8. 性能优化 搜索参数优化 IVF索引优化 # 根据数据量调整nlist data_size = collection.num_entities optimal_nlist = int(np.sqrt(data_size)) optimal_nlist = max(128, min(optimal_nlist, 4096)) # 限制在合理范围内 # 搜索时调整nprobe search_params = { \"metric_type\": \"L2\", \"params\": { \"nprobe\": min(optimal_nlist // 4, 64) # 通常设置为nlist的1/4 } } HNSW索引优化 # 构建时参数 hnsw_build_params = { \"index_type\": \"HNSW\", \"metric_type\": \"L2\", \"params\": { \"M\": 16, # 连接数，影响精度和内存 \"efConstruction\": 200 # 构建时搜索深度 } } # 搜索时参数 hnsw_search_params = { \"metric_type\": \"L2\", \"params\": { \"ef\": 100 # 搜索时的候选数量，越大精度越高但速度越慢 } } 内存管理 集合加载策略 # 部分加载 - 只加载需要的字段 collection.load(replica_number=1, _resource_groups=[\"default\"]) # 释放不需要的集合 collection.release() # 检查内存使用 from pymilvus import utility memory_info = utility.get_query_segment_info(collection.name) for info in memory_info: print(f\"Segment {info.segmentID}: {info.mem_size} bytes\") 分区加载 # 只加载特定分区 collection.load(partition_names=[\"partition_2024\"]) # 动态加载/释放分区 def load_partition_by_date(date_str): partition_name = f\"partition_{date_str}\" if partition_name in [p.name for p in collection.partitions]: collection.load(partition_names=[partition_name]) return True return False def release_old_partitions(keep_days=7): from datetime import datetime, timedelta cutoff_date = datetime.now() - timedelta(days=keep_days) for partition in collection.partitions: if partition.name.startswith(\"partition_\"): date_str = partition.name.replace(\"partition_\", \"\") try: partition_date = datetime.strptime(date_str, \"%Y%m%d\") if partition_date \u003c cutoff_date: collection.release(partition_names=[partition.name]) print(f\"Released partition: {partition.name}\") except ValueError: continue 批处理优化 批量插入优化 def optimized_batch_insert(collection, data, batch_size=10000): \"\"\"优化的批量插入函数\"\"\" total_entities = len(data[0]) for i in range(0, total_entities, batch_size): end_idx = min(i + batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] # 插入批次 collection.insert(batch_data) # 定期刷新 if (i + batch_size) % 50000 == 0: collection.flush() print(f\"Inserted and flushed {i + batch_size} entities\") # 最终刷新 collection.flush() print(f\"Completed insertion of {total_entities} entities\") 并行搜索 import concurrent.futures import threading def parallel_search(collection, query_vectors, search_params, max_workers=4): \"\"\"并行执行多个搜索请求\"\"\" def search_batch(vectors_batch): return collection.search( data=vectors_batch, anns_field=\"vector\", param=search_params, limit=10 ) # 将查询向量分批 batch_size = len(query_vectors) // max_workers batches = [query_vectors[i:i+batch_size] for i in range(0, len(query_vectors), batch_size)] # 并行执行搜索 with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: future_to_batch = {executor.submit(search_batch, batch): batch for batch in batches} all_results = [] for future in concurrent.futures.as_completed(future_to_batch): batch_results = future.result() all_results.extend(batch_results) return all_results 连接池管理 from pymilvus import connections import threading class MilvusConnectionPool: def __init__(self, host='localhost', port='19530', pool_size=10): self.host = host self.port = port self.pool_size = pool_size self.connections = [] self.lock = threading.Lock() self._initialize_pool() def _initialize_pool(self): for i in range(self.pool_size): alias = f\"connection_{i}\" connections.connect( alias=alias, host=self.host, port=self.port ) self.connections.append(alias) def get_connection(self): with self.lock: if self.connections: return self.connections.pop() else: # 如果池为空，创建新连接 alias = f\"temp_connection_{threading.current_thread().ident}\" connections.connect( alias=alias, host=self.host, port=self.port ) return alias def return_connection(self, alias): with self.lock: if len(self.connections) \u003c self.pool_size: self.connections.append(alias) else: connections.disconnect(alias) # 使用连接池 pool = MilvusConnectionPool() def search_with_pool(query_vector): alias = pool.get_connection() try: # 使用指定连接执行搜索 connections.connect(alias=alias) collection = Collection(\"documents\", using=alias) results = collection.search( data=[query_vector], anns_field=\"vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}}, limit=10 ) return results finally: pool.return_connection(alias) 9. 集群部署 Kubernetes集群部署 1. 准备配置文件 # milvus-cluster-values.yaml cluster: enabled: true image: all: repository: milvusdb/milvus tag: v2.3.0 pullPolicy: IfNotPresent service: type: LoadBalancer port: 19530 portName: milvus nodePort: 30530 rootCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryCoordinator: replicas: 1 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi queryNode: replicas: 2 resources: limits: cpu: 2 memory: 8Gi requests: cpu: 1 memory: 4Gi indexNode: replicas: 1 resources: limits: cpu: 2 memory: 4Gi requests: cpu: 1 memory: 2Gi dataNode: replicas: 2 resources: limits: cpu: 1 memory: 4Gi requests: cpu: 0.5 memory: 2Gi proxy: replicas: 2 resources: limits: cpu: 1 memory: 2Gi requests: cpu: 0.5 memory: 1Gi # 存储配置 minio: enabled: true mode: distributed replicas: 4 persistence: enabled: true size: 100Gi storageClass: \"fast-ssd\" etcd: enabled: true replicaCount: 3 persistence: enabled: true size: 10Gi storageClass: \"fast-ssd\" pulsar: enabled: true components: broker: true bookkeeper: true zookeeper: true zookeeper: replicaCount: 3 bookkeeper: replicaCount: 3 broker: replicaCount: 2 2. 部署集群 # 创建命名空间 kubectl create namespace milvus-cluster # 部署Milvus集群 helm install milvus-cluster milvus/milvus \\ --namespace milvus-cluster \\ --values milvus-cluster-values.yaml # 检查部署状态 kubectl get pods -n milvus-cluster kubectl get services -n milvus-cluster 3. 配置负载均衡 # milvus-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: milvus-ingress namespace: milvus-cluster annotations: nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\" nginx.ingress.kubernetes.io/grpc-backend: \"true\" spec: ingressClassName: nginx rules: - host: milvus.example.com http: paths: - path: / pathType: Prefix backend: service: name: milvus-cluster port: number: 19530 高可用配置 多副本配置 # 连接到集群 connections.connect( alias=\"cluster\", host='milvus.example.com', port='19530' ) # 创建集合时指定副本数 collection = Collection(\"ha_collection\", schema=schema) collection.create_index(field_name=\"vector\", index_params=index_params) # 加载时指定副本数 collection.load(replica_number=2) # 检查副本状态 from pymilvus import utility replica_info = utility.get_replicas(collection.name) for replica in replica_info: print(f\"Replica {replica.id}: {replica.node_ids}\") 故障转移测试 def test_failover(collection): \"\"\"测试故障转移能力\"\"\" import time import random query_vector = [random.random() for _ in range(256)] # 持续查询测试 success_count = 0 total_count = 0 for i in range(100): try: results = collection.search( data=[query_vector], anns_field=\"vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}}, limit=10 ) success_count += 1 print(f\"Query {i}: Success\") except Exception as e: print(f\"Query {i}: Failed - {e}\") total_count += 1 time.sleep(1) print(f\"Success rate: {success_count/total_count*100:.2f}%\") 数据分片策略 基于时间的分片 from datetime import datetime, timedelta def create_time_based_partitions(collection, start_date, end_date): \"\"\"创建基于时间的分区\"\"\" current_date = start_date while current_date \u003c= end_date: partition_name = f\"partition_{current_date.strftime('%Y%m%d')}\" try: collection.create_partition(partition_name) print(f\"Created partition: {partition_name}\") except Exception as e: print(f\"Partition {partition_name} already exists or error: {e}\") current_date += timedelta(days=1) def insert_with_time_partition(collection, entities, timestamp_field_idx=4): \"\"\"根据时间戳插入到对应分区\"\"\" # 按时间戳分组数据 partition_data = {} for i, timestamp in enumerate(entities[timestamp_field_idx]): date_str = datetime.fromtimestamp(timestamp).strftime('%Y%m%d') partition_name = f\"partition_{date_str}\" if partition_name not in partition_data: partition_data[partition_name] = [[] for _ in entities] for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 分别插入到各个分区 for partition_name, partition_entities in partition_data.items(): try: collection.insert(partition_entities, partition_name=partition_name) print(f\"Inserted {len(partition_entities[0])} entities to {partition_name}\") except Exception as e: print(f\"Failed to insert to {partition_name}: {e}\") 基于哈希的分片 import hashlib def create_hash_based_partitions(collection, num_partitions=8): \"\"\"创建基于哈希的分区\"\"\" for i in range(num_partitions): partition_name = f\"partition_hash_{i}\" try: collection.create_partition(partition_name) print(f\"Created partition: {partition_name}\") except Exception as e: print(f\"Partition {partition_name} already exists or error: {e}\") def insert_with_hash_partition(collection, entities, key_field_idx=0, num_partitions=8): \"\"\"根据键值哈希插入到对应分区\"\"\" partition_data = {f\"partition_hash_{i}\": [[] for _ in entities] for i in range(num_partitions)} for i, key in enumerate(entities[key_field_idx]): # 计算哈希值确定分区 hash_value = int(hashlib.md5(str(key).encode()).hexdigest(), 16) partition_idx = hash_value % num_partitions partition_name = f\"partition_hash_{partition_idx}\" for j, field_data in enumerate(entities): partition_data[partition_name][j].append(field_data[i]) # 插入到各个分区 for partition_name, partition_entities in partition_data.items(): if partition_entities[0]: # 如果分区有数据 collection.insert(partition_entities, partition_name=partition_name) print(f\"Inserted {len(partition_entities[0])} entities to {partition_name}\") 10. 监控运维 系统监控 Prometheus监控配置 # prometheus-config.yaml global: scrape_interval: 15s scrape_configs: - job_name: 'milvus' static_configs: - targets: ['milvus:9091'] metrics_path: /metrics scrape_interval: 15s - job_name: 'milvus-cluster' kubernetes_sd_configs: - role: pod namespaces: names: - milvus-cluster relabel_configs: - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name] action: keep regex: milvus - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port] action: replace target_label: __address__ regex: (.+) replacement: ${1}:9091 Grafana仪表板 { \"dashboard\": { \"title\": \"Milvus Monitoring\", \"panels\": [ { \"title\": \"QPS (Queries Per Second)\", \"type\": \"graph\", \"targets\": [ { \"expr\": \"rate(milvus_proxy_search_vectors_count[5m])\", \"legendFormat\": \"Search QPS\" }, { \"expr\": \"rate(milvus_proxy_insert_vectors_count[5m])\", \"legendFormat\": \"Insert QPS\" } ] }, { \"title\": \"Response Time\", \"type\": \"graph\", \"targets\": [ { \"expr\": \"histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))\", \"legendFormat\": \"Search P95 Latency\" }, { \"expr\": \"histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))\", \"legendFormat\": \"Search P99 Latency\" } ] }, { \"title\": \"Memory Usage\", \"type\": \"graph\", \"targets\": [ { \"expr\": \"milvus_querynode_memory_usage_bytes\", \"legendFormat\": \"QueryNode Memory\" }, { \"expr\": \"milvus_indexnode_memory_usage_bytes\", \"legendFormat\": \"IndexNode Memory\" } ] }, { \"title\": \"Collection Statistics\", \"type\": \"table\", \"targets\": [ { \"expr\": \"milvus_collection_num_entities\", \"format\": \"table\" } ] } ] } } 性能监控 自定义监控脚本 import time import psutil import threading from pymilvus import connections, Collection, utility from datetime import datetime class MilvusMonitor: def __init__(self, collection_name, interval=60): self.collection_name = collection_name self.interval = interval self.running = False self.metrics = [] def start_monitoring(self): self.running = True monitor_thread = threading.Thread(target=self._monitor_loop) monitor_thread.daemon = True monitor_thread.start() def stop_monitoring(self): self.running = False def _monitor_loop(self): while self.running: try: metrics = self._collect_metrics() self.metrics.append(metrics) print(f\"[{metrics['timestamp']}] {metrics}\") # 保留最近1000条记录 if len(self.metrics) \u003e 1000: self.metrics = self.metrics[-1000:] except Exception as e: print(f\"Monitoring error: {e}\") time.sleep(self.interval) def _collect_metrics(self): collection = Collection(self.collection_name) # 集合统计信息 stats = collection.get_stats() num_entities = int(stats['row_count']) # 系统资源 cpu_percent = psutil.cpu_percent() memory = psutil.virtual_memory() disk = psutil.disk_usage('/') # 查询性能测试 start_time = time.time() try: test_vector = [0.1] * 256 collection.search( data=[test_vector], anns_field=\"vector\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}}, limit=10 ) query_latency = (time.time() - start_time) * 1000 # ms except Exception as e: query_latency = -1 return { 'timestamp': datetime.now().isoformat(), 'collection_entities': num_entities, 'cpu_percent': cpu_percent, 'memory_percent': memory.percent, 'memory_used_gb': memory.used / (1024**3), 'disk_percent': disk.percent, 'disk_used_gb': disk.used / (1024**3), 'query_latency_ms': query_latency } def get_metrics_summary(self, last_n=100): \"\"\"获取最近N条记录的统计摘要\"\"\" if not self.metrics: return None recent_metrics = self.metrics[-last_n:] latencies = [m['query_latency_ms'] for m in recent_metrics if m['query_latency_ms'] \u003e 0] cpu_usage = [m['cpu_percent'] for m in recent_metrics] memory_usage = [m['memory_percent'] for m in recent_metrics] return { 'avg_query_latency_ms': sum(latencies) / len(latencies) if latencies else 0, 'max_query_latency_ms': max(latencies) if latencies else 0, 'avg_cpu_percent': sum(cpu_usage) / len(cpu_usage), 'max_cpu_percent': max(cpu_usage), 'avg_memory_percent': sum(memory_usage) / len(memory_usage), 'max_memory_percent': max(memory_usage), 'total_entities': recent_metrics[-1]['collection_entities'] if recent_metrics else 0 } # 使用监控器 monitor = MilvusMonitor(\"documents\", interval=30) monitor.start_monitoring() # 运行一段时间后查看摘要 time.sleep(300) # 5分钟 summary = monitor.get_metrics_summary() print(f\"Performance Summary: {summary}\") monitor.stop_monitoring() 日志管理 日志配置 # milvus-log-config.yaml log: level: info file: rootPath: \"/var/log/milvus\" maxSize: 100 # MB maxAge: 7 # days maxBackups: 10 format: json # 在Kubernetes中配置日志收集 apiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: milvus-cluster data: fluent-bit.conf: | [SERVICE] Flush 1 Log_Level info Daemon off Parsers_File parsers.conf [INPUT] Name tail Path /var/log/milvus/*.log Parser json Tag milvus.* Refresh_Interval 5 [OUTPUT] Name es Match milvus.* Host elasticsearch.logging.svc.cluster.local Port 9200 Index milvus-logs Type _doc 日志分析脚本 import json import re from datetime import datetime, timedelta from collections import defaultdict def analyze_milvus_logs(log_file_path, hours=24): \"\"\"分析Milvus日志文件\"\"\" cutoff_time = datetime.now() - timedelta(hours=hours) error_counts = defaultdict(int) warning_counts = defaultdict(int) performance_metrics = [] with open(log_file_path, 'r') as f: for line in f: try: log_entry = json.loads(line.strip()) log_time = datetime.fromisoformat(log_entry.get('time', '').replace('Z', '+00:00')) if log_time \u003c cutoff_time: continue level = log_entry.get('level', '').upper() message = log_entry.get('msg', '') # 统计错误和警告 if level == 'ERROR': error_counts[message] += 1 elif level == 'WARN': warning_counts[message] += 1 # 提取性能指标 if 'latency' in message.lower(): latency_match = re.search(r'latency[:\\s]+(\\d+(?:\\.\\d+)?)\\s*(ms|μs)', message) if latency_match: latency_value = float(latency_match.group(1)) latency_unit = latency_match.group(2) if latency_unit == 'μs': latency_value /= 1000 # 转换为ms performance_metrics.append({ 'timestamp': log_time, 'latency_ms': latency_value, 'operation': extract_operation(message) }) except (json.JSONDecodeError, ValueError) as e: continue return { 'error_summary': dict(error_counts), 'warning_summary': dict(warning_counts), 'performance_metrics': performance_metrics } def extract_operation(message): \"\"\"从日志消息中提取操作类型\"\"\" if 'search' in message.lower(): return 'search' elif 'insert' in message.lower(): return 'insert' elif 'index' in message.lower(): return 'index' else: return 'unknown' def generate_log_report(analysis_result): \"\"\"生成日志分析报告\"\"\" print(\"=== Milvus Log Analysis Report ===\") print(f\"Analysis time: {datetime.now()}\") print() # 错误摘要 print(\"Top Errors:\") sorted_errors = sorted(analysis_result['error_summary'].items(), key=lambda x: x[1], reverse=True) for error, count in sorted_errors[:10]: print(f\" {count:4d} - {error[:100]}...\") print() # 警告摘要 print(\"Top Warnings:\") sorted_warnings = sorted(analysis_result['warning_summary'].items(), key=lambda x: x[1], reverse=True) for warning, count in sorted_warnings[:10]: print(f\" {count:4d} - {warning[:100]}...\") print() # 性能摘要 metrics = analysis_result['performance_metrics'] if metrics: latencies = [m['latency_ms'] for m in metrics] print(\"Performance Summary:\") print(f\" Total operations: {len(metrics)}\") print(f\" Average latency: {sum(latencies)/len(latencies):.2f} ms\") print(f\" Max latency: {max(latencies):.2f} ms\") print(f\" Min latency: {min(latencies):.2f} ms\") # 按操作类型分组 by_operation = defaultdict(list) for metric in metrics: by_operation[metric['operation']].append(metric['latency_ms']) print(\"\\nPerformance by Operation:\") for operation, latencies in by_operation.items(): if latencies: avg_latency = sum(latencies) / len(latencies) print(f\" {operation.capitalize()}:\") print(f\" Count: {len(latencies)}\") print(f\" Avg latency: {avg_latency:.2f} ms\") print(f\" Max latency: {max(latencies):.2f} ms\") else: print(\"No performance metrics found.\") # 使用示例 if __name__ == \"__main__\": log_file = \"/path/to/milvus.log\" result = analyze_milvus_logs(log_file, hours=24) generate_log_report(result) 11. 最佳实践 1. 数据建模最佳实践 Collection设计原则 # 良好的Collection设计示例 def create_production_collection(name, vector_dim, expected_size): \"\"\"生产环境Collection设计\"\"\" # 根据数据规模选择分片数 shard_num = min(max(expected_size // 1000000, 2), 16) fields = [ # 主键字段 - 使用有意义的ID FieldSchema( name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False, description=\"Document unique identifier\" ), # 时间戳字段 - 便于数据管理 FieldSchema( name=\"created_at\", dtype=DataType.INT64, description=\"Creation timestamp\" ), # 分类字段 - 用于过滤 FieldSchema( name=\"category\", dtype=DataType.VARCHAR, max_length=50, description=\"Document category\" ), # 向量字段 - 核心搜索字段 FieldSchema( name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=vector_dim, description=\"Document embedding vector\" ), # 元数据字段 - 存储额外信息 FieldSchema( name=\"metadata\", dtype=DataType.JSON, description=\"Additional metadata\" ) ] schema = CollectionSchema( fields=fields, description=f\"Production collection for {expected_size} documents\", enable_dynamic_field=True # 允许动态字段 ) collection = Collection( name=name, schema=schema, shards_num=shard_num, consistency_level=\"Strong\" # 生产环境建议强一致性 ) return collection 分区策略 # 基于时间的分区策略 def create_time_based_partitions(collection, start_date, end_date): \"\"\"创建基于时间的分区\"\"\" from datetime import datetime, timedelta current_date = start_date while current_date \u003c= end_date: partition_name = f\"partition_{current_date.strftime('%Y%m%d')}\" try: collection.create_partition(partition_name) print(f\"Created partition: {partition_name}\") except Exception as e: print(f\"Partition {partition_name} already exists or error: {e}\") current_date += timedelta(days=1) # 基于类别的分区策略 def create_category_partitions(collection, categories): \"\"\"创建基于类别的分区\"\"\" for category in categories: partition_name = f\"category_{category.lower()}\" try: collection.create_partition(partition_name) print(f\"Created partition: {partition_name}\") except Exception as e: print(f\"Partition {partition_name} already exists or error: {e}\") 2. 性能优化最佳实践 索引选择策略 def choose_optimal_index(data_size, memory_budget, latency_requirement, accuracy_requirement): \"\"\"根据需求选择最优索引\"\"\" if data_size \u003c 100000: # 小数据集使用FLAT return { \"index_type\": \"FLAT\", \"metric_type\": \"L2\", \"params\": {} } elif latency_requirement == \"ultra_low\" and memory_budget == \"high\": # 超低延迟需求使用HNSW return { \"index_type\": \"HNSW\", \"metric_type\": \"L2\", \"params\": { \"M\": 32, \"efConstruction\": 400 } } elif memory_budget == \"low\": # 内存受限使用PQ压缩 return { \"index_type\": \"IVF_PQ\", \"metric_type\": \"L2\", \"params\": { \"nlist\": min(4 * int(np.sqrt(data_size)), 4096), \"m\": 16, \"nbits\": 8 } } else: # 平衡选择IVF_FLAT return { \"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": { \"nlist\": min(4 * int(np.sqrt(data_size)), 4096) } } # 动态调整搜索参数 def get_adaptive_search_params(index_type, accuracy_level=\"medium\", data_size=None): \"\"\"根据索引类型和精度要求动态调整搜索参数\"\"\" if index_type == \"IVF_FLAT\" or index_type == \"IVF_PQ\": nprobe_map = { \"low\": max(8, int(np.sqrt(data_size)) // 100) if data_size else 8, \"medium\": max(16, int(np.sqrt(data_size)) // 50) if data_size else 16, \"high\": max(32, int(np.sqrt(data_size)) // 25) if data_size else 32 } return {\"nprobe\": nprobe_map[accuracy_level]} elif index_type == \"HNSW\": ef_map = {\"low\": 64, \"medium\": 128, \"high\": 256} return {\"ef\": ef_map[accuracy_level]} elif index_type == \"ANNOY\": search_k_map = {\"low\": 100, \"medium\": 200, \"high\": 400} return {\"search_k\": search_k_map[accuracy_level]} return {} 批处理优化 class OptimizedBatchProcessor: \"\"\"优化的批处理器\"\"\" def __init__(self, collection, batch_size=10000, flush_interval=50000): self.collection = collection self.batch_size = batch_size self.flush_interval = flush_interval self.total_inserted = 0 def insert_batch(self, data): \"\"\"批量插入数据\"\"\" total_entities = len(data[0]) for i in range(0, total_entities, self.batch_size): end_idx = min(i + self.batch_size, total_entities) batch_data = [field_data[i:end_idx] for field_data in data] try: result = self.collection.insert(batch_data) self.total_inserted += len(result.primary_keys) # 定期刷新 if self.total_inserted % self.flush_interval == 0: self.collection.flush() print(f\"Flushed after inserting {self.total_inserted} entities\") except Exception as e: print(f\"Error inserting batch {i//self.batch_size}: {e}\") continue # 最终刷新 self.collection.flush() return self.total_inserted def parallel_search(self, query_vectors, search_params, max_workers=4): \"\"\"并行搜索\"\"\" import concurrent.futures def search_single(query_vector): return self.collection.search( data=[query_vector], anns_field=\"embedding\", param=search_params, limit=10 ) with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor: futures = [executor.submit(search_single, qv) for qv in query_vectors] results = [future.result() for future in concurrent.futures.as_completed(futures)] return results 3. 数据质量最佳实践 向量预处理 import numpy as np from sklearn.preprocessing import normalize def preprocess_vectors(vectors, normalization=\"l2\", dimension_check=True): \"\"\"向量预处理管道\"\"\" vectors = np.array(vectors, dtype=np.float32) # 维度检查 if dimension_check and len(vectors.shape) != 2: raise ValueError(f\"Expected 2D array, got {len(vectors.shape)}D\") # 检查NaN和无穷值 if np.any(np.isnan(vectors)) or np.any(np.isinf(vectors)): print(\"Warning: Found NaN or infinite values, replacing with zeros\") vectors = np.nan_to_num(vectors, nan=0.0, posinf=0.0, neginf=0.0) # 归一化 if normalization == \"l2\": vectors = normalize(vectors, norm='l2', axis=1) elif normalization == \"minmax\": from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() vectors = scaler.fit_transform(vectors) return vectors.tolist() # 数据验证 def validate_data_quality(data, schema): \"\"\"验证数据质量\"\"\" issues = [] # 检查数据长度一致性 field_lengths = [len(field_data) for field_data in data] if len(set(field_lengths)) \u003e 1: issues.append(f\"Inconsistent field lengths: {field_lengths}\") # 检查向量维度 for i, field in enumerate(schema.fields): if field.dtype == DataType.FLOAT_VECTOR: vectors = data[i] expected_dim = field.params.get('dim') for j, vector in enumerate(vectors[:100]): # 检查前100个 if len(vector) != expected_dim: issues.append(f\"Vector {j} has dimension {len(vector)}, expected {expected_dim}\") break return issues 4. 监控和运维最佳实践 健康检查系统 import time import logging from datetime import datetime class MilvusHealthMonitor: \"\"\"Milvus健康监控系统\"\"\" def __init__(self, collection_names, alert_thresholds=None): self.collection_names = collection_names self.alert_thresholds = alert_thresholds or { 'query_latency': 1.0, # 秒 'memory_usage': 0.8, # 80% 'error_rate': 0.05 # 5% } self.logger = self._setup_logger() def _setup_logger(self): logger = logging.getLogger('milvus_monitor') logger.setLevel(logging.INFO) handler = logging.FileHandler('milvus_health.log') formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s') handler.setFormatter(formatter) logger.addHandler(handler) return logger def check_connection_health(self): \"\"\"检查连接健康状态\"\"\" try: from pymilvus import utility version = utility.get_server_version() self.logger.info(f\"Milvus server version: {version}\") return True except Exception as e: self.logger.error(f\"Connection health check failed: {e}\") return False def check_collection_health(self, collection_name): \"\"\"检查集合健康状态\"\"\" try: collection = Collection(collection_name) # 检查集合状态 stats = collection.get_stats() num_entities = collection.num_entities # 执行测试查询 start_time = time.time() test_vector = [[0.1] * 128] # 假设128维向量 results = collection.search( data=test_vector, anns_field=\"embedding\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}, limit=1 ) query_latency = time.time() - start_time # 记录指标 metrics = { 'collection': collection_name, 'num_entities': num_entities, 'query_latency': query_latency, 'timestamp': datetime.now().isoformat() } self.logger.info(f\"Collection health: {metrics}\") # 检查告警阈值 if query_latency \u003e self.alert_thresholds['query_latency']: self.logger.warning(f\"High query latency: {query_latency:.3f}s\") return metrics except Exception as e: self.logger.error(f\"Collection health check failed for {collection_name}: {e}\") return None def run_continuous_monitoring(self, interval=60): \"\"\"持续监控\"\"\" while True: try: # 检查连接 if not self.check_connection_health(): self.logger.critical(\"Milvus connection lost!\") # 检查所有集合 for collection_name in self.collection_names: self.check_collection_health(collection_name) time.sleep(interval) except KeyboardInterrupt: self.logger.info(\"Monitoring stopped by user\") break except Exception as e: self.logger.error(f\"Monitoring error: {e}\") time.sleep(interval) 备份和恢复策略 import json import os from datetime import datetime class MilvusBackupManager: \"\"\"Milvus备份管理器\"\"\" def __init__(self, backup_dir=\"./milvus_backups\"): self.backup_dir = backup_dir os.makedirs(backup_dir, exist_ok=True) def backup_collection_metadata(self, collection_name): \"\"\"备份集合元数据\"\"\" try: collection = Collection(collection_name) # 收集元数据 metadata = { 'name': collection.name, 'description': collection.description, 'schema': { 'fields': [ { 'name': field.name, 'dtype': str(field.dtype), 'params': field.params, 'is_primary': field.is_primary, 'auto_id': field.auto_id } for field in collection.schema.fields ], 'enable_dynamic_field': collection.schema.enable_dynamic_field }, 'num_entities': collection.num_entities, 'partitions': [p.name for p in collection.partitions], 'indexes': [] } # 获取索引信息 try: index_info = collection.index() if index_info: metadata['indexes'].append({ 'field_name': 'embedding', # 假设向量字段名 'index_params': index_info.params }) except: pass # 保存元数据 timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") backup_file = f\"{self.backup_dir}/{collection_name}_metadata_{timestamp}.json\" with open(backup_file, 'w') as f: json.dump(metadata, f, indent=2) print(f\"Metadata backup saved: {backup_file}\") return backup_file except Exception as e: print(f\"Backup failed: {e}\") return None def restore_collection_from_metadata(self, backup_file): \"\"\"从元数据恢复集合结构\"\"\" try: with open(backup_file, 'r') as f: metadata = json.load(f) # 重建字段 fields = [] for field_info in metadata['schema']['fields']: field = FieldSchema( name=field_info['name'], dtype=getattr(DataType, field_info['dtype'].split('.')[-1]), is_primary=field_info.get('is_primary', False), auto_id=field_info.get('auto_id', False), **field_info.get('params', {}) ) fields.append(field) # 重建schema schema = CollectionSchema( fields=fields, description=metadata['description'], enable_dynamic_field=metadata['schema']['enable_dynamic_field'] ) # 创建集合 collection = Collection( name=metadata['name'], schema=schema ) # 重建分区 for partition_name in metadata['partitions']: if partition_name != '_default': collection.create_partition(partition_name) print(f\"Collection {metadata['name']} restored from backup\") return collection except Exception as e: print(f\"Restore failed: {e}\") return None 5. 安全最佳实践 访问控制 from pymilvus import connections # 安全连接配置 def secure_connect(host, port, username, password, secure=True): \"\"\"安全连接到Milvus\"\"\" try: connections.connect( alias=\"secure_connection\", host=host, port=port, user=username, password=password, secure=secure, server_pem_path=\"/path/to/server.pem\", # TLS证书路径 server_name=\"milvus-server\", timeout=30 ) print(\"Secure connection established\") return True except Exception as e: print(f\"Secure connection failed: {e}\") return False # 输入验证 def validate_search_input(query_vectors, limit, expr=None): \"\"\"验证搜索输入\"\"\" # 验证向量 if not isinstance(query_vectors, list) or not query_vectors: raise ValueError(\"Query vectors must be a non-empty list\") # 验证limit if not isinstance(limit, int) or limit \u003c= 0 or limit \u003e 10000: raise ValueError(\"Limit must be a positive integer \u003c= 10000\") # 验证表达式（防止注入） if expr: dangerous_keywords = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'CREATE'] expr_upper = expr.upper() for keyword in dangerous_keywords: if keyword in expr_upper: raise ValueError(f\"Dangerous keyword '{keyword}' found in expression\") return True 12. 常见问题 Q1: 如何选择合适的索引类型？ A: 索引选择主要考虑以下因素：\n数据规模：\n\u003c 10万条：FLAT索引（精确搜索） 10万-100万条：IVF_FLAT索引 大于100万条：HNSW或IVF_PQ索引 内存预算：\n内存充足：HNSW索引（最高性能） 内存有限：IVF_PQ索引（压缩存储） 极度受限：ANNOY索引 精度要求：\n需要精确结果：FLAT索引 高精度近似：HNSW索引 平衡精度性能：IVF_FLAT索引 查询模式：\n频繁查询：HNSW索引 批量查询：IVF系列索引 静态数据：ANNOY索引 Q2: 搜索性能慢怎么优化？ A: 性能优化策略：\n索引优化：\n# 调整索引参数 # IVF索引：增加nlist，减少nprobe # HNSW索引：增加M值，调整ef参数 查询优化：\n# 使用分区过滤 results = collection.search( data=query_vectors, anns_field=\"embedding\", param=search_params, limit=10, partition_names=[\"recent_partition\"] # 只搜索相关分区 ) 硬件优化：\n使用SSD存储 增加内存容量 使用GPU加速（如果支持） 并发优化：\n# 并行搜索多个查询 import concurrent.futures def parallel_search(queries): with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor: futures = [executor.submit(collection.search, [q], \"embedding\", search_params, 10) for q in queries] return [f.result() for f in futures] Q3: 内存使用过高怎么处理？ A: 内存优化方法：\n使用压缩索引：\n# 使用PQ压缩 pq_index = { \"index_type\": \"IVF_PQ\", \"metric_type\": \"L2\", \"params\": {\"nlist\": 128, \"m\": 16, \"nbits\": 8} } 分区管理：\n# 只加载需要的分区 collection.load(partition_names=[\"active_partition\"]) # 释放不用的分区 collection.release(partition_names=[\"old_partition\"]) 配置调整：\n# 在milvus.yaml中调整缓存大小 queryCoord: cache: size: 2GB # 减少缓存大小 Q4: 数据一致性问题如何解决？ A: 确保数据一致性：\n设置一致性级别：\n# 创建集合时设置强一致性 collection = Collection( name=\"consistent_collection\", schema=schema, consistency_level=\"Strong\" ) 及时刷新数据：\n# 插入后立即刷新 collection.insert(entities) collection.flush() # 等待刷新完成 import time time.sleep(1) 检查数据状态：\n# 检查索引构建状态 from pymilvus import utility progress = utility.index_building_progress(collection.name) print(f\"Index progress: {progress}\") Q5: 集群部署常见问题 A: 集群部署注意事项：\n资源规划：\n# Kubernetes资源配置示例 resources: requests: memory: \"8Gi\" cpu: \"4\" limits: memory: \"16Gi\" cpu: \"8\" 网络配置：\n# 确保节点间网络畅通 service: type: ClusterIP ports: - port: 19530 targetPort: 19530 存储配置：\n# 使用持久化存储 persistence: enabled: true storageClass: \"fast-ssd\" size: 100Gi Q6: 向量维度不匹配错误 A: 解决维度不匹配：\n检查向量维度：\ndef validate_vector_dimension(vectors, expected_dim): for i, vector in enumerate(vectors): if len(vector) != expected_dim: raise ValueError(f\"Vector {i} has dimension {len(vector)}, expected {expected_dim}\") 统一向量维度：\ndef normalize_vector_dimension(vectors, target_dim): normalized = [] for vector in vectors: if len(vector) \u003c target_dim: # 填充零值 vector.extend([0.0] * (target_dim - len(vector))) elif len(vector) \u003e target_dim: # 截断 vector = vector[:target_dim] normalized.append(vector) return normalized Q7: 连接超时和网络问题 A: 网络问题排查：\n增加超时时间：\nconnections.connect( alias=\"default\", host=\"milvus-server\", port=\"19530\", timeout=60 # 增加超时时间 ) 连接池配置：\n# 配置连接池 connections.configure( alias=\"production\", host=\"milvus-server\", port=\"19530\", pool_size=10, timeout=30 ) 健康检查：\ndef check_connection(): try: from pymilvus import utility utility.get_server_version() return True except Exception as e: print(f\"Connection check failed: {e}\") return False Q8: 搜索结果为空 A: 排查搜索结果为空：\n检查数据是否加载：\n# 确保集合已加载 collection.load() # 检查加载状态 print(f\"Collection loaded: {collection.has_index()}\") print(f\"Number of entities: {collection.num_entities}\") 检查搜索参数：\n# 放宽搜索条件 results = collection.search( data=query_vectors, anns_field=\"embedding\", param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 128}}, # 增加nprobe limit=100, # 增加返回数量 expr=None # 移除过滤条件 ) 验证查询向量：\n# 检查查询向量是否有效 def validate_query_vector(vector, collection_schema): vector_field = None for field in collection_schema.fields: if field.dtype == DataType.FLOAT_VECTOR: vector_field = field break if vector_field and len(vector) != vector_field.params['dim']: raise ValueError(f\"Query vector dimension mismatch\") if all(v == 0 for v in vector): print(\"Warning: Query vector is all zeros\") 进一步学习资源 Milvus官方文档 Milvus GitHub仓库 Milvus社区论坛 向量数据库最佳实践 ","wordCount":"4555","inLanguage":"en","datePublished":"2024-01-01T04:14:54-08:00","dateModified":"2024-01-01T04:14:54-08:00","author":{"@type":"Person","name":"wellzhi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wellzhi.github.io/posts/tech/2024-01-01_milvus/"},"publisher":{"@type":"Organization","name":"wellzhi","logo":{"@type":"ImageObject","url":"https://wellzhi.github.io/favicon.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wellzhi.github.io/ accesskey=h title="wellzhi (Alt + H)">wellzhi</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wellzhi.github.io/ title=Home><span>Home</span></a></li><li><a href=https://wellzhi.github.io/posts/ title=Post><span>Post</span></a></li><li><a href=https://wellzhi.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://wellzhi.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://wellzhi.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://wellzhi.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://wellzhi.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://wellzhi.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://wellzhi.github.io/posts/tech/>Tech</a></div><h1 class="post-title entry-hint-parent">Milvus使用指南</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-milvus%e7%ae%80%e4%bb%8b aria-label="1. Milvus简介">1. Milvus简介</a><ul><li><a href=#%e4%bb%80%e4%b9%88%e6%98%afmilvus aria-label=什么是Milvus>什么是Milvus</a></li><li><a href=#%e4%b8%bb%e8%a6%81%e7%89%b9%e6%80%a7 aria-label=主要特性>主要特性</a></li><li><a href=#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label=应用场景>应用场景</a></li></ul></li><li><a href=#2-%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5 aria-label="2. 核心概念">2. 核心概念</a><ul><li><a href=#%e5%9f%ba%e6%9c%ac%e6%9c%af%e8%af%ad aria-label=基本术语>基本术语</a><ul><li><a href=#collection%e9%9b%86%e5%90%88 aria-label=Collection（集合）>Collection（集合）</a></li><li><a href=#field%e5%ad%97%e6%ae%b5 aria-label=Field（字段）>Field（字段）</a></li><li><a href=#entity%e5%ae%9e%e4%bd%93 aria-label=Entity（实体）>Entity（实体）</a></li><li><a href=#partition%e5%88%86%e5%8c%ba aria-label=Partition（分区）>Partition（分区）</a></li><li><a href=#index%e7%b4%a2%e5%bc%95 aria-label=Index（索引）>Index（索引）</a></li><li><a href=#segment%e6%ae%b5 aria-label=Segment（段）>Segment（段）</a></li></ul></li><li><a href=#%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b aria-label=数据类型>数据类型</a><ul><li><a href=#%e5%90%91%e9%87%8f%e7%b1%bb%e5%9e%8b aria-label=向量类型>向量类型</a></li><li><a href=#%e6%a0%87%e9%87%8f%e7%b1%bb%e5%9e%8b aria-label=标量类型>标量类型</a></li></ul></li></ul></li><li><a href=#3-%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2 aria-label="3. 安装部署">3. 安装部署</a><ul><li><a href=#%e7%b3%bb%e7%bb%9f%e8%a6%81%e6%b1%82 aria-label=系统要求>系统要求</a><ul><li><a href=#%e7%a1%ac%e4%bb%b6%e8%a6%81%e6%b1%82 aria-label=硬件要求>硬件要求</a></li><li><a href=#%e8%bd%af%e4%bb%b6%e8%a6%81%e6%b1%82 aria-label=软件要求>软件要求</a></li></ul></li><li><a href=#docker%e5%ae%89%e8%a3%85%e6%8e%a8%e8%8d%90 aria-label=Docker安装（推荐）>Docker安装（推荐）</a><ul><li><a href=#1-%e4%b8%8b%e8%bd%bd%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="1. 下载配置文件">1. 下载配置文件</a></li><li><a href=#2-%e5%90%af%e5%8a%a8milvus aria-label="2. 启动Milvus">2. 启动Milvus</a></li><li><a href=#3-%e9%aa%8c%e8%af%81%e5%ae%89%e8%a3%85 aria-label="3. 验证安装">3. 验证安装</a></li></ul></li><li><a href=#kubernetes%e9%83%a8%e7%bd%b2 aria-label=Kubernetes部署>Kubernetes部署</a><ul><li><a href=#1-%e5%ae%89%e8%a3%85helm aria-label="1. 安装Helm">1. 安装Helm</a></li><li><a href=#2-%e6%b7%bb%e5%8a%a0milvus-helm%e4%bb%93%e5%ba%93 aria-label="2. 添加Milvus Helm仓库">2. 添加Milvus Helm仓库</a></li><li><a href=#3-%e9%83%a8%e7%bd%b2milvus aria-label="3. 部署Milvus">3. 部署Milvus</a></li></ul></li><li><a href=#%e6%ba%90%e7%a0%81%e7%bc%96%e8%af%91%e5%ae%89%e8%a3%85 aria-label=源码编译安装>源码编译安装</a><ul><li><a href=#1-%e5%ae%89%e8%a3%85%e4%be%9d%e8%b5%96 aria-label="1. 安装依赖">1. 安装依赖</a></li><li><a href=#2-%e7%bc%96%e8%af%91%e5%ae%89%e8%a3%85 aria-label="2. 编译安装">2. 编译安装</a></li></ul></li></ul></li><li><a href=#4-%e5%bf%ab%e9%80%9f%e5%bc%80%e5%a7%8b aria-label="4. 快速开始">4. 快速开始</a><ul><li><a href=#%e5%ae%89%e8%a3%85python-sdk aria-label="安装Python SDK">安装Python SDK</a></li><li><a href=#%e5%9f%ba%e6%9c%ac%e6%93%8d%e4%bd%9c%e7%a4%ba%e4%be%8b aria-label=基本操作示例>基本操作示例</a><ul><li><a href=#1-%e8%bf%9e%e6%8e%a5milvus aria-label="1. 连接Milvus">1. 连接Milvus</a></li><li><a href=#2-%e5%88%9b%e5%bb%ba%e9%9b%86%e5%90%88 aria-label="2. 创建集合">2. 创建集合</a></li><li><a href=#3-%e6%8f%92%e5%85%a5%e6%95%b0%e6%8d%ae aria-label="3. 插入数据">3. 插入数据</a></li><li><a href=#4-%e5%88%9b%e5%bb%ba%e7%b4%a2%e5%bc%95 aria-label="4. 创建索引">4. 创建索引</a></li><li><a href=#5-%e5%8a%a0%e8%bd%bd%e9%9b%86%e5%90%88 aria-label="5. 加载集合">5. 加载集合</a></li><li><a href=#6-%e5%90%91%e9%87%8f%e6%a3%80%e7%b4%a2 aria-label="6. 向量检索">6. 向量检索</a></li></ul></li></ul></li><li><a href=#5-%e6%95%b0%e6%8d%ae%e7%ae%a1%e7%90%86 aria-label="5. 数据管理">5. 数据管理</a><ul><li><a href=#%e9%9b%86%e5%90%88%e7%ae%a1%e7%90%86 aria-label=集合管理>集合管理</a><ul><li><a href=#%e5%88%9b%e5%bb%ba%e9%9b%86%e5%90%88 aria-label=创建集合>创建集合</a></li><li><a href=#%e6%9f%a5%e7%9c%8b%e9%9b%86%e5%90%88%e4%bf%a1%e6%81%af aria-label=查看集合信息>查看集合信息</a></li><li><a href=#%e5%88%a0%e9%99%a4%e9%9b%86%e5%90%88 aria-label=删除集合>删除集合</a></li></ul></li><li><a href=#%e5%88%86%e5%8c%ba%e7%ae%a1%e7%90%86 aria-label=分区管理>分区管理</a><ul><li><a href=#%e5%88%9b%e5%bb%ba%e5%88%86%e5%8c%ba aria-label=创建分区>创建分区</a></li><li><a href=#%e5%88%86%e5%8c%ba%e6%95%b0%e6%8d%ae%e6%93%8d%e4%bd%9c aria-label=分区数据操作>分区数据操作</a></li></ul></li><li><a href=#%e6%95%b0%e6%8d%ae%e6%8f%92%e5%85%a5%e5%92%8c%e6%9b%b4%e6%96%b0 aria-label=数据插入和更新>数据插入和更新</a><ul><li><a href=#%e6%89%b9%e9%87%8f%e6%8f%92%e5%85%a5 aria-label=批量插入>批量插入</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e6%9b%b4%e6%96%b0upsert aria-label=数据更新（Upsert）>数据更新（Upsert）</a></li></ul></li><li><a href=#%e6%95%b0%e6%8d%ae%e5%88%a0%e9%99%a4 aria-label=数据删除>数据删除</a><ul><li><a href=#%e6%8c%89id%e5%88%a0%e9%99%a4 aria-label=按ID删除>按ID删除</a></li><li><a href=#%e6%8c%89%e6%9d%a1%e4%bb%b6%e5%88%a0%e9%99%a4 aria-label=按条件删除>按条件删除</a></li></ul></li></ul></li><li><a href=#6-%e5%90%91%e9%87%8f%e6%a3%80%e7%b4%a2-1 aria-label="6. 向量检索">6. 向量检索</a><ul><li><a href=#%e5%9f%ba%e6%9c%ac%e6%a3%80%e7%b4%a2 aria-label=基本检索>基本检索</a><ul><li><a href=#%e7%9b%b8%e4%bc%bc%e6%80%a7%e6%90%9c%e7%b4%a2 aria-label=相似性搜索>相似性搜索</a></li><li><a href=#%e6%b7%b7%e5%90%88%e6%90%9c%e7%b4%a2 aria-label=混合搜索>混合搜索</a></li></ul></li><li><a href=#%e9%ab%98%e7%ba%a7%e6%a3%80%e7%b4%a2 aria-label=高级检索>高级检索</a><ul><li><a href=#%e8%8c%83%e5%9b%b4%e6%90%9c%e7%b4%a2 aria-label=范围搜索>范围搜索</a></li><li><a href=#%e5%a4%9a%e5%90%91%e9%87%8f%e6%90%9c%e7%b4%a2 aria-label=多向量搜索>多向量搜索</a></li></ul></li><li><a href=#%e6%9f%a5%e8%af%a2%e6%93%8d%e4%bd%9c aria-label=查询操作>查询操作</a><ul><li><a href=#%e6%a0%87%e9%87%8f%e6%9f%a5%e8%af%a2 aria-label=标量查询>标量查询</a></li><li><a href=#%e5%a4%8d%e6%9d%82%e6%9f%a5%e8%af%a2 aria-label=复杂查询>复杂查询</a></li><li><a href=#%e5%88%86%e9%a1%b5%e6%9f%a5%e8%af%a2 aria-label=分页查询>分页查询</a></li></ul></li></ul></li><li><a href=#7-%e7%b4%a2%e5%bc%95%e7%ae%a1%e7%90%86 aria-label="7. 索引管理">7. 索引管理</a><ul><li><a href=#%e7%b4%a2%e5%bc%95%e7%b1%bb%e5%9e%8b aria-label=索引类型>索引类型</a><ul><li><a href=#flat%e7%b4%a2%e5%bc%95 aria-label=FLAT索引>FLAT索引</a></li><li><a href=#ivf%e7%b4%a2%e5%bc%95 aria-label=IVF索引>IVF索引</a></li><li><a href=#hnsw%e7%b4%a2%e5%bc%95 aria-label=HNSW索引>HNSW索引</a></li><li><a href=#annoy%e7%b4%a2%e5%bc%95 aria-label=ANNOY索引>ANNOY索引</a></li></ul></li><li><a href=#%e8%b7%9d%e7%a6%bb%e5%ba%a6%e9%87%8f aria-label=距离度量>距离度量</a><ul><li><a href=#%e6%ac%a7%e5%87%a0%e9%87%8c%e5%be%97%e8%b7%9d%e7%a6%bbl2 aria-label=欧几里得距离（L2）>欧几里得距离（L2）</a></li><li><a href=#%e5%86%85%e7%a7%afip aria-label=内积（IP）>内积（IP）</a></li><li><a href=#%e4%bd%99%e5%bc%a6%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-label=余弦相似度>余弦相似度</a></li></ul></li><li><a href=#%e7%b4%a2%e5%bc%95%e7%ae%a1%e7%90%86%e6%93%8d%e4%bd%9c aria-label=索引管理操作>索引管理操作</a><ul><li><a href=#%e6%9f%a5%e7%9c%8b%e7%b4%a2%e5%bc%95%e4%bf%a1%e6%81%af aria-label=查看索引信息>查看索引信息</a></li><li><a href=#%e9%87%8d%e5%bb%ba%e7%b4%a2%e5%bc%95 aria-label=重建索引>重建索引</a></li></ul></li></ul></li><li><a href=#8-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96 aria-label="8. 性能优化">8. 性能优化</a><ul><li><a href=#%e6%90%9c%e7%b4%a2%e5%8f%82%e6%95%b0%e4%bc%98%e5%8c%96 aria-label=搜索参数优化>搜索参数优化</a><ul><li><a href=#ivf%e7%b4%a2%e5%bc%95%e4%bc%98%e5%8c%96 aria-label=IVF索引优化>IVF索引优化</a></li><li><a href=#hnsw%e7%b4%a2%e5%bc%95%e4%bc%98%e5%8c%96 aria-label=HNSW索引优化>HNSW索引优化</a></li></ul></li><li><a href=#%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86 aria-label=内存管理>内存管理</a><ul><li><a href=#%e9%9b%86%e5%90%88%e5%8a%a0%e8%bd%bd%e7%ad%96%e7%95%a5 aria-label=集合加载策略>集合加载策略</a></li><li><a href=#%e5%88%86%e5%8c%ba%e5%8a%a0%e8%bd%bd aria-label=分区加载>分区加载</a></li></ul></li><li><a href=#%e6%89%b9%e5%a4%84%e7%90%86%e4%bc%98%e5%8c%96 aria-label=批处理优化>批处理优化</a><ul><li><a href=#%e6%89%b9%e9%87%8f%e6%8f%92%e5%85%a5%e4%bc%98%e5%8c%96 aria-label=批量插入优化>批量插入优化</a></li><li><a href=#%e5%b9%b6%e8%a1%8c%e6%90%9c%e7%b4%a2 aria-label=并行搜索>并行搜索</a></li></ul></li><li><a href=#%e8%bf%9e%e6%8e%a5%e6%b1%a0%e7%ae%a1%e7%90%86 aria-label=连接池管理>连接池管理</a></li></ul></li><li><a href=#9-%e9%9b%86%e7%be%a4%e9%83%a8%e7%bd%b2 aria-label="9. 集群部署">9. 集群部署</a><ul><li><a href=#kubernetes%e9%9b%86%e7%be%a4%e9%83%a8%e7%bd%b2 aria-label=Kubernetes集群部署>Kubernetes集群部署</a><ul><li><a href=#1-%e5%87%86%e5%a4%87%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="1. 准备配置文件">1. 准备配置文件</a></li><li><a href=#2-%e9%83%a8%e7%bd%b2%e9%9b%86%e7%be%a4 aria-label="2. 部署集群">2. 部署集群</a></li><li><a href=#3-%e9%85%8d%e7%bd%ae%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1 aria-label="3. 配置负载均衡">3. 配置负载均衡</a></li></ul></li><li><a href=#%e9%ab%98%e5%8f%af%e7%94%a8%e9%85%8d%e7%bd%ae aria-label=高可用配置>高可用配置</a><ul><li><a href=#%e5%a4%9a%e5%89%af%e6%9c%ac%e9%85%8d%e7%bd%ae aria-label=多副本配置>多副本配置</a></li><li><a href=#%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb%e6%b5%8b%e8%af%95 aria-label=故障转移测试>故障转移测试</a></li></ul></li><li><a href=#%e6%95%b0%e6%8d%ae%e5%88%86%e7%89%87%e7%ad%96%e7%95%a5 aria-label=数据分片策略>数据分片策略</a><ul><li><a href=#%e5%9f%ba%e4%ba%8e%e6%97%b6%e9%97%b4%e7%9a%84%e5%88%86%e7%89%87 aria-label=基于时间的分片>基于时间的分片</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e5%93%88%e5%b8%8c%e7%9a%84%e5%88%86%e7%89%87 aria-label=基于哈希的分片>基于哈希的分片</a></li></ul></li></ul></li><li><a href=#10-%e7%9b%91%e6%8e%a7%e8%bf%90%e7%bb%b4 aria-label="10. 监控运维">10. 监控运维</a><ul><li><a href=#%e7%b3%bb%e7%bb%9f%e7%9b%91%e6%8e%a7 aria-label=系统监控>系统监控</a><ul><li><a href=#prometheus%e7%9b%91%e6%8e%a7%e9%85%8d%e7%bd%ae aria-label=Prometheus监控配置>Prometheus监控配置</a></li><li><a href=#grafana%e4%bb%aa%e8%a1%a8%e6%9d%bf aria-label=Grafana仪表板>Grafana仪表板</a></li></ul></li><li><a href=#%e6%80%a7%e8%83%bd%e7%9b%91%e6%8e%a7 aria-label=性能监控>性能监控</a><ul><li><a href=#%e8%87%aa%e5%ae%9a%e4%b9%89%e7%9b%91%e6%8e%a7%e8%84%9a%e6%9c%ac aria-label=自定义监控脚本>自定义监控脚本</a></li></ul></li><li><a href=#%e6%97%a5%e5%bf%97%e7%ae%a1%e7%90%86 aria-label=日志管理>日志管理</a><ul><li><a href=#%e6%97%a5%e5%bf%97%e9%85%8d%e7%bd%ae aria-label=日志配置>日志配置</a></li><li><a href=#%e6%97%a5%e5%bf%97%e5%88%86%e6%9e%90%e8%84%9a%e6%9c%ac aria-label=日志分析脚本>日志分析脚本</a></li></ul></li></ul></li><li><a href=#11-%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="11. 最佳实践">11. 最佳实践</a><ul><li><a href=#1-%e6%95%b0%e6%8d%ae%e5%bb%ba%e6%a8%a1%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="1. 数据建模最佳实践">1. 数据建模最佳实践</a><ul><li><a href=#collection%e8%ae%be%e8%ae%a1%e5%8e%9f%e5%88%99 aria-label=Collection设计原则>Collection设计原则</a></li><li><a href=#%e5%88%86%e5%8c%ba%e7%ad%96%e7%95%a5 aria-label=分区策略>分区策略</a></li></ul></li><li><a href=#2-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="2. 性能优化最佳实践">2. 性能优化最佳实践</a><ul><li><a href=#%e7%b4%a2%e5%bc%95%e9%80%89%e6%8b%a9%e7%ad%96%e7%95%a5 aria-label=索引选择策略>索引选择策略</a></li><li><a href=#%e6%89%b9%e5%a4%84%e7%90%86%e4%bc%98%e5%8c%96-1 aria-label=批处理优化>批处理优化</a></li></ul></li><li><a href=#3-%e6%95%b0%e6%8d%ae%e8%b4%a8%e9%87%8f%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="3. 数据质量最佳实践">3. 数据质量最佳实践</a><ul><li><a href=#%e5%90%91%e9%87%8f%e9%a2%84%e5%a4%84%e7%90%86 aria-label=向量预处理>向量预处理</a></li></ul></li><li><a href=#4-%e7%9b%91%e6%8e%a7%e5%92%8c%e8%bf%90%e7%bb%b4%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="4. 监控和运维最佳实践">4. 监控和运维最佳实践</a><ul><li><a href=#%e5%81%a5%e5%ba%b7%e6%a3%80%e6%9f%a5%e7%b3%bb%e7%bb%9f aria-label=健康检查系统>健康检查系统</a></li><li><a href=#%e5%a4%87%e4%bb%bd%e5%92%8c%e6%81%a2%e5%a4%8d%e7%ad%96%e7%95%a5 aria-label=备份和恢复策略>备份和恢复策略</a></li></ul></li><li><a href=#5-%e5%ae%89%e5%85%a8%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 aria-label="5. 安全最佳实践">5. 安全最佳实践</a><ul><li><a href=#%e8%ae%bf%e9%97%ae%e6%8e%a7%e5%88%b6 aria-label=访问控制>访问控制</a></li></ul></li></ul></li><li><a href=#12-%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98 aria-label="12. 常见问题">12. 常见问题</a><ul><li><a href=#q1-%e5%a6%82%e4%bd%95%e9%80%89%e6%8b%a9%e5%90%88%e9%80%82%e7%9a%84%e7%b4%a2%e5%bc%95%e7%b1%bb%e5%9e%8b aria-label="Q1: 如何选择合适的索引类型？">Q1: 如何选择合适的索引类型？</a></li><li><a href=#q2-%e6%90%9c%e7%b4%a2%e6%80%a7%e8%83%bd%e6%85%a2%e6%80%8e%e4%b9%88%e4%bc%98%e5%8c%96 aria-label="Q2: 搜索性能慢怎么优化？">Q2: 搜索性能慢怎么优化？</a></li><li><a href=#q3-%e5%86%85%e5%ad%98%e4%bd%bf%e7%94%a8%e8%bf%87%e9%ab%98%e6%80%8e%e4%b9%88%e5%a4%84%e7%90%86 aria-label="Q3: 内存使用过高怎么处理？">Q3: 内存使用过高怎么处理？</a></li><li><a href=#q4-%e6%95%b0%e6%8d%ae%e4%b8%80%e8%87%b4%e6%80%a7%e9%97%ae%e9%a2%98%e5%a6%82%e4%bd%95%e8%a7%a3%e5%86%b3 aria-label="Q4: 数据一致性问题如何解决？">Q4: 数据一致性问题如何解决？</a></li><li><a href=#q5-%e9%9b%86%e7%be%a4%e9%83%a8%e7%bd%b2%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98 aria-label="Q5: 集群部署常见问题">Q5: 集群部署常见问题</a></li><li><a href=#q6-%e5%90%91%e9%87%8f%e7%bb%b4%e5%ba%a6%e4%b8%8d%e5%8c%b9%e9%85%8d%e9%94%99%e8%af%af aria-label="Q6: 向量维度不匹配错误">Q6: 向量维度不匹配错误</a></li><li><a href=#q7-%e8%bf%9e%e6%8e%a5%e8%b6%85%e6%97%b6%e5%92%8c%e7%bd%91%e7%bb%9c%e9%97%ae%e9%a2%98 aria-label="Q7: 连接超时和网络问题">Q7: 连接超时和网络问题</a></li><li><a href=#q8-%e6%90%9c%e7%b4%a2%e7%bb%93%e6%9e%9c%e4%b8%ba%e7%a9%ba aria-label="Q8: 搜索结果为空">Q8: 搜索结果为空</a></li><li><a href=#%e8%bf%9b%e4%b8%80%e6%ad%a5%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%ba%90 aria-label=进一步学习资源>进一步学习资源</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=1-milvus简介>1. Milvus简介<a hidden class=anchor aria-hidden=true href=#1-milvus简介>#</a></h2><h3 id=什么是milvus>什么是Milvus<a hidden class=anchor aria-hidden=true href=#什么是milvus>#</a></h3><p>Milvus是一个开源的向量数据库，专为处理大规模向量数据而设计。它支持多种向量相似性搜索算法，能够处理十亿级别的向量数据，广泛应用于AI应用场景，如推荐系统、图像检索、自然语言处理等。</p><h3 id=主要特性>主要特性<a hidden class=anchor aria-hidden=true href=#主要特性>#</a></h3><ul><li><strong>高性能</strong>：支持十亿级向量的毫秒级检索</li><li><strong>多样化索引</strong>：支持多种向量索引算法（IVF、HNSW、ANNOY等）</li><li><strong>云原生</strong>：基于Kubernetes的分布式架构</li><li><strong>多语言SDK</strong>：支持Python、Java、Go、Node.js等</li><li><strong>ACID事务</strong>：保证数据一致性</li><li><strong>混合搜索</strong>：支持向量和标量数据的混合查询</li></ul><h3 id=应用场景>应用场景<a hidden class=anchor aria-hidden=true href=#应用场景>#</a></h3><ul><li><strong>推荐系统</strong>：基于用户行为向量进行个性化推荐</li><li><strong>图像检索</strong>：以图搜图、相似图片查找</li><li><strong>文本搜索</strong>：语义搜索、文档相似性匹配</li><li><strong>视频分析</strong>：视频内容检索和分析</li><li><strong>药物发现</strong>：分子结构相似性搜索</li><li><strong>异常检测</strong>：基于向量距离的异常识别</li></ul><h2 id=2-核心概念>2. 核心概念<a hidden class=anchor aria-hidden=true href=#2-核心概念>#</a></h2><h3 id=基本术语>基本术语<a hidden class=anchor aria-hidden=true href=#基本术语>#</a></h3><h4 id=collection集合>Collection（集合）<a hidden class=anchor aria-hidden=true href=#collection集合>#</a></h4><p>类似于关系数据库中的表，用于存储向量数据和相关的标量字段。</p><h4 id=field字段>Field（字段）<a hidden class=anchor aria-hidden=true href=#field字段>#</a></h4><p>集合中的列，包括向量字段和标量字段。</p><h4 id=entity实体>Entity（实体）<a hidden class=anchor aria-hidden=true href=#entity实体>#</a></h4><p>集合中的一行数据，包含多个字段的值。</p><h4 id=partition分区>Partition（分区）<a hidden class=anchor aria-hidden=true href=#partition分区>#</a></h4><p>集合的子集，用于数据分片和查询优化。</p><h4 id=index索引>Index（索引）<a hidden class=anchor aria-hidden=true href=#index索引>#</a></h4><p>为加速向量检索而构建的数据结构。</p><h4 id=segment段>Segment（段）<a hidden class=anchor aria-hidden=true href=#segment段>#</a></h4><p>Milvus内部的数据存储单元，用于数据管理和查询优化。</p><h3 id=数据类型>数据类型<a hidden class=anchor aria-hidden=true href=#数据类型>#</a></h3><h4 id=向量类型>向量类型<a hidden class=anchor aria-hidden=true href=#向量类型>#</a></h4><ul><li><strong>FloatVector</strong>：浮点数向量</li><li><strong>BinaryVector</strong>：二进制向量</li></ul><h4 id=标量类型>标量类型<a hidden class=anchor aria-hidden=true href=#标量类型>#</a></h4><ul><li><strong>Bool</strong>：布尔值</li><li><strong>Int8/Int16/Int32/Int64</strong>：整数</li><li><strong>Float/Double</strong>：浮点数</li><li><strong>String/VarChar</strong>：字符串</li><li><strong>JSON</strong>：JSON对象</li></ul><h2 id=3-安装部署>3. 安装部署<a hidden class=anchor aria-hidden=true href=#3-安装部署>#</a></h2><h3 id=系统要求>系统要求<a hidden class=anchor aria-hidden=true href=#系统要求>#</a></h3><h4 id=硬件要求>硬件要求<a hidden class=anchor aria-hidden=true href=#硬件要求>#</a></h4><ul><li><strong>CPU</strong>：x86_64架构，支持SSE4.2指令集</li><li><strong>内存</strong>：8GB以上（推荐16GB+）</li><li><strong>存储</strong>：SSD硬盘（推荐NVMe）</li><li><strong>网络</strong>：千兆网卡</li></ul><h4 id=软件要求>软件要求<a hidden class=anchor aria-hidden=true href=#软件要求>#</a></h4><ul><li><strong>操作系统</strong>：Ubuntu 18.04+、CentOS 7+、macOS 10.14+</li><li><strong>Docker</strong>：20.10+</li><li><strong>Docker Compose</strong>：1.28+</li></ul><h3 id=docker安装推荐>Docker安装（推荐）<a hidden class=anchor aria-hidden=true href=#docker安装推荐>#</a></h3><h4 id=1-下载配置文件>1. 下载配置文件<a hidden class=anchor aria-hidden=true href=#1-下载配置文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 下载docker-compose.yml</span>
</span></span><span style=display:flex><span>wget https://github.com/milvus-io/milvus/releases/download/v2.3.0/milvus-standalone-docker-compose.yml -O docker-compose.yml
</span></span></code></pre></div><h4 id=2-启动milvus>2. 启动Milvus<a hidden class=anchor aria-hidden=true href=#2-启动milvus>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 启动服务</span>
</span></span><span style=display:flex><span>docker-compose up -d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查服务状态</span>
</span></span><span style=display:flex><span>docker-compose ps
</span></span></code></pre></div><h4 id=3-验证安装>3. 验证安装<a hidden class=anchor aria-hidden=true href=#3-验证安装>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 检查Milvus是否正常运行</span>
</span></span><span style=display:flex><span>curl -X GET <span style=color:#e6db74>&#34;http://localhost:9091/health&#34;</span>
</span></span></code></pre></div><h3 id=kubernetes部署>Kubernetes部署<a hidden class=anchor aria-hidden=true href=#kubernetes部署>#</a></h3><h4 id=1-安装helm>1. 安装Helm<a hidden class=anchor aria-hidden=true href=#1-安装helm>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
</span></span></code></pre></div><h4 id=2-添加milvus-helm仓库>2. 添加Milvus Helm仓库<a hidden class=anchor aria-hidden=true href=#2-添加milvus-helm仓库>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm repo add milvus https://milvus-io.github.io/milvus-helm/
</span></span><span style=display:flex><span>helm repo update
</span></span></code></pre></div><h4 id=3-部署milvus>3. 部署Milvus<a hidden class=anchor aria-hidden=true href=#3-部署milvus>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 创建命名空间</span>
</span></span><span style=display:flex><span>kubectl create namespace milvus
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 部署Milvus集群</span>
</span></span><span style=display:flex><span>helm install milvus milvus/milvus --namespace milvus
</span></span></code></pre></div><h3 id=源码编译安装>源码编译安装<a hidden class=anchor aria-hidden=true href=#源码编译安装>#</a></h3><h4 id=1-安装依赖>1. 安装依赖<a hidden class=anchor aria-hidden=true href=#1-安装依赖>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Ubuntu/Debian</span>
</span></span><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install -y build-essential cmake libopenblas-dev
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># CentOS/RHEL</span>
</span></span><span style=display:flex><span>sudo yum groupinstall -y <span style=color:#e6db74>&#34;Development Tools&#34;</span>
</span></span><span style=display:flex><span>sudo yum install -y cmake openblas-devel
</span></span></code></pre></div><h4 id=2-编译安装>2. 编译安装<a hidden class=anchor aria-hidden=true href=#2-编译安装>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 克隆源码</span>
</span></span><span style=display:flex><span>git clone https://github.com/milvus-io/milvus.git
</span></span><span style=display:flex><span>cd milvus
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 编译</span>
</span></span><span style=display:flex><span>make build
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动</span>
</span></span><span style=display:flex><span>./bin/milvus run standalone
</span></span></code></pre></div><h2 id=4-快速开始>4. 快速开始<a hidden class=anchor aria-hidden=true href=#4-快速开始>#</a></h2><h3 id=安装python-sdk>安装Python SDK<a hidden class=anchor aria-hidden=true href=#安装python-sdk>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install pymilvus
</span></span></code></pre></div><h3 id=基本操作示例>基本操作示例<a hidden class=anchor aria-hidden=true href=#基本操作示例>#</a></h3><h4 id=1-连接milvus>1. 连接Milvus<a hidden class=anchor aria-hidden=true href=#1-连接milvus>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> connections, Collection, FieldSchema, CollectionSchema, DataType
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 连接到Milvus</span>
</span></span><span style=display:flex><span>connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>    alias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>    host<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;localhost&#39;</span>,
</span></span><span style=display:flex><span>    port<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;19530&#39;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Connected to Milvus&#34;</span>)
</span></span></code></pre></div><h4 id=2-创建集合>2. 创建集合<a hidden class=anchor aria-hidden=true href=#2-创建集合>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 定义字段</span>
</span></span><span style=display:flex><span>fields <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;id&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64, is_primary<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, auto_id<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT_VECTOR, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;title&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>VARCHAR, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>200</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;category&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>VARCHAR, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建集合schema</span>
</span></span><span style=display:flex><span>schema <span style=color:#f92672>=</span> CollectionSchema(
</span></span><span style=display:flex><span>    fields<span style=color:#f92672>=</span>fields,
</span></span><span style=display:flex><span>    description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Document embedding collection&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建集合</span>
</span></span><span style=display:flex><span>collection <span style=color:#f92672>=</span> Collection(
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;documents&#34;</span>,
</span></span><span style=display:flex><span>    schema<span style=color:#f92672>=</span>schema
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Collection created&#34;</span>)
</span></span></code></pre></div><h4 id=3-插入数据>3. 插入数据<a hidden class=anchor aria-hidden=true href=#3-插入数据>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 准备数据</span>
</span></span><span style=display:flex><span>num_entities <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>entities <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    [i <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_entities)],  <span style=color:#75715e># id字段</span>
</span></span><span style=display:flex><span>    [[random<span style=color:#f92672>.</span>random() <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>128</span>)] <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(num_entities)],  <span style=color:#75715e># embedding字段</span>
</span></span><span style=display:flex><span>    [<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Document </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_entities)],  <span style=color:#75715e># title字段</span>
</span></span><span style=display:flex><span>    [<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Category </span><span style=color:#e6db74>{</span>i <span style=color:#f92672>%</span> <span style=color:#ae81ff>10</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_entities)]  <span style=color:#75715e># category字段</span>
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 插入数据</span>
</span></span><span style=display:flex><span>insert_result <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>insert(entities)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inserted </span><span style=color:#e6db74>{</span>len(insert_result<span style=color:#f92672>.</span>primary_keys)<span style=color:#e6db74>}</span><span style=color:#e6db74> entities&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 刷新数据到磁盘</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>flush()
</span></span></code></pre></div><h4 id=4-创建索引>4. 创建索引<a hidden class=anchor aria-hidden=true href=#4-创建索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 定义索引参数</span>
</span></span><span style=display:flex><span>index_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建索引</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    index_params<span style=color:#f92672>=</span>index_params
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Index created&#34;</span>)
</span></span></code></pre></div><h4 id=5-加载集合>5. 加载集合<a hidden class=anchor aria-hidden=true href=#5-加载集合>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 加载集合到内存</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Collection loaded&#34;</span>)
</span></span></code></pre></div><h4 id=6-向量检索>6. 向量检索<a hidden class=anchor aria-hidden=true href=#6-向量检索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 准备查询向量</span>
</span></span><span style=display:flex><span>query_vectors <span style=color:#f92672>=</span> [[random<span style=color:#f92672>.</span>random() <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>128</span>)]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 执行搜索</span>
</span></span><span style=display:flex><span>search_params <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>10</span>}}
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;title&#34;</span>, <span style=color:#e6db74>&#34;category&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 输出结果</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> hits <span style=color:#f92672>in</span> results:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> hit <span style=color:#f92672>in</span> hits:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;ID: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>id<span style=color:#e6db74>}</span><span style=color:#e6db74>, Distance: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>distance<span style=color:#e6db74>}</span><span style=color:#e6db74>, Title: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>entity<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;title&#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h2 id=5-数据管理>5. 数据管理<a hidden class=anchor aria-hidden=true href=#5-数据管理>#</a></h2><h3 id=集合管理>集合管理<a hidden class=anchor aria-hidden=true href=#集合管理>#</a></h3><h4 id=创建集合>创建集合<a hidden class=anchor aria-hidden=true href=#创建集合>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> Collection, FieldSchema, CollectionSchema, DataType
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义复杂schema</span>
</span></span><span style=display:flex><span>fields <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;id&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64, is_primary<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT_VECTOR, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>VARCHAR, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;score&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;timestamp&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metadata&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>JSON)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>schema <span style=color:#f92672>=</span> CollectionSchema(
</span></span><span style=display:flex><span>    fields<span style=color:#f92672>=</span>fields,
</span></span><span style=display:flex><span>    description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Advanced collection with multiple field types&#34;</span>,
</span></span><span style=display:flex><span>    enable_dynamic_field<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>  <span style=color:#75715e># 启用动态字段</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection <span style=color:#f92672>=</span> Collection(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;advanced_collection&#34;</span>, schema<span style=color:#f92672>=</span>schema)
</span></span></code></pre></div><h4 id=查看集合信息>查看集合信息<a hidden class=anchor aria-hidden=true href=#查看集合信息>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 获取集合统计信息</span>
</span></span><span style=display:flex><span>stats <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>get_stats()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection stats: </span><span style=color:#e6db74>{</span>stats<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 获取集合schema</span>
</span></span><span style=display:flex><span>schema <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>schema
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> field <span style=color:#f92672>in</span> schema<span style=color:#f92672>.</span>fields:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Field: </span><span style=color:#e6db74>{</span>field<span style=color:#f92672>.</span>name<span style=color:#e6db74>}</span><span style=color:#e6db74>, Type: </span><span style=color:#e6db74>{</span>field<span style=color:#f92672>.</span>dtype<span style=color:#e6db74>}</span><span style=color:#e6db74>, Params: </span><span style=color:#e6db74>{</span>field<span style=color:#f92672>.</span>params<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查集合是否存在</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>has_collection <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>has_collection(<span style=color:#e6db74>&#34;advanced_collection&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection exists: </span><span style=color:#e6db74>{</span>has_collection<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=删除集合>删除集合<a hidden class=anchor aria-hidden=true href=#删除集合>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 删除集合</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>drop()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 或者使用utility函数</span>
</span></span><span style=display:flex><span>utility<span style=color:#f92672>.</span>drop_collection(<span style=color:#e6db74>&#34;collection_name&#34;</span>)
</span></span></code></pre></div><h3 id=分区管理>分区管理<a hidden class=anchor aria-hidden=true href=#分区管理>#</a></h3><h4 id=创建分区>创建分区<a hidden class=anchor aria-hidden=true href=#创建分区>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 创建分区</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_partition(<span style=color:#e6db74>&#34;partition_2023&#34;</span>)
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_partition(<span style=color:#e6db74>&#34;partition_2024&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看所有分区</span>
</span></span><span style=display:flex><span>partitions <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>partitions
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> partition <span style=color:#f92672>in</span> partitions:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Partition: </span><span style=color:#e6db74>{</span>partition<span style=color:#f92672>.</span>name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=分区数据操作>分区数据操作<a hidden class=anchor aria-hidden=true href=#分区数据操作>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 向特定分区插入数据</span>
</span></span><span style=display:flex><span>entities <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>],  <span style=color:#75715e># ids</span>
</span></span><span style=display:flex><span>    [[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>, [<span style=color:#ae81ff>0.2</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>, [<span style=color:#ae81ff>0.3</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>],  <span style=color:#75715e># vectors</span>
</span></span><span style=display:flex><span>    [<span style=color:#e6db74>&#34;text1&#34;</span>, <span style=color:#e6db74>&#34;text2&#34;</span>, <span style=color:#e6db74>&#34;text3&#34;</span>],  <span style=color:#75715e># text</span>
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.9</span>, <span style=color:#ae81ff>0.7</span>],  <span style=color:#75715e># scores</span>
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>1640995200</span>, <span style=color:#ae81ff>1640995300</span>, <span style=color:#ae81ff>1640995400</span>],  <span style=color:#75715e># timestamps</span>
</span></span><span style=display:flex><span>    [{<span style=color:#e6db74>&#34;key&#34;</span>: <span style=color:#e6db74>&#34;value1&#34;</span>}, {<span style=color:#e6db74>&#34;key&#34;</span>: <span style=color:#e6db74>&#34;value2&#34;</span>}, {<span style=color:#e6db74>&#34;key&#34;</span>: <span style=color:#e6db74>&#34;value3&#34;</span>}]  <span style=color:#75715e># metadata</span>
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>insert(entities, partition_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;partition_2023&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 在特定分区中搜索</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>[[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>],
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>10</span>}},
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    partition_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;partition_2023&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=数据插入和更新>数据插入和更新<a hidden class=anchor aria-hidden=true href=#数据插入和更新>#</a></h3><h4 id=批量插入>批量插入<a hidden class=anchor aria-hidden=true href=#批量插入>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 大批量数据插入</span>
</span></span><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>10000</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100000</span>, batch_size):
</span></span><span style=display:flex><span>    ids <span style=color:#f92672>=</span> list(range(i, min(i <span style=color:#f92672>+</span> batch_size, <span style=color:#ae81ff>100000</span>)))
</span></span><span style=display:flex><span>    vectors <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random((len(ids), <span style=color:#ae81ff>256</span>))<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>    texts <span style=color:#f92672>=</span> [<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Document </span><span style=color:#e6db74>{</span>j<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> ids]
</span></span><span style=display:flex><span>    scores <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random(len(ids))<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>    timestamps <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1640995200</span> <span style=color:#f92672>+</span> j <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> ids]
</span></span><span style=display:flex><span>    metadata <span style=color:#f92672>=</span> [{<span style=color:#e6db74>&#34;batch&#34;</span>: i <span style=color:#f92672>//</span> batch_size} <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> ids]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    entities <span style=color:#f92672>=</span> [ids, vectors, texts, scores, timestamps, metadata]
</span></span><span style=display:flex><span>    collection<span style=color:#f92672>.</span>insert(entities)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> i <span style=color:#f92672>%</span> <span style=color:#ae81ff>50000</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        collection<span style=color:#f92672>.</span>flush()  <span style=color:#75715e># 定期刷新</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inserted </span><span style=color:#e6db74>{</span>i <span style=color:#f92672>+</span> len(ids)<span style=color:#e6db74>}</span><span style=color:#e6db74> entities&#34;</span>)
</span></span></code></pre></div><h4 id=数据更新upsert>数据更新（Upsert）<a hidden class=anchor aria-hidden=true href=#数据更新upsert>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Milvus 2.3+支持upsert操作</span>
</span></span><span style=display:flex><span>update_entities <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>],  <span style=color:#75715e># 更新已存在的ID</span>
</span></span><span style=display:flex><span>    [[<span style=color:#ae81ff>0.5</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>, [<span style=color:#ae81ff>0.6</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>, [<span style=color:#ae81ff>0.7</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>],  <span style=color:#75715e># 新的向量</span>
</span></span><span style=display:flex><span>    [<span style=color:#e6db74>&#34;Updated text1&#34;</span>, <span style=color:#e6db74>&#34;Updated text2&#34;</span>, <span style=color:#e6db74>&#34;Updated text3&#34;</span>],  <span style=color:#75715e># 新的文本</span>
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>0.95</span>, <span style=color:#ae81ff>0.96</span>, <span style=color:#ae81ff>0.97</span>],  <span style=color:#75715e># 新的分数</span>
</span></span><span style=display:flex><span>    [<span style=color:#ae81ff>1640995500</span>, <span style=color:#ae81ff>1640995600</span>, <span style=color:#ae81ff>1640995700</span>],  <span style=color:#75715e># 新的时间戳</span>
</span></span><span style=display:flex><span>    [{<span style=color:#e6db74>&#34;updated&#34;</span>: <span style=color:#66d9ef>True</span>}, {<span style=color:#e6db74>&#34;updated&#34;</span>: <span style=color:#66d9ef>True</span>}, {<span style=color:#e6db74>&#34;updated&#34;</span>: <span style=color:#66d9ef>True</span>}]  <span style=color:#75715e># 新的元数据</span>
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>upsert(update_entities)
</span></span></code></pre></div><h3 id=数据删除>数据删除<a hidden class=anchor aria-hidden=true href=#数据删除>#</a></h3><h4 id=按id删除>按ID删除<a hidden class=anchor aria-hidden=true href=#按id删除>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 删除指定ID的实体</span>
</span></span><span style=display:flex><span>delete_ids <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>]
</span></span><span style=display:flex><span>expr <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;id in </span><span style=color:#e6db74>{</span>delete_ids<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>delete(expr)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 删除满足条件的实体</span>
</span></span><span style=display:flex><span>expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;score &lt; 0.5&#34;</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>delete(expr)
</span></span></code></pre></div><h4 id=按条件删除>按条件删除<a hidden class=anchor aria-hidden=true href=#按条件删除>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 复杂删除条件</span>
</span></span><span style=display:flex><span>expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;score &lt; 0.3 and timestamp &lt; 1640995300&#34;</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>delete(expr)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用JSON字段删除</span>
</span></span><span style=display:flex><span>expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;JSON_CONTAINS(metadata, &#39;</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>updated</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>: true&#39;)&#34;</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>delete(expr)
</span></span></code></pre></div><h2 id=6-向量检索-1>6. 向量检索<a hidden class=anchor aria-hidden=true href=#6-向量检索-1>#</a></h2><h3 id=基本检索>基本检索<a hidden class=anchor aria-hidden=true href=#基本检索>#</a></h3><h4 id=相似性搜索>相似性搜索<a hidden class=anchor aria-hidden=true href=#相似性搜索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 基本向量搜索</span>
</span></span><span style=display:flex><span>query_vectors <span style=color:#f92672>=</span> [[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>, [<span style=color:#ae81ff>0.2</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>]
</span></span><span style=display:flex><span>search_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;text&#34;</span>, <span style=color:#e6db74>&#34;score&#34;</span>, <span style=color:#e6db74>&#34;timestamp&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, hits <span style=color:#f92672>in</span> enumerate(results):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Query </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74> results:&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> hit <span style=color:#f92672>in</span> hits:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  ID: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>id<span style=color:#e6db74>}</span><span style=color:#e6db74>, Distance: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>distance<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Text: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>entity<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;text&#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Score: </span><span style=color:#e6db74>{</span>hit<span style=color:#f92672>.</span>entity<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;score&#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=混合搜索>混合搜索<a hidden class=anchor aria-hidden=true href=#混合搜索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 向量搜索 + 标量过滤</span>
</span></span><span style=display:flex><span>query_vectors <span style=color:#f92672>=</span> [[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>]
</span></span><span style=display:flex><span>search_params <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 添加标量过滤条件</span>
</span></span><span style=display:flex><span>filter_expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;score &gt; 0.8 and timestamp &gt; 1640995200&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    expr<span style=color:#f92672>=</span>filter_expr,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;text&#34;</span>, <span style=color:#e6db74>&#34;score&#34;</span>, <span style=color:#e6db74>&#34;timestamp&#34;</span>, <span style=color:#e6db74>&#34;metadata&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=高级检索>高级检索<a hidden class=anchor aria-hidden=true href=#高级检索>#</a></h3><h4 id=范围搜索>范围搜索<a hidden class=anchor aria-hidden=true href=#范围搜索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 搜索距离在指定范围内的向量</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> SearchResult
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>query_vectors <span style=color:#f92672>=</span> [[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>]
</span></span><span style=display:flex><span>search_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;radius&#34;</span>: <span style=color:#ae81ff>0.1</span>,  <span style=color:#75715e># 最大距离</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;range_filter&#34;</span>: <span style=color:#ae81ff>0.05</span>  <span style=color:#75715e># 最小距离</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;text&#34;</span>, <span style=color:#e6db74>&#34;score&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=多向量搜索>多向量搜索<a hidden class=anchor aria-hidden=true href=#多向量搜索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 同时搜索多个向量字段（如果集合有多个向量字段）</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 假设有text_vector和image_vector两个字段</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建包含多个向量字段的集合</span>
</span></span><span style=display:flex><span>multi_vector_fields <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;id&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64, is_primary<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text_vector&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT_VECTOR, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;image_vector&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT_VECTOR, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>    FieldSchema(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;title&#34;</span>, dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>VARCHAR, max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>200</span>)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>multi_schema <span style=color:#f92672>=</span> CollectionSchema(fields<span style=color:#f92672>=</span>multi_vector_fields)
</span></span><span style=display:flex><span>multi_collection <span style=color:#f92672>=</span> Collection(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;multi_vector_collection&#34;</span>, schema<span style=color:#f92672>=</span>multi_schema)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分别在不同向量字段上搜索</span>
</span></span><span style=display:flex><span>text_results <span style=color:#f92672>=</span> multi_collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>[[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>128</span>],
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text_vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}},
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>image_results <span style=color:#f92672>=</span> multi_collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>[[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>],
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;image_vector&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}},
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=查询操作>查询操作<a hidden class=anchor aria-hidden=true href=#查询操作>#</a></h3><h4 id=标量查询>标量查询<a hidden class=anchor aria-hidden=true href=#标量查询>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 基于标量字段的查询</span>
</span></span><span style=display:flex><span>query_expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;score &gt; 0.8&#34;</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    expr<span style=color:#f92672>=</span>query_expr,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;id&#34;</span>, <span style=color:#e6db74>&#34;text&#34;</span>, <span style=color:#e6db74>&#34;score&#34;</span>, <span style=color:#e6db74>&#34;timestamp&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> result <span style=color:#f92672>in</span> results:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;ID: </span><span style=color:#e6db74>{</span>result[<span style=color:#e6db74>&#39;id&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>, Text: </span><span style=color:#e6db74>{</span>result[<span style=color:#e6db74>&#39;text&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>, Score: </span><span style=color:#e6db74>{</span>result[<span style=color:#e6db74>&#39;score&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=复杂查询>复杂查询<a hidden class=anchor aria-hidden=true href=#复杂查询>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 复杂查询表达式</span>
</span></span><span style=display:flex><span>complex_expr <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    (score &gt; 0.8 and timestamp &gt; 1640995200) or 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    (score &gt; 0.9 and JSON_CONTAINS(metadata, &#39;&#34;important&#34;: true&#39;))
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>    expr<span style=color:#f92672>=</span>complex_expr,
</span></span><span style=display:flex><span>    output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;*&#34;</span>],  <span style=color:#75715e># 输出所有字段</span>
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=分页查询>分页查询<a hidden class=anchor aria-hidden=true href=#分页查询>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 分页查询大量数据</span>
</span></span><span style=display:flex><span>page_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>offset <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>    results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>query(
</span></span><span style=display:flex><span>        expr<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;score &gt; 0.5&#34;</span>,
</span></span><span style=display:flex><span>        output_fields<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;id&#34;</span>, <span style=color:#e6db74>&#34;text&#34;</span>, <span style=color:#e6db74>&#34;score&#34;</span>],
</span></span><span style=display:flex><span>        limit<span style=color:#f92672>=</span>page_size,
</span></span><span style=display:flex><span>        offset<span style=color:#f92672>=</span>offset
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> results:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Page </span><span style=color:#e6db74>{</span>offset <span style=color:#f92672>//</span> page_size <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>len(results)<span style=color:#e6db74>}</span><span style=color:#e6db74> results&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 处理结果</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> result <span style=color:#f92672>in</span> results:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 处理每个结果</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>pass</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    offset <span style=color:#f92672>+=</span> page_size
</span></span></code></pre></div><h2 id=7-索引管理>7. 索引管理<a hidden class=anchor aria-hidden=true href=#7-索引管理>#</a></h2><h3 id=索引类型>索引类型<a hidden class=anchor aria-hidden=true href=#索引类型>#</a></h3><h4 id=flat索引>FLAT索引<a hidden class=anchor aria-hidden=true href=#flat索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># FLAT索引 - 精确搜索，适合小数据集</span>
</span></span><span style=display:flex><span>flat_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>    index_params<span style=color:#f92672>=</span>flat_index
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=ivf索引>IVF索引<a hidden class=anchor aria-hidden=true href=#ivf索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># IVF_FLAT索引 - 平衡性能和精度</span>
</span></span><span style=display:flex><span>ivf_flat_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>  <span style=color:#75715e># 聚类中心数量</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># IVF_PQ索引 - 压缩存储，适合大数据集</span>
</span></span><span style=display:flex><span>ivf_pq_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_PQ&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;m&#34;</span>: <span style=color:#ae81ff>16</span>,  <span style=color:#75715e># PQ分段数</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;nbits&#34;</span>: <span style=color:#ae81ff>8</span>  <span style=color:#75715e># 每段的位数</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, index_params<span style=color:#f92672>=</span>ivf_pq_index)
</span></span></code></pre></div><h4 id=hnsw索引>HNSW索引<a hidden class=anchor aria-hidden=true href=#hnsw索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># HNSW索引 - 高性能近似搜索</span>
</span></span><span style=display:flex><span>hnsw_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;HNSW&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;M&#34;</span>: <span style=color:#ae81ff>16</span>,  <span style=color:#75715e># 每层的最大连接数</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;efConstruction&#34;</span>: <span style=color:#ae81ff>200</span>  <span style=color:#75715e># 构建时的搜索深度</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, index_params<span style=color:#f92672>=</span>hnsw_index)
</span></span></code></pre></div><h4 id=annoy索引>ANNOY索引<a hidden class=anchor aria-hidden=true href=#annoy索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># ANNOY索引 - 内存友好</span>
</span></span><span style=display:flex><span>annoy_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;ANNOY&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;n_trees&#34;</span>: <span style=color:#ae81ff>8</span>  <span style=color:#75715e># 树的数量</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, index_params<span style=color:#f92672>=</span>annoy_index)
</span></span></code></pre></div><h3 id=距离度量>距离度量<a hidden class=anchor aria-hidden=true href=#距离度量>#</a></h3><h4 id=欧几里得距离l2>欧几里得距离（L2）<a hidden class=anchor aria-hidden=true href=#欧几里得距离l2>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>l2_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,  <span style=color:#75715e># 欧几里得距离</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=内积ip>内积（IP）<a hidden class=anchor aria-hidden=true href=#内积ip>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>ip_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;IP&#34;</span>,  <span style=color:#75715e># 内积</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=余弦相似度>余弦相似度<a hidden class=anchor aria-hidden=true href=#余弦相似度>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 余弦相似度需要先归一化向量，然后使用IP</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>normalize_vectors</span>(vectors):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;归一化向量以使用余弦相似度&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    vectors <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(vectors)
</span></span><span style=display:flex><span>    norms <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linalg<span style=color:#f92672>.</span>norm(vectors, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, keepdims<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> (vectors <span style=color:#f92672>/</span> norms)<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 插入归一化后的向量</span>
</span></span><span style=display:flex><span>normalized_vectors <span style=color:#f92672>=</span> normalize_vectors(original_vectors)
</span></span><span style=display:flex><span>entities <span style=color:#f92672>=</span> [ids, normalized_vectors, texts, scores, timestamps, metadata]
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>insert(entities)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用IP度量进行余弦相似度搜索</span>
</span></span><span style=display:flex><span>cosine_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;IP&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=索引管理操作>索引管理操作<a hidden class=anchor aria-hidden=true href=#索引管理操作>#</a></h3><h4 id=查看索引信息>查看索引信息<a hidden class=anchor aria-hidden=true href=#查看索引信息>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 获取索引信息</span>
</span></span><span style=display:flex><span>index_info <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>index()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Index type: </span><span style=color:#e6db74>{</span>index_info<span style=color:#f92672>.</span>params[<span style=color:#e6db74>&#39;index_type&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Metric type: </span><span style=color:#e6db74>{</span>index_info<span style=color:#f92672>.</span>params[<span style=color:#e6db74>&#39;metric_type&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Index params: </span><span style=color:#e6db74>{</span>index_info<span style=color:#f92672>.</span>params[<span style=color:#e6db74>&#39;params&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查索引构建进度</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>index_progress <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>index_building_progress(<span style=color:#e6db74>&#34;collection_name&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Index building progress: </span><span style=color:#e6db74>{</span>index_progress<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=重建索引>重建索引<a hidden class=anchor aria-hidden=true href=#重建索引>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 删除现有索引</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>drop_index()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建新索引</span>
</span></span><span style=display:flex><span>new_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;HNSW&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;M&#34;</span>: <span style=color:#ae81ff>32</span>, <span style=color:#e6db74>&#34;efConstruction&#34;</span>: <span style=color:#ae81ff>400</span>}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, index_params<span style=color:#f92672>=</span>new_index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 等待索引构建完成</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>    progress <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>index_building_progress(collection<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> progress[<span style=color:#e6db74>&#39;pending_index_rows&#39;</span>] <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Index building progress: </span><span style=color:#e6db74>{</span>progress<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Index building completed&#34;</span>)
</span></span></code></pre></div><h2 id=8-性能优化>8. 性能优化<a hidden class=anchor aria-hidden=true href=#8-性能优化>#</a></h2><h3 id=搜索参数优化>搜索参数优化<a hidden class=anchor aria-hidden=true href=#搜索参数优化>#</a></h3><h4 id=ivf索引优化>IVF索引优化<a hidden class=anchor aria-hidden=true href=#ivf索引优化>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 根据数据量调整nlist</span>
</span></span><span style=display:flex><span>data_size <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>num_entities
</span></span><span style=display:flex><span>optimal_nlist <span style=color:#f92672>=</span> int(np<span style=color:#f92672>.</span>sqrt(data_size))
</span></span><span style=display:flex><span>optimal_nlist <span style=color:#f92672>=</span> max(<span style=color:#ae81ff>128</span>, min(optimal_nlist, <span style=color:#ae81ff>4096</span>))  <span style=color:#75715e># 限制在合理范围内</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 搜索时调整nprobe</span>
</span></span><span style=display:flex><span>search_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;nprobe&#34;</span>: min(optimal_nlist <span style=color:#f92672>//</span> <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>64</span>)  <span style=color:#75715e># 通常设置为nlist的1/4</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=hnsw索引优化>HNSW索引优化<a hidden class=anchor aria-hidden=true href=#hnsw索引优化>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 构建时参数</span>
</span></span><span style=display:flex><span>hnsw_build_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;HNSW&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;M&#34;</span>: <span style=color:#ae81ff>16</span>,  <span style=color:#75715e># 连接数，影响精度和内存</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;efConstruction&#34;</span>: <span style=color:#ae81ff>200</span>  <span style=color:#75715e># 构建时搜索深度</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 搜索时参数</span>
</span></span><span style=display:flex><span>hnsw_search_params <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;ef&#34;</span>: <span style=color:#ae81ff>100</span>  <span style=color:#75715e># 搜索时的候选数量，越大精度越高但速度越慢</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=内存管理>内存管理<a hidden class=anchor aria-hidden=true href=#内存管理>#</a></h3><h4 id=集合加载策略>集合加载策略<a hidden class=anchor aria-hidden=true href=#集合加载策略>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 部分加载 - 只加载需要的字段</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load(replica_number<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, _resource_groups<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;default&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 释放不需要的集合</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>release()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查内存使用</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>memory_info <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>get_query_segment_info(collection<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> info <span style=color:#f92672>in</span> memory_info:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Segment </span><span style=color:#e6db74>{</span>info<span style=color:#f92672>.</span>segmentID<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>info<span style=color:#f92672>.</span>mem_size<span style=color:#e6db74>}</span><span style=color:#e6db74> bytes&#34;</span>)
</span></span></code></pre></div><h4 id=分区加载>分区加载<a hidden class=anchor aria-hidden=true href=#分区加载>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 只加载特定分区</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load(partition_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;partition_2024&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 动态加载/释放分区</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>load_partition_by_date</span>(date_str):
</span></span><span style=display:flex><span>    partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_</span><span style=color:#e6db74>{</span>date_str<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> partition_name <span style=color:#f92672>in</span> [p<span style=color:#f92672>.</span>name <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> collection<span style=color:#f92672>.</span>partitions]:
</span></span><span style=display:flex><span>        collection<span style=color:#f92672>.</span>load(partition_names<span style=color:#f92672>=</span>[partition_name])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>release_old_partitions</span>(keep_days<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>):
</span></span><span style=display:flex><span>    <span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime, timedelta
</span></span><span style=display:flex><span>    cutoff_date <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>now() <span style=color:#f92672>-</span> timedelta(days<span style=color:#f92672>=</span>keep_days)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> partition <span style=color:#f92672>in</span> collection<span style=color:#f92672>.</span>partitions:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> partition<span style=color:#f92672>.</span>name<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#34;partition_&#34;</span>):
</span></span><span style=display:flex><span>            date_str <span style=color:#f92672>=</span> partition<span style=color:#f92672>.</span>name<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;partition_&#34;</span>, <span style=color:#e6db74>&#34;&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                partition_date <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>strptime(date_str, <span style=color:#e6db74>&#34;%Y%m</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> partition_date <span style=color:#f92672>&lt;</span> cutoff_date:
</span></span><span style=display:flex><span>                    collection<span style=color:#f92672>.</span>release(partition_names<span style=color:#f92672>=</span>[partition<span style=color:#f92672>.</span>name])
</span></span><span style=display:flex><span>                    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Released partition: </span><span style=color:#e6db74>{</span>partition<span style=color:#f92672>.</span>name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>ValueError</span>:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>continue</span>
</span></span></code></pre></div><h3 id=批处理优化>批处理优化<a hidden class=anchor aria-hidden=true href=#批处理优化>#</a></h3><h4 id=批量插入优化>批量插入优化<a hidden class=anchor aria-hidden=true href=#批量插入优化>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>optimized_batch_insert</span>(collection, data, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;优化的批量插入函数&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    total_entities <span style=color:#f92672>=</span> len(data[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, total_entities, batch_size):
</span></span><span style=display:flex><span>        end_idx <span style=color:#f92672>=</span> min(i <span style=color:#f92672>+</span> batch_size, total_entities)
</span></span><span style=display:flex><span>        batch_data <span style=color:#f92672>=</span> [field_data[i:end_idx] <span style=color:#66d9ef>for</span> field_data <span style=color:#f92672>in</span> data]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 插入批次</span>
</span></span><span style=display:flex><span>        collection<span style=color:#f92672>.</span>insert(batch_data)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 定期刷新</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> (i <span style=color:#f92672>+</span> batch_size) <span style=color:#f92672>%</span> <span style=color:#ae81ff>50000</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>flush()
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inserted and flushed </span><span style=color:#e6db74>{</span>i <span style=color:#f92672>+</span> batch_size<span style=color:#e6db74>}</span><span style=color:#e6db74> entities&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 最终刷新</span>
</span></span><span style=display:flex><span>    collection<span style=color:#f92672>.</span>flush()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Completed insertion of </span><span style=color:#e6db74>{</span>total_entities<span style=color:#e6db74>}</span><span style=color:#e6db74> entities&#34;</span>)
</span></span></code></pre></div><h4 id=并行搜索>并行搜索<a hidden class=anchor aria-hidden=true href=#并行搜索>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> concurrent.futures
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> threading
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parallel_search</span>(collection, query_vectors, search_params, max_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;并行执行多个搜索请求&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_batch</span>(vectors_batch):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>            data<span style=color:#f92672>=</span>vectors_batch,
</span></span><span style=display:flex><span>            anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>            param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>            limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将查询向量分批</span>
</span></span><span style=display:flex><span>    batch_size <span style=color:#f92672>=</span> len(query_vectors) <span style=color:#f92672>//</span> max_workers
</span></span><span style=display:flex><span>    batches <span style=color:#f92672>=</span> [query_vectors[i:i<span style=color:#f92672>+</span>batch_size] 
</span></span><span style=display:flex><span>               <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, len(query_vectors), batch_size)]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 并行执行搜索</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> concurrent<span style=color:#f92672>.</span>futures<span style=color:#f92672>.</span>ThreadPoolExecutor(max_workers<span style=color:#f92672>=</span>max_workers) <span style=color:#66d9ef>as</span> executor:
</span></span><span style=display:flex><span>        future_to_batch <span style=color:#f92672>=</span> {executor<span style=color:#f92672>.</span>submit(search_batch, batch): batch 
</span></span><span style=display:flex><span>                          <span style=color:#66d9ef>for</span> batch <span style=color:#f92672>in</span> batches}
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        all_results <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> future <span style=color:#f92672>in</span> concurrent<span style=color:#f92672>.</span>futures<span style=color:#f92672>.</span>as_completed(future_to_batch):
</span></span><span style=display:flex><span>            batch_results <span style=color:#f92672>=</span> future<span style=color:#f92672>.</span>result()
</span></span><span style=display:flex><span>            all_results<span style=color:#f92672>.</span>extend(batch_results)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> all_results
</span></span></code></pre></div><h3 id=连接池管理>连接池管理<a hidden class=anchor aria-hidden=true href=#连接池管理>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> connections
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> threading
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MilvusConnectionPool</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, host<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;localhost&#39;</span>, port<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;19530&#39;</span>, pool_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>host <span style=color:#f92672>=</span> host
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>port <span style=color:#f92672>=</span> port
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>pool_size <span style=color:#f92672>=</span> pool_size
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>connections <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>lock <span style=color:#f92672>=</span> threading<span style=color:#f92672>.</span>Lock()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_initialize_pool()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_initialize_pool</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(self<span style=color:#f92672>.</span>pool_size):
</span></span><span style=display:flex><span>            alias <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;connection_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>            connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>                alias<span style=color:#f92672>=</span>alias,
</span></span><span style=display:flex><span>                host<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>host,
</span></span><span style=display:flex><span>                port<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>port
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>connections<span style=color:#f92672>.</span>append(alias)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_connection</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> self<span style=color:#f92672>.</span>lock:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>connections:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>connections<span style=color:#f92672>.</span>pop()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># 如果池为空，创建新连接</span>
</span></span><span style=display:flex><span>                alias <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;temp_connection_</span><span style=color:#e6db74>{</span>threading<span style=color:#f92672>.</span>current_thread()<span style=color:#f92672>.</span>ident<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>                connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>                    alias<span style=color:#f92672>=</span>alias,
</span></span><span style=display:flex><span>                    host<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>host,
</span></span><span style=display:flex><span>                    port<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>port
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>return</span> alias
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>return_connection</span>(self, alias):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> self<span style=color:#f92672>.</span>lock:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> len(self<span style=color:#f92672>.</span>connections) <span style=color:#f92672>&lt;</span> self<span style=color:#f92672>.</span>pool_size:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>connections<span style=color:#f92672>.</span>append(alias)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                connections<span style=color:#f92672>.</span>disconnect(alias)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用连接池</span>
</span></span><span style=display:flex><span>pool <span style=color:#f92672>=</span> MilvusConnectionPool()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_with_pool</span>(query_vector):
</span></span><span style=display:flex><span>    alias <span style=color:#f92672>=</span> pool<span style=color:#f92672>.</span>get_connection()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用指定连接执行搜索</span>
</span></span><span style=display:flex><span>        connections<span style=color:#f92672>.</span>connect(alias<span style=color:#f92672>=</span>alias)
</span></span><span style=display:flex><span>        collection <span style=color:#f92672>=</span> Collection(<span style=color:#e6db74>&#34;documents&#34;</span>, using<span style=color:#f92672>=</span>alias)
</span></span><span style=display:flex><span>        results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>            data<span style=color:#f92672>=</span>[query_vector],
</span></span><span style=display:flex><span>            anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>            param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}},
</span></span><span style=display:flex><span>            limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> results
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>finally</span>:
</span></span><span style=display:flex><span>        pool<span style=color:#f92672>.</span>return_connection(alias)
</span></span></code></pre></div><h2 id=9-集群部署>9. 集群部署<a hidden class=anchor aria-hidden=true href=#9-集群部署>#</a></h2><h3 id=kubernetes集群部署>Kubernetes集群部署<a hidden class=anchor aria-hidden=true href=#kubernetes集群部署>#</a></h3><h4 id=1-准备配置文件>1. 准备配置文件<a hidden class=anchor aria-hidden=true href=#1-准备配置文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># milvus-cluster-values.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>cluster</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>image</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>all</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>repository</span>: <span style=color:#ae81ff>milvusdb/milvus</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>tag</span>: <span style=color:#ae81ff>v2.3.0</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>pullPolicy</span>: <span style=color:#ae81ff>IfNotPresent</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>service</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>type</span>: <span style=color:#ae81ff>LoadBalancer</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>port</span>: <span style=color:#ae81ff>19530</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>portName</span>: <span style=color:#ae81ff>milvus</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodePort</span>: <span style=color:#ae81ff>30530</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>rootCoordinator</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>2Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>1Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>queryCoordinator</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>2Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>1Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>queryNode</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>8Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>4Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>indexNode</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>4Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>2Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>dataNode</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>4Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>2Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>proxy</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>2Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>1Gi</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 存储配置</span>
</span></span><span style=display:flex><span><span style=color:#f92672>minio</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>mode</span>: <span style=color:#ae81ff>distributed</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>persistence</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>size</span>: <span style=color:#ae81ff>100Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>storageClass</span>: <span style=color:#e6db74>&#34;fast-ssd&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>etcd</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicaCount</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>persistence</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>size</span>: <span style=color:#ae81ff>10Gi</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>storageClass</span>: <span style=color:#e6db74>&#34;fast-ssd&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>pulsar</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>components</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>broker</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>bookkeeper</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>zookeeper</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>zookeeper</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>replicaCount</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>bookkeeper</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>replicaCount</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>broker</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>replicaCount</span>: <span style=color:#ae81ff>2</span>
</span></span></code></pre></div><h4 id=2-部署集群>2. 部署集群<a hidden class=anchor aria-hidden=true href=#2-部署集群>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 创建命名空间</span>
</span></span><span style=display:flex><span>kubectl create namespace milvus-cluster
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 部署Milvus集群</span>
</span></span><span style=display:flex><span>helm install milvus-cluster milvus/milvus <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace milvus-cluster <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --values milvus-cluster-values.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查部署状态</span>
</span></span><span style=display:flex><span>kubectl get pods -n milvus-cluster
</span></span><span style=display:flex><span>kubectl get services -n milvus-cluster
</span></span></code></pre></div><h4 id=3-配置负载均衡>3. 配置负载均衡<a hidden class=anchor aria-hidden=true href=#3-配置负载均衡>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># milvus-ingress.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Ingress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>milvus-ingress</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>milvus-cluster</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nginx.ingress.kubernetes.io/backend-protocol</span>: <span style=color:#e6db74>&#34;GRPC&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>nginx.ingress.kubernetes.io/grpc-backend</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>ingressClassName</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>rules</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>host</span>: <span style=color:#ae81ff>milvus.example.com</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>paths</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>pathType</span>: <span style=color:#ae81ff>Prefix</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>backend</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>service</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>name</span>: <span style=color:#ae81ff>milvus-cluster</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>port</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>number</span>: <span style=color:#ae81ff>19530</span>
</span></span></code></pre></div><h3 id=高可用配置>高可用配置<a hidden class=anchor aria-hidden=true href=#高可用配置>#</a></h3><h4 id=多副本配置>多副本配置<a hidden class=anchor aria-hidden=true href=#多副本配置>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 连接到集群</span>
</span></span><span style=display:flex><span>connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>    alias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;cluster&#34;</span>,
</span></span><span style=display:flex><span>    host<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;milvus.example.com&#39;</span>,
</span></span><span style=display:flex><span>    port<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;19530&#39;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 创建集合时指定副本数</span>
</span></span><span style=display:flex><span>collection <span style=color:#f92672>=</span> Collection(<span style=color:#e6db74>&#34;ha_collection&#34;</span>, schema<span style=color:#f92672>=</span>schema)
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>create_index(field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>, index_params<span style=color:#f92672>=</span>index_params)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 加载时指定副本数</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load(replica_number<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查副本状态</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>replica_info <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>get_replicas(collection<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> replica <span style=color:#f92672>in</span> replica_info:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Replica </span><span style=color:#e6db74>{</span>replica<span style=color:#f92672>.</span>id<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>replica<span style=color:#f92672>.</span>node_ids<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=故障转移测试>故障转移测试<a hidden class=anchor aria-hidden=true href=#故障转移测试>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_failover</span>(collection):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;测试故障转移能力&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>    <span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    query_vector <span style=color:#f92672>=</span> [random<span style=color:#f92672>.</span>random() <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>256</span>)]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 持续查询测试</span>
</span></span><span style=display:flex><span>    success_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>                data<span style=color:#f92672>=</span>[query_vector],
</span></span><span style=display:flex><span>                anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>                param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}},
</span></span><span style=display:flex><span>                limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            success_count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Query </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>: Success&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Query </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>: Failed - </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Success rate: </span><span style=color:#e6db74>{</span>success_count<span style=color:#f92672>/</span>total_count<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span></code></pre></div><h3 id=数据分片策略>数据分片策略<a hidden class=anchor aria-hidden=true href=#数据分片策略>#</a></h3><h4 id=基于时间的分片>基于时间的分片<a hidden class=anchor aria-hidden=true href=#基于时间的分片>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime, timedelta
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_time_based_partitions</span>(collection, start_date, end_date):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;创建基于时间的分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    current_date <span style=color:#f92672>=</span> start_date
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> current_date <span style=color:#f92672>&lt;=</span> end_date:
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_</span><span style=color:#e6db74>{</span>current_date<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#39;%Y%m</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>create_partition(partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Created partition: </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Partition </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74> already exists or error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        current_date <span style=color:#f92672>+=</span> timedelta(days<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>insert_with_time_partition</span>(collection, entities, timestamp_field_idx<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;根据时间戳插入到对应分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 按时间戳分组数据</span>
</span></span><span style=display:flex><span>    partition_data <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, timestamp <span style=color:#f92672>in</span> enumerate(entities[timestamp_field_idx]):
</span></span><span style=display:flex><span>        date_str <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>fromtimestamp(timestamp)<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#39;%Y%m</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_</span><span style=color:#e6db74>{</span>date_str<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> partition_name <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> partition_data:
</span></span><span style=display:flex><span>            partition_data[partition_name] <span style=color:#f92672>=</span> [[] <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> entities]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> j, field_data <span style=color:#f92672>in</span> enumerate(entities):
</span></span><span style=display:flex><span>            partition_data[partition_name][j]<span style=color:#f92672>.</span>append(field_data[i])
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 分别插入到各个分区</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> partition_name, partition_entities <span style=color:#f92672>in</span> partition_data<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>insert(partition_entities, partition_name<span style=color:#f92672>=</span>partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inserted </span><span style=color:#e6db74>{</span>len(partition_entities[<span style=color:#ae81ff>0</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74> entities to </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Failed to insert to </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h4 id=基于哈希的分片>基于哈希的分片<a hidden class=anchor aria-hidden=true href=#基于哈希的分片>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> hashlib
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_hash_based_partitions</span>(collection, num_partitions<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;创建基于哈希的分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_partitions):
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_hash_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>create_partition(partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Created partition: </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Partition </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74> already exists or error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>insert_with_hash_partition</span>(collection, entities, key_field_idx<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, num_partitions<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;根据键值哈希插入到对应分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    partition_data <span style=color:#f92672>=</span> {<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_hash_</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>: [[] <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> entities] 
</span></span><span style=display:flex><span>                     <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_partitions)}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, key <span style=color:#f92672>in</span> enumerate(entities[key_field_idx]):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 计算哈希值确定分区</span>
</span></span><span style=display:flex><span>        hash_value <span style=color:#f92672>=</span> int(hashlib<span style=color:#f92672>.</span>md5(str(key)<span style=color:#f92672>.</span>encode())<span style=color:#f92672>.</span>hexdigest(), <span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>        partition_idx <span style=color:#f92672>=</span> hash_value <span style=color:#f92672>%</span> num_partitions
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_hash_</span><span style=color:#e6db74>{</span>partition_idx<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> j, field_data <span style=color:#f92672>in</span> enumerate(entities):
</span></span><span style=display:flex><span>            partition_data[partition_name][j]<span style=color:#f92672>.</span>append(field_data[i])
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 插入到各个分区</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> partition_name, partition_entities <span style=color:#f92672>in</span> partition_data<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> partition_entities[<span style=color:#ae81ff>0</span>]:  <span style=color:#75715e># 如果分区有数据</span>
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>insert(partition_entities, partition_name<span style=color:#f92672>=</span>partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inserted </span><span style=color:#e6db74>{</span>len(partition_entities[<span style=color:#ae81ff>0</span>])<span style=color:#e6db74>}</span><span style=color:#e6db74> entities to </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h2 id=10-监控运维>10. 监控运维<a hidden class=anchor aria-hidden=true href=#10-监控运维>#</a></h2><h3 id=系统监控>系统监控<a hidden class=anchor aria-hidden=true href=#系统监控>#</a></h3><h4 id=prometheus监控配置>Prometheus监控配置<a hidden class=anchor aria-hidden=true href=#prometheus监控配置>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># prometheus-config.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>global</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>15s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>scrape_configs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;milvus&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>static_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>targets</span>: [<span style=color:#e6db74>&#39;milvus:9091&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#f92672>metrics_path</span>: <span style=color:#ae81ff>/metrics</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>scrape_interval</span>: <span style=color:#ae81ff>15s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>job_name</span>: <span style=color:#e6db74>&#39;milvus-cluster&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>kubernetes_sd_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>role</span>: <span style=color:#ae81ff>pod</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>namespaces</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>names</span>:
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>milvus-cluster</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>relabel_configs</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>__meta_kubernetes_pod_label_app_kubernetes_io_name]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>action</span>: <span style=color:#ae81ff>keep</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>regex</span>: <span style=color:#ae81ff>milvus</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>action</span>: <span style=color:#ae81ff>keep</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>regex</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>source_labels</span>: [<span style=color:#ae81ff>__meta_kubernetes_pod_annotation_prometheus_io_port]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>action</span>: <span style=color:#ae81ff>replace</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>target_label</span>: <span style=color:#ae81ff>__address__</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>regex</span>: <span style=color:#ae81ff>(.+)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>replacement</span>: <span style=color:#ae81ff>${1}:9091</span>
</span></span></code></pre></div><h4 id=grafana仪表板>Grafana仪表板<a hidden class=anchor aria-hidden=true href=#grafana仪表板>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;dashboard&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;title&#34;</span>: <span style=color:#e6db74>&#34;Milvus Monitoring&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;panels&#34;</span>: [
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;title&#34;</span>: <span style=color:#e6db74>&#34;QPS (Queries Per Second)&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;graph&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;targets&#34;</span>: [
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;rate(milvus_proxy_search_vectors_count[5m])&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;Search QPS&#34;</span>
</span></span><span style=display:flex><span>          },
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;rate(milvus_proxy_insert_vectors_count[5m])&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;Insert QPS&#34;</span>
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;title&#34;</span>: <span style=color:#e6db74>&#34;Response Time&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;graph&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;targets&#34;</span>: [
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;histogram_quantile(0.95, rate(milvus_proxy_search_latency_bucket[5m]))&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;Search P95 Latency&#34;</span>
</span></span><span style=display:flex><span>          },
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;histogram_quantile(0.99, rate(milvus_proxy_search_latency_bucket[5m]))&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;Search P99 Latency&#34;</span>
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;title&#34;</span>: <span style=color:#e6db74>&#34;Memory Usage&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;graph&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;targets&#34;</span>: [
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;milvus_querynode_memory_usage_bytes&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;QueryNode Memory&#34;</span>
</span></span><span style=display:flex><span>          },
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;milvus_indexnode_memory_usage_bytes&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;legendFormat&#34;</span>: <span style=color:#e6db74>&#34;IndexNode Memory&#34;</span>
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;title&#34;</span>: <span style=color:#e6db74>&#34;Collection Statistics&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;table&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;targets&#34;</span>: [
</span></span><span style=display:flex><span>          {
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;expr&#34;</span>: <span style=color:#e6db74>&#34;milvus_collection_num_entities&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#f92672>&#34;format&#34;</span>: <span style=color:#e6db74>&#34;table&#34;</span>
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=性能监控>性能监控<a hidden class=anchor aria-hidden=true href=#性能监控>#</a></h3><h4 id=自定义监控脚本>自定义监控脚本<a hidden class=anchor aria-hidden=true href=#自定义监控脚本>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> psutil
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> threading
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> connections, Collection, utility
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MilvusMonitor</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, collection_name, interval<span style=color:#f92672>=</span><span style=color:#ae81ff>60</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection_name <span style=color:#f92672>=</span> collection_name
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>interval <span style=color:#f92672>=</span> interval
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>running <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>metrics <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>start_monitoring</span>(self):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>running <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>        monitor_thread <span style=color:#f92672>=</span> threading<span style=color:#f92672>.</span>Thread(target<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>_monitor_loop)
</span></span><span style=display:flex><span>        monitor_thread<span style=color:#f92672>.</span>daemon <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>        monitor_thread<span style=color:#f92672>.</span>start()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>stop_monitoring</span>(self):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>running <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_monitor_loop</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> self<span style=color:#f92672>.</span>running:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                metrics <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_collect_metrics()
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>append(metrics)
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;[</span><span style=color:#e6db74>{</span>metrics[<span style=color:#e6db74>&#39;timestamp&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>] </span><span style=color:#e6db74>{</span>metrics<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#75715e># 保留最近1000条记录</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> len(self<span style=color:#f92672>.</span>metrics) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1000</span>:
</span></span><span style=display:flex><span>                    self<span style=color:#f92672>.</span>metrics <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>metrics[<span style=color:#f92672>-</span><span style=color:#ae81ff>1000</span>:]
</span></span><span style=display:flex><span>                    
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Monitoring error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>            time<span style=color:#f92672>.</span>sleep(self<span style=color:#f92672>.</span>interval)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_collect_metrics</span>(self):
</span></span><span style=display:flex><span>        collection <span style=color:#f92672>=</span> Collection(self<span style=color:#f92672>.</span>collection_name)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 集合统计信息</span>
</span></span><span style=display:flex><span>        stats <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>get_stats()
</span></span><span style=display:flex><span>        num_entities <span style=color:#f92672>=</span> int(stats[<span style=color:#e6db74>&#39;row_count&#39;</span>])
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 系统资源</span>
</span></span><span style=display:flex><span>        cpu_percent <span style=color:#f92672>=</span> psutil<span style=color:#f92672>.</span>cpu_percent()
</span></span><span style=display:flex><span>        memory <span style=color:#f92672>=</span> psutil<span style=color:#f92672>.</span>virtual_memory()
</span></span><span style=display:flex><span>        disk <span style=color:#f92672>=</span> psutil<span style=color:#f92672>.</span>disk_usage(<span style=color:#e6db74>&#39;/&#39;</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 查询性能测试</span>
</span></span><span style=display:flex><span>        start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            test_vector <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>256</span>
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>                data<span style=color:#f92672>=</span>[test_vector],
</span></span><span style=display:flex><span>                anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;vector&#34;</span>,
</span></span><span style=display:flex><span>                param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>16</span>}},
</span></span><span style=display:flex><span>                limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            query_latency <span style=color:#f92672>=</span> (time<span style=color:#f92672>.</span>time() <span style=color:#f92672>-</span> start_time) <span style=color:#f92672>*</span> <span style=color:#ae81ff>1000</span>  <span style=color:#75715e># ms</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            query_latency <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;timestamp&#39;</span>: datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;collection_entities&#39;</span>: num_entities,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;cpu_percent&#39;</span>: cpu_percent,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;memory_percent&#39;</span>: memory<span style=color:#f92672>.</span>percent,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;memory_used_gb&#39;</span>: memory<span style=color:#f92672>.</span>used <span style=color:#f92672>/</span> (<span style=color:#ae81ff>1024</span><span style=color:#f92672>**</span><span style=color:#ae81ff>3</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;disk_percent&#39;</span>: disk<span style=color:#f92672>.</span>percent,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;disk_used_gb&#39;</span>: disk<span style=color:#f92672>.</span>used <span style=color:#f92672>/</span> (<span style=color:#ae81ff>1024</span><span style=color:#f92672>**</span><span style=color:#ae81ff>3</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;query_latency_ms&#39;</span>: query_latency
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_metrics_summary</span>(self, last_n<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;获取最近N条记录的统计摘要&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> self<span style=color:#f92672>.</span>metrics:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        recent_metrics <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>metrics[<span style=color:#f92672>-</span>last_n:]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        latencies <span style=color:#f92672>=</span> [m[<span style=color:#e6db74>&#39;query_latency_ms&#39;</span>] <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> recent_metrics <span style=color:#66d9ef>if</span> m[<span style=color:#e6db74>&#39;query_latency_ms&#39;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        cpu_usage <span style=color:#f92672>=</span> [m[<span style=color:#e6db74>&#39;cpu_percent&#39;</span>] <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> recent_metrics]
</span></span><span style=display:flex><span>        memory_usage <span style=color:#f92672>=</span> [m[<span style=color:#e6db74>&#39;memory_percent&#39;</span>] <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> recent_metrics]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;avg_query_latency_ms&#39;</span>: sum(latencies) <span style=color:#f92672>/</span> len(latencies) <span style=color:#66d9ef>if</span> latencies <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;max_query_latency_ms&#39;</span>: max(latencies) <span style=color:#66d9ef>if</span> latencies <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;avg_cpu_percent&#39;</span>: sum(cpu_usage) <span style=color:#f92672>/</span> len(cpu_usage),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;max_cpu_percent&#39;</span>: max(cpu_usage),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;avg_memory_percent&#39;</span>: sum(memory_usage) <span style=color:#f92672>/</span> len(memory_usage),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;max_memory_percent&#39;</span>: max(memory_usage),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;total_entities&#39;</span>: recent_metrics[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>][<span style=color:#e6db74>&#39;collection_entities&#39;</span>] <span style=color:#66d9ef>if</span> recent_metrics <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用监控器</span>
</span></span><span style=display:flex><span>monitor <span style=color:#f92672>=</span> MilvusMonitor(<span style=color:#e6db74>&#34;documents&#34;</span>, interval<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>)
</span></span><span style=display:flex><span>monitor<span style=color:#f92672>.</span>start_monitoring()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 运行一段时间后查看摘要</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>300</span>)  <span style=color:#75715e># 5分钟</span>
</span></span><span style=display:flex><span>summary <span style=color:#f92672>=</span> monitor<span style=color:#f92672>.</span>get_metrics_summary()
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Performance Summary: </span><span style=color:#e6db74>{</span>summary<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>monitor<span style=color:#f92672>.</span>stop_monitoring()
</span></span></code></pre></div><h3 id=日志管理>日志管理<a hidden class=anchor aria-hidden=true href=#日志管理>#</a></h3><h4 id=日志配置>日志配置<a hidden class=anchor aria-hidden=true href=#日志配置>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># milvus-log-config.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>log</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>level</span>: <span style=color:#ae81ff>info</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>file</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>rootPath</span>: <span style=color:#e6db74>&#34;/var/log/milvus&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxSize</span>: <span style=color:#ae81ff>100</span>  <span style=color:#75715e># MB</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxAge</span>: <span style=color:#ae81ff>7</span>     <span style=color:#75715e># days</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxBackups</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>format</span>: <span style=color:#ae81ff>json</span>
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span><span style=color:#75715e># 在Kubernetes中配置日志收集</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ConfigMap</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>fluent-bit-config</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>milvus-cluster</span>
</span></span><span style=display:flex><span><span style=color:#f92672>data</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>fluent-bit.conf</span>: |<span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [SERVICE]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Flush         1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Log_Level     info
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Daemon        off
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Parsers_File  parsers.conf
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [INPUT]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Name              tail
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Path              /var/log/milvus/*.log
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Parser            json
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Tag               milvus.*
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Refresh_Interval  5
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    [OUTPUT]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Name  es
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Match milvus.*
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Host  elasticsearch.logging.svc.cluster.local
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Port  9200
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Index milvus-logs
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Type  _doc</span>
</span></span></code></pre></div><h4 id=日志分析脚本>日志分析脚本<a hidden class=anchor aria-hidden=true href=#日志分析脚本>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime, timedelta
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>analyze_milvus_logs</span>(log_file_path, hours<span style=color:#f92672>=</span><span style=color:#ae81ff>24</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;分析Milvus日志文件&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    cutoff_time <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>now() <span style=color:#f92672>-</span> timedelta(hours<span style=color:#f92672>=</span>hours)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    error_counts <span style=color:#f92672>=</span> defaultdict(int)
</span></span><span style=display:flex><span>    warning_counts <span style=color:#f92672>=</span> defaultdict(int)
</span></span><span style=display:flex><span>    performance_metrics <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> open(log_file_path, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> f:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                log_entry <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(line<span style=color:#f92672>.</span>strip())
</span></span><span style=display:flex><span>                log_time <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>fromisoformat(log_entry<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;time&#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;Z&#39;</span>, <span style=color:#e6db74>&#39;+00:00&#39;</span>))
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> log_time <span style=color:#f92672>&lt;</span> cutoff_time:
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>                    
</span></span><span style=display:flex><span>                level <span style=color:#f92672>=</span> log_entry<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;level&#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)<span style=color:#f92672>.</span>upper()
</span></span><span style=display:flex><span>                message <span style=color:#f92672>=</span> log_entry<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;msg&#39;</span>, <span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#75715e># 统计错误和警告</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> level <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;ERROR&#39;</span>:
</span></span><span style=display:flex><span>                    error_counts[message] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>elif</span> level <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;WARN&#39;</span>:
</span></span><span style=display:flex><span>                    warning_counts[message] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>                    
</span></span><span style=display:flex><span>                <span style=color:#75715e># 提取性能指标</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;latency&#39;</span> <span style=color:#f92672>in</span> message<span style=color:#f92672>.</span>lower():
</span></span><span style=display:flex><span>                    latency_match <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>search(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;latency[:\s]+(\d+(?:\.\d+)?)\s*(ms|μs)&#39;</span>, message)
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>if</span> latency_match:
</span></span><span style=display:flex><span>                        latency_value <span style=color:#f92672>=</span> float(latency_match<span style=color:#f92672>.</span>group(<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>                        latency_unit <span style=color:#f92672>=</span> latency_match<span style=color:#f92672>.</span>group(<span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>                        
</span></span><span style=display:flex><span>                        <span style=color:#66d9ef>if</span> latency_unit <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;μs&#39;</span>:
</span></span><span style=display:flex><span>                            latency_value <span style=color:#f92672>/=</span> <span style=color:#ae81ff>1000</span>  <span style=color:#75715e># 转换为ms</span>
</span></span><span style=display:flex><span>                            
</span></span><span style=display:flex><span>                        performance_metrics<span style=color:#f92672>.</span>append({
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;timestamp&#39;</span>: log_time,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;latency_ms&#39;</span>: latency_value,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;operation&#39;</span>: extract_operation(message)
</span></span><span style=display:flex><span>                        })
</span></span><span style=display:flex><span>                        
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> (json<span style=color:#f92672>.</span>JSONDecodeError, <span style=color:#a6e22e>ValueError</span>) <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;error_summary&#39;</span>: dict(error_counts),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;warning_summary&#39;</span>: dict(warning_counts),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;performance_metrics&#39;</span>: performance_metrics
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>extract_operation</span>(message):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;从日志消息中提取操作类型&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;search&#39;</span> <span style=color:#f92672>in</span> message<span style=color:#f92672>.</span>lower():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;search&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#39;insert&#39;</span> <span style=color:#f92672>in</span> message<span style=color:#f92672>.</span>lower():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;insert&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#39;index&#39;</span> <span style=color:#f92672>in</span> message<span style=color:#f92672>.</span>lower():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;index&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;unknown&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_log_report</span>(analysis_result):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;生成日志分析报告&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;=== Milvus Log Analysis Report ===&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Analysis time: </span><span style=color:#e6db74>{</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 错误摘要</span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Top Errors:&#34;</span>)
</span></span><span style=display:flex><span>    sorted_errors <span style=color:#f92672>=</span> sorted(analysis_result[<span style=color:#e6db74>&#39;error_summary&#39;</span>]<span style=color:#f92672>.</span>items(), 
</span></span><span style=display:flex><span>                          key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: x[<span style=color:#ae81ff>1</span>], reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> error, count <span style=color:#f92672>in</span> sorted_errors[:<span style=color:#ae81ff>10</span>]:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  </span><span style=color:#e6db74>{</span>count<span style=color:#e6db74>:</span><span style=color:#e6db74>4d</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - </span><span style=color:#e6db74>{</span>error[:<span style=color:#ae81ff>100</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>...&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 警告摘要</span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Top Warnings:&#34;</span>)
</span></span><span style=display:flex><span>    sorted_warnings <span style=color:#f92672>=</span> sorted(analysis_result[<span style=color:#e6db74>&#39;warning_summary&#39;</span>]<span style=color:#f92672>.</span>items(), 
</span></span><span style=display:flex><span>                           key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: x[<span style=color:#ae81ff>1</span>], reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> warning, count <span style=color:#f92672>in</span> sorted_warnings[:<span style=color:#ae81ff>10</span>]:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  </span><span style=color:#e6db74>{</span>count<span style=color:#e6db74>:</span><span style=color:#e6db74>4d</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - </span><span style=color:#e6db74>{</span>warning[:<span style=color:#ae81ff>100</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>...&#34;</span>)
</span></span><span style=display:flex><span>    print()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 性能摘要</span>
</span></span><span style=display:flex><span>    metrics <span style=color:#f92672>=</span> analysis_result[<span style=color:#e6db74>&#39;performance_metrics&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> metrics:
</span></span><span style=display:flex><span>        latencies <span style=color:#f92672>=</span> [m[<span style=color:#e6db74>&#39;latency_ms&#39;</span>] <span style=color:#66d9ef>for</span> m <span style=color:#f92672>in</span> metrics]
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Performance Summary:&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Total operations: </span><span style=color:#e6db74>{</span>len(metrics)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Average latency: </span><span style=color:#e6db74>{</span>sum(latencies)<span style=color:#f92672>/</span>len(latencies)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> ms&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Max latency: </span><span style=color:#e6db74>{</span>max(latencies)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> ms&#34;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  Min latency: </span><span style=color:#e6db74>{</span>min(latencies)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> ms&#34;</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 按操作类型分组</span>
</span></span><span style=display:flex><span>        by_operation <span style=color:#f92672>=</span> defaultdict(list)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> metric <span style=color:#f92672>in</span> metrics:
</span></span><span style=display:flex><span>            by_operation[metric[<span style=color:#e6db74>&#39;operation&#39;</span>]]<span style=color:#f92672>.</span>append(metric[<span style=color:#e6db74>&#39;latency_ms&#39;</span>])
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Performance by Operation:&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> operation, latencies <span style=color:#f92672>in</span> by_operation<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> latencies:
</span></span><span style=display:flex><span>                avg_latency <span style=color:#f92672>=</span> sum(latencies) <span style=color:#f92672>/</span> len(latencies)
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;  </span><span style=color:#e6db74>{</span>operation<span style=color:#f92672>.</span>capitalize()<span style=color:#e6db74>}</span><span style=color:#e6db74>:&#34;</span>)
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;    Count: </span><span style=color:#e6db74>{</span>len(latencies)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;    Avg latency: </span><span style=color:#e6db74>{</span>avg_latency<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> ms&#34;</span>)
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;    Max latency: </span><span style=color:#e6db74>{</span>max(latencies)<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> ms&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;No performance metrics found.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用示例</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    log_file <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/path/to/milvus.log&#34;</span>
</span></span><span style=display:flex><span>    result <span style=color:#f92672>=</span> analyze_milvus_logs(log_file, hours<span style=color:#f92672>=</span><span style=color:#ae81ff>24</span>)
</span></span><span style=display:flex><span>    generate_log_report(result)
</span></span></code></pre></div><h2 id=11-最佳实践>11. 最佳实践<a hidden class=anchor aria-hidden=true href=#11-最佳实践>#</a></h2><h3 id=1-数据建模最佳实践>1. 数据建模最佳实践<a hidden class=anchor aria-hidden=true href=#1-数据建模最佳实践>#</a></h3><h4 id=collection设计原则>Collection设计原则<a hidden class=anchor aria-hidden=true href=#collection设计原则>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 良好的Collection设计示例</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_production_collection</span>(name, vector_dim, expected_size):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;生产环境Collection设计&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 根据数据规模选择分片数</span>
</span></span><span style=display:flex><span>    shard_num <span style=color:#f92672>=</span> min(max(expected_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>1000000</span>, <span style=color:#ae81ff>2</span>), <span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    fields <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>        <span style=color:#75715e># 主键字段 - 使用有意义的ID</span>
</span></span><span style=display:flex><span>        FieldSchema(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;id&#34;</span>, 
</span></span><span style=display:flex><span>            dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64, 
</span></span><span style=display:flex><span>            is_primary<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>            auto_id<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>            description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Document unique identifier&#34;</span>
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        <span style=color:#75715e># 时间戳字段 - 便于数据管理</span>
</span></span><span style=display:flex><span>        FieldSchema(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;created_at&#34;</span>, 
</span></span><span style=display:flex><span>            dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>INT64,
</span></span><span style=display:flex><span>            description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Creation timestamp&#34;</span>
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分类字段 - 用于过滤</span>
</span></span><span style=display:flex><span>        FieldSchema(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;category&#34;</span>, 
</span></span><span style=display:flex><span>            dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>VARCHAR, 
</span></span><span style=display:flex><span>            max_length<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>,
</span></span><span style=display:flex><span>            description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Document category&#34;</span>
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        <span style=color:#75715e># 向量字段 - 核心搜索字段</span>
</span></span><span style=display:flex><span>        FieldSchema(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>, 
</span></span><span style=display:flex><span>            dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>FLOAT_VECTOR, 
</span></span><span style=display:flex><span>            dim<span style=color:#f92672>=</span>vector_dim,
</span></span><span style=display:flex><span>            description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Document embedding vector&#34;</span>
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        <span style=color:#75715e># 元数据字段 - 存储额外信息</span>
</span></span><span style=display:flex><span>        FieldSchema(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metadata&#34;</span>, 
</span></span><span style=display:flex><span>            dtype<span style=color:#f92672>=</span>DataType<span style=color:#f92672>.</span>JSON,
</span></span><span style=display:flex><span>            description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Additional metadata&#34;</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    schema <span style=color:#f92672>=</span> CollectionSchema(
</span></span><span style=display:flex><span>        fields<span style=color:#f92672>=</span>fields,
</span></span><span style=display:flex><span>        description<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Production collection for </span><span style=color:#e6db74>{</span>expected_size<span style=color:#e6db74>}</span><span style=color:#e6db74> documents&#34;</span>,
</span></span><span style=display:flex><span>        enable_dynamic_field<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>  <span style=color:#75715e># 允许动态字段</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    collection <span style=color:#f92672>=</span> Collection(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span>name,
</span></span><span style=display:flex><span>        schema<span style=color:#f92672>=</span>schema,
</span></span><span style=display:flex><span>        shards_num<span style=color:#f92672>=</span>shard_num,
</span></span><span style=display:flex><span>        consistency_level<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Strong&#34;</span>  <span style=color:#75715e># 生产环境建议强一致性</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> collection
</span></span></code></pre></div><h4 id=分区策略>分区策略<a hidden class=anchor aria-hidden=true href=#分区策略>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 基于时间的分区策略</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_time_based_partitions</span>(collection, start_date, end_date):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;创建基于时间的分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime, timedelta
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    current_date <span style=color:#f92672>=</span> start_date
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> current_date <span style=color:#f92672>&lt;=</span> end_date:
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;partition_</span><span style=color:#e6db74>{</span>current_date<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#39;%Y%m</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>&#39;</span>)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>create_partition(partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Created partition: </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Partition </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74> already exists or error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        current_date <span style=color:#f92672>+=</span> timedelta(days<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 基于类别的分区策略</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_category_partitions</span>(collection, categories):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;创建基于类别的分区&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> category <span style=color:#f92672>in</span> categories:
</span></span><span style=display:flex><span>        partition_name <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;category_</span><span style=color:#e6db74>{</span>category<span style=color:#f92672>.</span>lower()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection<span style=color:#f92672>.</span>create_partition(partition_name)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Created partition: </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Partition </span><span style=color:#e6db74>{</span>partition_name<span style=color:#e6db74>}</span><span style=color:#e6db74> already exists or error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h3 id=2-性能优化最佳实践>2. 性能优化最佳实践<a hidden class=anchor aria-hidden=true href=#2-性能优化最佳实践>#</a></h3><h4 id=索引选择策略>索引选择策略<a hidden class=anchor aria-hidden=true href=#索引选择策略>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>choose_optimal_index</span>(data_size, memory_budget, latency_requirement, accuracy_requirement):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;根据需求选择最优索引&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> data_size <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>100000</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 小数据集使用FLAT</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;FLAT&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;params&#34;</span>: {}
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> latency_requirement <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;ultra_low&#34;</span> <span style=color:#f92672>and</span> memory_budget <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;high&#34;</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 超低延迟需求使用HNSW</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;HNSW&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;M&#34;</span>: <span style=color:#ae81ff>32</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;efConstruction&#34;</span>: <span style=color:#ae81ff>400</span>
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> memory_budget <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;low&#34;</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 内存受限使用PQ压缩</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_PQ&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;nlist&#34;</span>: min(<span style=color:#ae81ff>4</span> <span style=color:#f92672>*</span> int(np<span style=color:#f92672>.</span>sqrt(data_size)), <span style=color:#ae81ff>4096</span>),
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;m&#34;</span>: <span style=color:#ae81ff>16</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;nbits&#34;</span>: <span style=color:#ae81ff>8</span>
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 平衡选择IVF_FLAT</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;params&#34;</span>: {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;nlist&#34;</span>: min(<span style=color:#ae81ff>4</span> <span style=color:#f92672>*</span> int(np<span style=color:#f92672>.</span>sqrt(data_size)), <span style=color:#ae81ff>4096</span>)
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 动态调整搜索参数</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_adaptive_search_params</span>(index_type, accuracy_level<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;medium&#34;</span>, data_size<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;根据索引类型和精度要求动态调整搜索参数&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> index_type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;IVF_FLAT&#34;</span> <span style=color:#f92672>or</span> index_type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;IVF_PQ&#34;</span>:
</span></span><span style=display:flex><span>        nprobe_map <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;low&#34;</span>: max(<span style=color:#ae81ff>8</span>, int(np<span style=color:#f92672>.</span>sqrt(data_size)) <span style=color:#f92672>//</span> <span style=color:#ae81ff>100</span>) <span style=color:#66d9ef>if</span> data_size <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>8</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;medium&#34;</span>: max(<span style=color:#ae81ff>16</span>, int(np<span style=color:#f92672>.</span>sqrt(data_size)) <span style=color:#f92672>//</span> <span style=color:#ae81ff>50</span>) <span style=color:#66d9ef>if</span> data_size <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>16</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;high&#34;</span>: max(<span style=color:#ae81ff>32</span>, int(np<span style=color:#f92672>.</span>sqrt(data_size)) <span style=color:#f92672>//</span> <span style=color:#ae81ff>25</span>) <span style=color:#66d9ef>if</span> data_size <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;nprobe&#34;</span>: nprobe_map[accuracy_level]}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> index_type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;HNSW&#34;</span>:
</span></span><span style=display:flex><span>        ef_map <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;low&#34;</span>: <span style=color:#ae81ff>64</span>, <span style=color:#e6db74>&#34;medium&#34;</span>: <span style=color:#ae81ff>128</span>, <span style=color:#e6db74>&#34;high&#34;</span>: <span style=color:#ae81ff>256</span>}
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;ef&#34;</span>: ef_map[accuracy_level]}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> index_type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;ANNOY&#34;</span>:
</span></span><span style=display:flex><span>        search_k_map <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;low&#34;</span>: <span style=color:#ae81ff>100</span>, <span style=color:#e6db74>&#34;medium&#34;</span>: <span style=color:#ae81ff>200</span>, <span style=color:#e6db74>&#34;high&#34;</span>: <span style=color:#ae81ff>400</span>}
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;search_k&#34;</span>: search_k_map[accuracy_level]}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {}
</span></span></code></pre></div><h4 id=批处理优化-1>批处理优化<a hidden class=anchor aria-hidden=true href=#批处理优化-1>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>OptimizedBatchProcessor</span>:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;优化的批处理器&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, collection, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>, flush_interval<span style=color:#f92672>=</span><span style=color:#ae81ff>50000</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection <span style=color:#f92672>=</span> collection
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>batch_size <span style=color:#f92672>=</span> batch_size
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>flush_interval <span style=color:#f92672>=</span> flush_interval
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>total_inserted <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>insert_batch</span>(self, data):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;批量插入数据&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        total_entities <span style=color:#f92672>=</span> len(data[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>, total_entities, self<span style=color:#f92672>.</span>batch_size):
</span></span><span style=display:flex><span>            end_idx <span style=color:#f92672>=</span> min(i <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>batch_size, total_entities)
</span></span><span style=display:flex><span>            batch_data <span style=color:#f92672>=</span> [field_data[i:end_idx] <span style=color:#66d9ef>for</span> field_data <span style=color:#f92672>in</span> data]
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                result <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>collection<span style=color:#f92672>.</span>insert(batch_data)
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>total_inserted <span style=color:#f92672>+=</span> len(result<span style=color:#f92672>.</span>primary_keys)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#75715e># 定期刷新</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>total_inserted <span style=color:#f92672>%</span> self<span style=color:#f92672>.</span>flush_interval <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>                    self<span style=color:#f92672>.</span>collection<span style=color:#f92672>.</span>flush()
</span></span><span style=display:flex><span>                    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Flushed after inserting </span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>total_inserted<span style=color:#e6db74>}</span><span style=color:#e6db74> entities&#34;</span>)
</span></span><span style=display:flex><span>                    
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Error inserting batch </span><span style=color:#e6db74>{</span>i<span style=color:#f92672>//</span>self<span style=color:#f92672>.</span>batch_size<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 最终刷新</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection<span style=color:#f92672>.</span>flush()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>total_inserted
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parallel_search</span>(self, query_vectors, search_params, max_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;并行搜索&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>import</span> concurrent.futures
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_single</span>(query_vector):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>                data<span style=color:#f92672>=</span>[query_vector],
</span></span><span style=display:flex><span>                anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>                param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>                limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> concurrent<span style=color:#f92672>.</span>futures<span style=color:#f92672>.</span>ThreadPoolExecutor(max_workers<span style=color:#f92672>=</span>max_workers) <span style=color:#66d9ef>as</span> executor:
</span></span><span style=display:flex><span>            futures <span style=color:#f92672>=</span> [executor<span style=color:#f92672>.</span>submit(search_single, qv) <span style=color:#66d9ef>for</span> qv <span style=color:#f92672>in</span> query_vectors]
</span></span><span style=display:flex><span>            results <span style=color:#f92672>=</span> [future<span style=color:#f92672>.</span>result() <span style=color:#66d9ef>for</span> future <span style=color:#f92672>in</span> concurrent<span style=color:#f92672>.</span>futures<span style=color:#f92672>.</span>as_completed(futures)]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> results
</span></span></code></pre></div><h3 id=3-数据质量最佳实践>3. 数据质量最佳实践<a hidden class=anchor aria-hidden=true href=#3-数据质量最佳实践>#</a></h3><h4 id=向量预处理>向量预处理<a hidden class=anchor aria-hidden=true href=#向量预处理>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> normalize
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>preprocess_vectors</span>(vectors, normalization<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l2&#34;</span>, dimension_check<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;向量预处理管道&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    vectors <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(vectors, dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 维度检查</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> dimension_check <span style=color:#f92672>and</span> len(vectors<span style=color:#f92672>.</span>shape) <span style=color:#f92672>!=</span> <span style=color:#ae81ff>2</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Expected 2D array, got </span><span style=color:#e6db74>{</span>len(vectors<span style=color:#f92672>.</span>shape)<span style=color:#e6db74>}</span><span style=color:#e6db74>D&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 检查NaN和无穷值</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> np<span style=color:#f92672>.</span>any(np<span style=color:#f92672>.</span>isnan(vectors)) <span style=color:#f92672>or</span> np<span style=color:#f92672>.</span>any(np<span style=color:#f92672>.</span>isinf(vectors)):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Warning: Found NaN or infinite values, replacing with zeros&#34;</span>)
</span></span><span style=display:flex><span>        vectors <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>nan_to_num(vectors, nan<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, posinf<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, neginf<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 归一化</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> normalization <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;l2&#34;</span>:
</span></span><span style=display:flex><span>        vectors <span style=color:#f92672>=</span> normalize(vectors, norm<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;l2&#39;</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>elif</span> normalization <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;minmax&#34;</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
</span></span><span style=display:flex><span>        scaler <span style=color:#f92672>=</span> MinMaxScaler()
</span></span><span style=display:flex><span>        vectors <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(vectors)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> vectors<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 数据验证</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>validate_data_quality</span>(data, schema):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;验证数据质量&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    issues <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 检查数据长度一致性</span>
</span></span><span style=display:flex><span>    field_lengths <span style=color:#f92672>=</span> [len(field_data) <span style=color:#66d9ef>for</span> field_data <span style=color:#f92672>in</span> data]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> len(set(field_lengths)) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span>        issues<span style=color:#f92672>.</span>append(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inconsistent field lengths: </span><span style=color:#e6db74>{</span>field_lengths<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 检查向量维度</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, field <span style=color:#f92672>in</span> enumerate(schema<span style=color:#f92672>.</span>fields):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> field<span style=color:#f92672>.</span>dtype <span style=color:#f92672>==</span> DataType<span style=color:#f92672>.</span>FLOAT_VECTOR:
</span></span><span style=display:flex><span>            vectors <span style=color:#f92672>=</span> data[i]
</span></span><span style=display:flex><span>            expected_dim <span style=color:#f92672>=</span> field<span style=color:#f92672>.</span>params<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;dim&#39;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> j, vector <span style=color:#f92672>in</span> enumerate(vectors[:<span style=color:#ae81ff>100</span>]):  <span style=color:#75715e># 检查前100个</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> len(vector) <span style=color:#f92672>!=</span> expected_dim:
</span></span><span style=display:flex><span>                    issues<span style=color:#f92672>.</span>append(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Vector </span><span style=color:#e6db74>{</span>j<span style=color:#e6db74>}</span><span style=color:#e6db74> has dimension </span><span style=color:#e6db74>{</span>len(vector)<span style=color:#e6db74>}</span><span style=color:#e6db74>, expected </span><span style=color:#e6db74>{</span>expected_dim<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> issues
</span></span></code></pre></div><h3 id=4-监控和运维最佳实践>4. 监控和运维最佳实践<a hidden class=anchor aria-hidden=true href=#4-监控和运维最佳实践>#</a></h3><h4 id=健康检查系统>健康检查系统<a hidden class=anchor aria-hidden=true href=#健康检查系统>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> logging
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MilvusHealthMonitor</span>:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Milvus健康监控系统&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, collection_names, alert_thresholds<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection_names <span style=color:#f92672>=</span> collection_names
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>alert_thresholds <span style=color:#f92672>=</span> alert_thresholds <span style=color:#f92672>or</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;query_latency&#39;</span>: <span style=color:#ae81ff>1.0</span>,  <span style=color:#75715e># 秒</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;memory_usage&#39;</span>: <span style=color:#ae81ff>0.8</span>,   <span style=color:#75715e># 80%</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#39;error_rate&#39;</span>: <span style=color:#ae81ff>0.05</span>     <span style=color:#75715e># 5%</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>logger <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_setup_logger()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_setup_logger</span>(self):
</span></span><span style=display:flex><span>        logger <span style=color:#f92672>=</span> logging<span style=color:#f92672>.</span>getLogger(<span style=color:#e6db74>&#39;milvus_monitor&#39;</span>)
</span></span><span style=display:flex><span>        logger<span style=color:#f92672>.</span>setLevel(logging<span style=color:#f92672>.</span>INFO)
</span></span><span style=display:flex><span>        handler <span style=color:#f92672>=</span> logging<span style=color:#f92672>.</span>FileHandler(<span style=color:#e6db74>&#39;milvus_health.log&#39;</span>)
</span></span><span style=display:flex><span>        formatter <span style=color:#f92672>=</span> logging<span style=color:#f92672>.</span>Formatter(<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%(asctime)s</span><span style=color:#e6db74> - </span><span style=color:#e6db74>%(levelname)s</span><span style=color:#e6db74> - </span><span style=color:#e6db74>%(message)s</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>        handler<span style=color:#f92672>.</span>setFormatter(formatter)
</span></span><span style=display:flex><span>        logger<span style=color:#f92672>.</span>addHandler(handler)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> logger
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>check_connection_health</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;检查连接健康状态&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>            version <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>get_server_version()
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Milvus server version: </span><span style=color:#e6db74>{</span>version<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>error(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Connection health check failed: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>check_collection_health</span>(self, collection_name):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;检查集合健康状态&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection <span style=color:#f92672>=</span> Collection(collection_name)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 检查集合状态</span>
</span></span><span style=display:flex><span>            stats <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>get_stats()
</span></span><span style=display:flex><span>            num_entities <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>num_entities
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 执行测试查询</span>
</span></span><span style=display:flex><span>            start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>            test_vector <span style=color:#f92672>=</span> [[<span style=color:#ae81ff>0.1</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>128</span>]  <span style=color:#75715e># 假设128维向量</span>
</span></span><span style=display:flex><span>            results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>                data<span style=color:#f92672>=</span>test_vector,
</span></span><span style=display:flex><span>                anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>                param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>10</span>}},
</span></span><span style=display:flex><span>                limit<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            query_latency <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time() <span style=color:#f92672>-</span> start_time
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 记录指标</span>
</span></span><span style=display:flex><span>            metrics <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;collection&#39;</span>: collection_name,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;num_entities&#39;</span>: num_entities,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;query_latency&#39;</span>: query_latency,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;timestamp&#39;</span>: datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat()
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection health: </span><span style=color:#e6db74>{</span>metrics<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 检查告警阈值</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> query_latency <span style=color:#f92672>&gt;</span> self<span style=color:#f92672>.</span>alert_thresholds[<span style=color:#e6db74>&#39;query_latency&#39;</span>]:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>warning(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;High query latency: </span><span style=color:#e6db74>{</span>query_latency<span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>s&#34;</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> metrics
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>error(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection health check failed for </span><span style=color:#e6db74>{</span>collection_name<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run_continuous_monitoring</span>(self, interval<span style=color:#f92672>=</span><span style=color:#ae81ff>60</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;持续监控&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                <span style=color:#75715e># 检查连接</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> self<span style=color:#f92672>.</span>check_connection_health():
</span></span><span style=display:flex><span>                    self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>critical(<span style=color:#e6db74>&#34;Milvus connection lost!&#34;</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#75715e># 检查所有集合</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>for</span> collection_name <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>collection_names:
</span></span><span style=display:flex><span>                    self<span style=color:#f92672>.</span>check_collection_health(collection_name)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                time<span style=color:#f92672>.</span>sleep(interval)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>KeyboardInterrupt</span>:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>info(<span style=color:#e6db74>&#34;Monitoring stopped by user&#34;</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>logger<span style=color:#f92672>.</span>error(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Monitoring error: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                time<span style=color:#f92672>.</span>sleep(interval)
</span></span></code></pre></div><h4 id=备份和恢复策略>备份和恢复策略<a hidden class=anchor aria-hidden=true href=#备份和恢复策略>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MilvusBackupManager</span>:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Milvus备份管理器&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, backup_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;./milvus_backups&#34;</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>backup_dir <span style=color:#f92672>=</span> backup_dir
</span></span><span style=display:flex><span>        os<span style=color:#f92672>.</span>makedirs(backup_dir, exist_ok<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>backup_collection_metadata</span>(self, collection_name):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;备份集合元数据&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            collection <span style=color:#f92672>=</span> Collection(collection_name)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 收集元数据</span>
</span></span><span style=display:flex><span>            metadata <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;name&#39;</span>: collection<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;description&#39;</span>: collection<span style=color:#f92672>.</span>description,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;schema&#39;</span>: {
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;fields&#39;</span>: [
</span></span><span style=display:flex><span>                        {
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;name&#39;</span>: field<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;dtype&#39;</span>: str(field<span style=color:#f92672>.</span>dtype),
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;params&#39;</span>: field<span style=color:#f92672>.</span>params,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;is_primary&#39;</span>: field<span style=color:#f92672>.</span>is_primary,
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;auto_id&#39;</span>: field<span style=color:#f92672>.</span>auto_id
</span></span><span style=display:flex><span>                        }
</span></span><span style=display:flex><span>                        <span style=color:#66d9ef>for</span> field <span style=color:#f92672>in</span> collection<span style=color:#f92672>.</span>schema<span style=color:#f92672>.</span>fields
</span></span><span style=display:flex><span>                    ],
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>&#39;enable_dynamic_field&#39;</span>: collection<span style=color:#f92672>.</span>schema<span style=color:#f92672>.</span>enable_dynamic_field
</span></span><span style=display:flex><span>                },
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;num_entities&#39;</span>: collection<span style=color:#f92672>.</span>num_entities,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;partitions&#39;</span>: [p<span style=color:#f92672>.</span>name <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> collection<span style=color:#f92672>.</span>partitions],
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#39;indexes&#39;</span>: []
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 获取索引信息</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                index_info <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>index()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> index_info:
</span></span><span style=display:flex><span>                    metadata[<span style=color:#e6db74>&#39;indexes&#39;</span>]<span style=color:#f92672>.</span>append({
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#39;field_name&#39;</span>: <span style=color:#e6db74>&#39;embedding&#39;</span>,  <span style=color:#75715e># 假设向量字段名</span>
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#39;index_params&#39;</span>: index_info<span style=color:#f92672>.</span>params
</span></span><span style=display:flex><span>                    })
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span>:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>pass</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 保存元数据</span>
</span></span><span style=display:flex><span>            timestamp <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#34;%Y%m</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>_%H%M%S&#34;</span>)
</span></span><span style=display:flex><span>            backup_file <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>backup_dir<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>collection_name<span style=color:#e6db74>}</span><span style=color:#e6db74>_metadata_</span><span style=color:#e6db74>{</span>timestamp<span style=color:#e6db74>}</span><span style=color:#e6db74>.json&#34;</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>with</span> open(backup_file, <span style=color:#e6db74>&#39;w&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>                json<span style=color:#f92672>.</span>dump(metadata, f, indent<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Metadata backup saved: </span><span style=color:#e6db74>{</span>backup_file<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> backup_file
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Backup failed: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>restore_collection_from_metadata</span>(self, backup_file):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;从元数据恢复集合结构&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>with</span> open(backup_file, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>                metadata <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>load(f)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 重建字段</span>
</span></span><span style=display:flex><span>            fields <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> field_info <span style=color:#f92672>in</span> metadata[<span style=color:#e6db74>&#39;schema&#39;</span>][<span style=color:#e6db74>&#39;fields&#39;</span>]:
</span></span><span style=display:flex><span>                field <span style=color:#f92672>=</span> FieldSchema(
</span></span><span style=display:flex><span>                    name<span style=color:#f92672>=</span>field_info[<span style=color:#e6db74>&#39;name&#39;</span>],
</span></span><span style=display:flex><span>                    dtype<span style=color:#f92672>=</span>getattr(DataType, field_info[<span style=color:#e6db74>&#39;dtype&#39;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;.&#39;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]),
</span></span><span style=display:flex><span>                    is_primary<span style=color:#f92672>=</span>field_info<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;is_primary&#39;</span>, <span style=color:#66d9ef>False</span>),
</span></span><span style=display:flex><span>                    auto_id<span style=color:#f92672>=</span>field_info<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;auto_id&#39;</span>, <span style=color:#66d9ef>False</span>),
</span></span><span style=display:flex><span>                    <span style=color:#f92672>**</span>field_info<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;params&#39;</span>, {})
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                fields<span style=color:#f92672>.</span>append(field)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 重建schema</span>
</span></span><span style=display:flex><span>            schema <span style=color:#f92672>=</span> CollectionSchema(
</span></span><span style=display:flex><span>                fields<span style=color:#f92672>=</span>fields,
</span></span><span style=display:flex><span>                description<span style=color:#f92672>=</span>metadata[<span style=color:#e6db74>&#39;description&#39;</span>],
</span></span><span style=display:flex><span>                enable_dynamic_field<span style=color:#f92672>=</span>metadata[<span style=color:#e6db74>&#39;schema&#39;</span>][<span style=color:#e6db74>&#39;enable_dynamic_field&#39;</span>]
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 创建集合</span>
</span></span><span style=display:flex><span>            collection <span style=color:#f92672>=</span> Collection(
</span></span><span style=display:flex><span>                name<span style=color:#f92672>=</span>metadata[<span style=color:#e6db74>&#39;name&#39;</span>],
</span></span><span style=display:flex><span>                schema<span style=color:#f92672>=</span>schema
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 重建分区</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> partition_name <span style=color:#f92672>in</span> metadata[<span style=color:#e6db74>&#39;partitions&#39;</span>]:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> partition_name <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#39;_default&#39;</span>:
</span></span><span style=display:flex><span>                    collection<span style=color:#f92672>.</span>create_partition(partition_name)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection </span><span style=color:#e6db74>{</span>metadata[<span style=color:#e6db74>&#39;name&#39;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74> restored from backup&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> collection
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Restore failed: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>
</span></span></code></pre></div><h3 id=5-安全最佳实践>5. 安全最佳实践<a hidden class=anchor aria-hidden=true href=#5-安全最佳实践>#</a></h3><h4 id=访问控制>访问控制<a hidden class=anchor aria-hidden=true href=#访问控制>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> connections
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安全连接配置</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>secure_connect</span>(host, port, username, password, secure<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;安全连接到Milvus&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>        connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>            alias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;secure_connection&#34;</span>,
</span></span><span style=display:flex><span>            host<span style=color:#f92672>=</span>host,
</span></span><span style=display:flex><span>            port<span style=color:#f92672>=</span>port,
</span></span><span style=display:flex><span>            user<span style=color:#f92672>=</span>username,
</span></span><span style=display:flex><span>            password<span style=color:#f92672>=</span>password,
</span></span><span style=display:flex><span>            secure<span style=color:#f92672>=</span>secure,
</span></span><span style=display:flex><span>            server_pem_path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/path/to/server.pem&#34;</span>,  <span style=color:#75715e># TLS证书路径</span>
</span></span><span style=display:flex><span>            server_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;milvus-server&#34;</span>,
</span></span><span style=display:flex><span>            timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Secure connection established&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Secure connection failed: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 输入验证</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>validate_search_input</span>(query_vectors, limit, expr<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;验证搜索输入&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 验证向量</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> isinstance(query_vectors, list) <span style=color:#f92672>or</span> <span style=color:#f92672>not</span> query_vectors:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;Query vectors must be a non-empty list&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 验证limit</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> isinstance(limit, int) <span style=color:#f92672>or</span> limit <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>or</span> limit <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>10000</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;Limit must be a positive integer &lt;= 10000&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 验证表达式（防止注入）</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> expr:
</span></span><span style=display:flex><span>        dangerous_keywords <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;DROP&#39;</span>, <span style=color:#e6db74>&#39;DELETE&#39;</span>, <span style=color:#e6db74>&#39;UPDATE&#39;</span>, <span style=color:#e6db74>&#39;INSERT&#39;</span>, <span style=color:#e6db74>&#39;CREATE&#39;</span>]
</span></span><span style=display:flex><span>        expr_upper <span style=color:#f92672>=</span> expr<span style=color:#f92672>.</span>upper()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> keyword <span style=color:#f92672>in</span> dangerous_keywords:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> keyword <span style=color:#f92672>in</span> expr_upper:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Dangerous keyword &#39;</span><span style=color:#e6db74>{</span>keyword<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39; found in expression&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>True</span>
</span></span></code></pre></div><h2 id=12-常见问题>12. 常见问题<a hidden class=anchor aria-hidden=true href=#12-常见问题>#</a></h2><h3 id=q1-如何选择合适的索引类型>Q1: 如何选择合适的索引类型？<a hidden class=anchor aria-hidden=true href=#q1-如何选择合适的索引类型>#</a></h3><p><strong>A</strong>: 索引选择主要考虑以下因素：</p><ul><li><p><strong>数据规模</strong>：</p><ul><li>&lt; 10万条：FLAT索引（精确搜索）</li><li>10万-100万条：IVF_FLAT索引</li><li>大于100万条：HNSW或IVF_PQ索引</li></ul></li><li><p><strong>内存预算</strong>：</p><ul><li>内存充足：HNSW索引（最高性能）</li><li>内存有限：IVF_PQ索引（压缩存储）</li><li>极度受限：ANNOY索引</li></ul></li><li><p><strong>精度要求</strong>：</p><ul><li>需要精确结果：FLAT索引</li><li>高精度近似：HNSW索引</li><li>平衡精度性能：IVF_FLAT索引</li></ul></li><li><p><strong>查询模式</strong>：</p><ul><li>频繁查询：HNSW索引</li><li>批量查询：IVF系列索引</li><li>静态数据：ANNOY索引</li></ul></li></ul><h3 id=q2-搜索性能慢怎么优化>Q2: 搜索性能慢怎么优化？<a hidden class=anchor aria-hidden=true href=#q2-搜索性能慢怎么优化>#</a></h3><p><strong>A</strong>: 性能优化策略：</p><ol><li><p><strong>索引优化</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 调整索引参数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IVF索引：增加nlist，减少nprobe</span>
</span></span><span style=display:flex><span><span style=color:#75715e># HNSW索引：增加M值，调整ef参数</span>
</span></span></code></pre></div></li><li><p><strong>查询优化</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 使用分区过滤</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>search_params,
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    partition_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;recent_partition&#34;</span>]  <span style=color:#75715e># 只搜索相关分区</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>硬件优化</strong>：</p><ul><li>使用SSD存储</li><li>增加内存容量</li><li>使用GPU加速（如果支持）</li></ul></li><li><p><strong>并发优化</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 并行搜索多个查询</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> concurrent.futures
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parallel_search</span>(queries):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> concurrent<span style=color:#f92672>.</span>futures<span style=color:#f92672>.</span>ThreadPoolExecutor(max_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>) <span style=color:#66d9ef>as</span> executor:
</span></span><span style=display:flex><span>        futures <span style=color:#f92672>=</span> [executor<span style=color:#f92672>.</span>submit(collection<span style=color:#f92672>.</span>search, [q], <span style=color:#e6db74>&#34;embedding&#34;</span>, search_params, <span style=color:#ae81ff>10</span>) 
</span></span><span style=display:flex><span>                  <span style=color:#66d9ef>for</span> q <span style=color:#f92672>in</span> queries]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> [f<span style=color:#f92672>.</span>result() <span style=color:#66d9ef>for</span> f <span style=color:#f92672>in</span> futures]
</span></span></code></pre></div></li></ol><h3 id=q3-内存使用过高怎么处理>Q3: 内存使用过高怎么处理？<a hidden class=anchor aria-hidden=true href=#q3-内存使用过高怎么处理>#</a></h3><p><strong>A</strong>: 内存优化方法：</p><ol><li><p><strong>使用压缩索引</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 使用PQ压缩</span>
</span></span><span style=display:flex><span>pq_index <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;index_type&#34;</span>: <span style=color:#e6db74>&#34;IVF_PQ&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nlist&#34;</span>: <span style=color:#ae81ff>128</span>, <span style=color:#e6db74>&#34;m&#34;</span>: <span style=color:#ae81ff>16</span>, <span style=color:#e6db74>&#34;nbits&#34;</span>: <span style=color:#ae81ff>8</span>}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></li><li><p><strong>分区管理</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 只加载需要的分区</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load(partition_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;active_partition&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 释放不用的分区</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>release(partition_names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;old_partition&#34;</span>])
</span></span></code></pre></div></li><li><p><strong>配置调整</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># 在milvus.yaml中调整缓存大小</span>
</span></span><span style=display:flex><span><span style=color:#f92672>queryCoord</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>cache</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>size</span>: <span style=color:#ae81ff>2GB </span> <span style=color:#75715e># 减少缓存大小</span>
</span></span></code></pre></div></li></ol><h3 id=q4-数据一致性问题如何解决>Q4: 数据一致性问题如何解决？<a hidden class=anchor aria-hidden=true href=#q4-数据一致性问题如何解决>#</a></h3><p><strong>A</strong>: 确保数据一致性：</p><ol><li><p><strong>设置一致性级别</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 创建集合时设置强一致性</span>
</span></span><span style=display:flex><span>collection <span style=color:#f92672>=</span> Collection(
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;consistent_collection&#34;</span>,
</span></span><span style=display:flex><span>    schema<span style=color:#f92672>=</span>schema,
</span></span><span style=display:flex><span>    consistency_level<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Strong&#34;</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>及时刷新数据</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 插入后立即刷新</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>insert(entities)
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>flush()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 等待刷新完成</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
</span></span></code></pre></div></li><li><p><strong>检查数据状态</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 检查索引构建状态</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>progress <span style=color:#f92672>=</span> utility<span style=color:#f92672>.</span>index_building_progress(collection<span style=color:#f92672>.</span>name)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Index progress: </span><span style=color:#e6db74>{</span>progress<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div></li></ol><h3 id=q5-集群部署常见问题>Q5: 集群部署常见问题<a hidden class=anchor aria-hidden=true href=#q5-集群部署常见问题>#</a></h3><p><strong>A</strong>: 集群部署注意事项：</p><ol><li><p><strong>资源规划</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># Kubernetes资源配置示例</span>
</span></span><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>memory</span>: <span style=color:#e6db74>&#34;8Gi&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>cpu</span>: <span style=color:#e6db74>&#34;4&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>memory</span>: <span style=color:#e6db74>&#34;16Gi&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>cpu</span>: <span style=color:#e6db74>&#34;8&#34;</span>
</span></span></code></pre></div></li><li><p><strong>网络配置</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># 确保节点间网络畅通</span>
</span></span><span style=display:flex><span><span style=color:#f92672>service</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>type</span>: <span style=color:#ae81ff>ClusterIP</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>port</span>: <span style=color:#ae81ff>19530</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>targetPort</span>: <span style=color:#ae81ff>19530</span>
</span></span></code></pre></div></li><li><p><strong>存储配置</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># 使用持久化存储</span>
</span></span><span style=display:flex><span><span style=color:#f92672>persistence</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>storageClass</span>: <span style=color:#e6db74>&#34;fast-ssd&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>size</span>: <span style=color:#ae81ff>100Gi</span>
</span></span></code></pre></div></li></ol><h3 id=q6-向量维度不匹配错误>Q6: 向量维度不匹配错误<a hidden class=anchor aria-hidden=true href=#q6-向量维度不匹配错误>#</a></h3><p><strong>A</strong>: 解决维度不匹配：</p><ol><li><p><strong>检查向量维度</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>validate_vector_dimension</span>(vectors, expected_dim):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, vector <span style=color:#f92672>in</span> enumerate(vectors):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> len(vector) <span style=color:#f92672>!=</span> expected_dim:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Vector </span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74> has dimension </span><span style=color:#e6db74>{</span>len(vector)<span style=color:#e6db74>}</span><span style=color:#e6db74>, expected </span><span style=color:#e6db74>{</span>expected_dim<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div></li><li><p><strong>统一向量维度</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>normalize_vector_dimension</span>(vectors, target_dim):
</span></span><span style=display:flex><span>    normalized <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> vector <span style=color:#f92672>in</span> vectors:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> len(vector) <span style=color:#f92672>&lt;</span> target_dim:
</span></span><span style=display:flex><span>            <span style=color:#75715e># 填充零值</span>
</span></span><span style=display:flex><span>            vector<span style=color:#f92672>.</span>extend([<span style=color:#ae81ff>0.0</span>] <span style=color:#f92672>*</span> (target_dim <span style=color:#f92672>-</span> len(vector)))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elif</span> len(vector) <span style=color:#f92672>&gt;</span> target_dim:
</span></span><span style=display:flex><span>            <span style=color:#75715e># 截断</span>
</span></span><span style=display:flex><span>            vector <span style=color:#f92672>=</span> vector[:target_dim]
</span></span><span style=display:flex><span>        normalized<span style=color:#f92672>.</span>append(vector)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> normalized
</span></span></code></pre></div></li></ol><h3 id=q7-连接超时和网络问题>Q7: 连接超时和网络问题<a hidden class=anchor aria-hidden=true href=#q7-连接超时和网络问题>#</a></h3><p><strong>A</strong>: 网络问题排查：</p><ol><li><p><strong>增加超时时间</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>connections<span style=color:#f92672>.</span>connect(
</span></span><span style=display:flex><span>    alias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>    host<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;milvus-server&#34;</span>,
</span></span><span style=display:flex><span>    port<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;19530&#34;</span>,
</span></span><span style=display:flex><span>    timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>60</span>  <span style=color:#75715e># 增加超时时间</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>连接池配置</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 配置连接池</span>
</span></span><span style=display:flex><span>connections<span style=color:#f92672>.</span>configure(
</span></span><span style=display:flex><span>    alias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;production&#34;</span>,
</span></span><span style=display:flex><span>    host<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;milvus-server&#34;</span>,
</span></span><span style=display:flex><span>    port<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;19530&#34;</span>,
</span></span><span style=display:flex><span>    pool_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>    timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>健康检查</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>check_connection</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>from</span> pymilvus <span style=color:#f92672>import</span> utility
</span></span><span style=display:flex><span>        utility<span style=color:#f92672>.</span>get_server_version()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Connection check failed: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>False</span>
</span></span></code></pre></div></li></ol><h3 id=q8-搜索结果为空>Q8: 搜索结果为空<a hidden class=anchor aria-hidden=true href=#q8-搜索结果为空>#</a></h3><p><strong>A</strong>: 排查搜索结果为空：</p><ol><li><p><strong>检查数据是否加载</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 确保集合已加载</span>
</span></span><span style=display:flex><span>collection<span style=color:#f92672>.</span>load()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 检查加载状态</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Collection loaded: </span><span style=color:#e6db74>{</span>collection<span style=color:#f92672>.</span>has_index()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Number of entities: </span><span style=color:#e6db74>{</span>collection<span style=color:#f92672>.</span>num_entities<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div></li><li><p><strong>检查搜索参数</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 放宽搜索条件</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> collection<span style=color:#f92672>.</span>search(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>query_vectors,
</span></span><span style=display:flex><span>    anns_field<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    param<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;metric_type&#34;</span>: <span style=color:#e6db74>&#34;L2&#34;</span>, <span style=color:#e6db74>&#34;params&#34;</span>: {<span style=color:#e6db74>&#34;nprobe&#34;</span>: <span style=color:#ae81ff>128</span>}},  <span style=color:#75715e># 增加nprobe</span>
</span></span><span style=display:flex><span>    limit<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,  <span style=color:#75715e># 增加返回数量</span>
</span></span><span style=display:flex><span>    expr<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>  <span style=color:#75715e># 移除过滤条件</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>验证查询向量</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 检查查询向量是否有效</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>validate_query_vector</span>(vector, collection_schema):
</span></span><span style=display:flex><span>    vector_field <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> field <span style=color:#f92672>in</span> collection_schema<span style=color:#f92672>.</span>fields:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> field<span style=color:#f92672>.</span>dtype <span style=color:#f92672>==</span> DataType<span style=color:#f92672>.</span>FLOAT_VECTOR:
</span></span><span style=display:flex><span>            vector_field <span style=color:#f92672>=</span> field
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> vector_field <span style=color:#f92672>and</span> len(vector) <span style=color:#f92672>!=</span> vector_field<span style=color:#f92672>.</span>params[<span style=color:#e6db74>&#39;dim&#39;</span>]:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Query vector dimension mismatch&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> all(v <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> vector):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;Warning: Query vector is all zeros&#34;</span>)
</span></span></code></pre></div></li></ol><h3 id=进一步学习资源>进一步学习资源<a hidden class=anchor aria-hidden=true href=#进一步学习资源>#</a></h3><ul><li><a href=https://milvus.io/docs>Milvus官方文档</a></li><li><a href=https://github.com/milvus-io/milvus>Milvus GitHub仓库</a></li><li><a href=https://discuss.milvus.io/>Milvus社区论坛</a></li><li><a href=https://milvus.io/blog>向量数据库最佳实践</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://wellzhi.github.io/tags/milvus/>Milvus</a></li><li><a href=https://wellzhi.github.io/tags/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/>向量数据库</a></li><li><a href=https://wellzhi.github.io/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/>向量检索</a></li><li><a href=https://wellzhi.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/>分布式</a></li><li><a href=https://wellzhi.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/>搜索引擎</a></li></ul></footer><div class=comments-section><div class=comments-header><h3 class=comments-title><svg class="comments-icon" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2"><path d="M21 15a2 2 0 01-2 2H7l-4 4V5a2 2 0 012-2h14a2 2 0 012 2z"/></svg>
评论区</h3><div class=comments-divider></div></div><div id=twikoo-loading class=twikoo-loading><div class=loading-spinner></div><p>评论加载中...</p></div><div id=twikoo class=twikoo-container></div><div id=twikoo-error class=twikoo-error style=display:none><div class=error-content><svg class="error-icon" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2"><circle cx="12" cy="12" r="10"/><line x1="15" y1="9" x2="9" y2="15"/><line x1="9" y1="9" x2="15" y2="15"/></svg><p>评论加载失败，请刷新页面重试</p></div></div></div><style>.comments-section{margin:3rem 0 2rem;padding:0;max-width:100%}.comments-header{margin-bottom:2rem}.comments-title{display:flex;align-items:center;gap:.5rem;font-size:1.5rem;font-weight:600;color:var(--primary,#1a1a1a);margin:0 0 1rem}.comments-icon{width:1.5rem;height:1.5rem;color:var(--theme,#007acc)}.comments-divider{height:2px;background:linear-gradient(90deg,var(--theme,#007acc) 0%,transparent 100%);border-radius:1px;width:60px}.twikoo-container{background:var(--code-bg,#f8f9fa);border-radius:12px;padding:1.5rem;border:1px solid var(--border,#e1e5e9);transition:all .3s ease;min-height:200px}.twikoo-container:hover{border-color:var(--theme,#007acc);box-shadow:0 4px 12px rgba(0,122,204,.1)}.twikoo-loading{display:flex;flex-direction:column;align-items:center;justify-content:center;padding:3rem 1rem;color:var(--secondary,#666)}.loading-spinner{width:32px;height:32px;border:3px solid var(--border,#e1e5e9);border-top:3px solid var(--theme,#007acc);border-radius:50%;animation:spin 1s linear infinite;margin-bottom:1rem}@keyframes spin{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}.twikoo-error{text-align:center;padding:2rem;color:var(--secondary,#666)}.error-content{display:flex;flex-direction:column;align-items:center;gap:1rem}.error-icon{width:2rem;height:2rem;color:#dc3545}@media(prefers-color-scheme:dark){.comments-title{color:var(--primary,#ffffff)}.twikoo-container{background:var(--code-bg,#2d3748);border-color:var(--border,#4a5568)}}@media(max-width:768px){.comments-section{margin:2rem 0 1rem}.twikoo-container{padding:1rem;border-radius:8px}.comments-title{font-size:1.25rem}}</style><script src=https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js></script><script>(function(){const e=document.getElementById("twikoo-loading"),t=document.getElementById("twikoo-error"),n=document.getElementById("twikoo");twikoo.init({envId:"https://twikoo-vercel-navy.vercel.app/",el:"#twikoo",onCommentLoaded:function(){e&&(e.style.display="none")}}).then(function(){e&&(e.style.display="none")}).catch(function(n){console.error("Twikoo 初始化失败:",n),e&&(e.style.display="none"),t&&(t.style.display="block")}),setTimeout(function(){e&&e.style.display!=="none"&&(e.style.display="none",t&&(t.style.display="block"))},5e3)})()</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://wellzhi.github.io/>wellzhi</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light"),theme=""):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"),theme="dark"),mermaidTextContents.forEach((e,t)=>{document.getElementsByClassName("language-mermaid")[t].removeAttribute("data-processed"),document.getElementsByClassName("language-mermaid")[t].innerHTML=e}),mermaid.initialize({theme,startOnLoad:!0}),mermaid.init(void 0,".language-mermaid")})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>localStorage.getItem("pref-theme")=="dark"?theme="dark":theme="",mermaidTextContents=Array.from(document.getElementsByClassName("language-mermaid")).map(e=>e.innerHTML),mermaid.initialize({theme,startOnLoad:!0}),mermaid.init(void 0,".language-mermaid")</script></body></html>