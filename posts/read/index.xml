<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Read on wellzhi</title><link>https://wellzhi.github.io/posts/read/</link><description>Recent content in Read on wellzhi</description><generator>Hugo -- 0.147.2</generator><language>zh-cn</language><lastBuildDate>Sun, 27 Apr 2025 11:11:45 +0800</lastBuildDate><atom:link href="https://wellzhi.github.io/posts/read/index.xml" rel="self" type="application/rss+xml"/><item><title>Strengthening AI Agent Hijacking Evaluations</title><link>https://wellzhi.github.io/posts/read/2025-04-27_strengthening-ai-agent-hijacking-evaluations/</link><pubDate>Sun, 27 Apr 2025 11:11:45 +0800</pubDate><guid>https://wellzhi.github.io/posts/read/2025-04-27_strengthening-ai-agent-hijacking-evaluations/</guid><description>&lt;h2 id="文章来源">文章来源&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="%5BURL_ADDRESS.org/abs/2305.15733%5D(https://www.nist.gov/news-events/news/2025/01/technical-blog-strengthening-ai-agent-hijacking-evaluations)">Strengthening AI Agent Hijacking Evaluations&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Large AI models are increasingly used to power agentic systems, or “agents,” which can automate complex tasks on behalf of users. AI agents could have a wide range of potential benefits, such as automating scientific research or serving as personal assistants.&lt;/p>
&lt;p>However, to fully realize the potential of AI agents, it is essential to identify and measure — in order to ultimately mitigate — the security risks these systems could introduce.&lt;/p></description></item><item><title>LLM Prompt Trick</title><link>https://wellzhi.github.io/posts/read/2025-01-07_llm-prompt-trick/</link><pubDate>Tue, 07 Jan 2025 20:42:05 +0800</pubDate><guid>https://wellzhi.github.io/posts/read/2025-01-07_llm-prompt-trick/</guid><description>&lt;p>A recent paper, “Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4,” introduces 26 guiding principles designed to streamline the process of querying and prompting large language models. Here’s the list of these prompt engineering tricks with examples.&lt;/p>
&lt;p>&lt;a href="https://www.superannotate.com/blog/llm-prompting-tricks">https://www.superannotate.com/blog/llm-prompting-tricks&lt;/a>&lt;/p></description></item><item><title>LLM Agent</title><link>https://wellzhi.github.io/posts/read/2025-01-04_llm-agent/</link><pubDate>Sat, 04 Jan 2025 14:51:27 +0800</pubDate><guid>https://wellzhi.github.io/posts/read/2025-01-04_llm-agent/</guid><description>&lt;p>&lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent/">LLM Powered Autonomous Agents&lt;/a>&lt;/p></description></item></channel></rss>